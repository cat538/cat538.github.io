---
title: OS复习
date: 2021-06-16 15:05:29
categories: 'CS基础'
tags: ['OS']
description: "OS期末考试的复习总结。主要包括进程、内存、文件、IO四个模块。参考教材为《现代操作系统》第四版。"
cover: 
mathjax: true
---

# 第0章	概述

## OS为什么要分用户态和内核态？

>  CPU可以执行其指令集中的每条指令，并在内核态下执行时使用硬件的各种功能。 
>
> 但是用户态只能执行部分指令，执行时仅使用部分功能。 
>
> 拥有两种模式允许设计人员以用户态运行用户程序，从而拒绝他们访问关键指令。

## 中断和异常

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607163949806.png" alt="image-20210607163949806" style="zoom: 50%;" />

- 中断的分类按照老师课件：

  <img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607172447167.png" alt="image-20210607172447167" style="zoom:50%;" />

- 中断处理流程：

  1. 接收中断信号
  2. 硬件保护现场（程序信息压入堆栈）
  3. 根据中断源查找中断向量
  4. 中断处理程序入口address推入相应寄存器
  5. 执行中断处理程序
  6. 中断处理程序执行结束之后恢复状态
  7. 继续执行原来的程序

## 系统调用

系统调用属于软中断，**是唯一可以让程序主动进入操作系统（特权模式）的操作 **

- 函数库调用和系统调用：

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607195017196.png" alt="image-20210607195017196" style="zoom:50%;" />

## 宏内核和微内核

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607195533629.png" alt="image-20210607195533629" style="zoom: 50%;" />



## 几个设计思想

- **多道程序设计（multiprogramming）**：多道程序设计的主要原因是在某个程序等待I/O完成时，可以让CPU做一些其他操作。
- **分时操作系统（timesharing）**：**多用户**共享主机，操作系统为多用户提供快速交互式服务。同时性、独立性、及时性、交互作用性

# 第1章	进程

## 进程基础

**进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位。**

### 进程的三个状态

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607210215115.png" alt="image-20210607210215115" style="zoom:50%;" />

### 多道程序设计的CPU利用率

- $CPU利用率 = 1-P^n$，
  - 其中P为$进程等待IO时间/进程在内存时间$
  - n为多道程序设计道数
- 从公式可以看出，进程IO时间占比越少，进程道数越多，CPU利用率越高

### 用户级线程和内核级线程

二者区别在于性能：

- 用户级线程的切换只需要少数几条机器指令；而内核级线程切换需要完整保存上下文，修改内存映像，使cache失效
- 用户级线程使用系统调用（如IO阻塞）的时候，会将整个进程挂起；而内核级线程则不会





## 进程调度

### 调度算法分类和目标：

对于不同的系统，进程调度算法有着不同的目标和度量指标

- 批处理系统：
  - 吞吐量（throughput）：系统单位时间完成作业数量，越大越好
  - 周转时间（turnaround time）：提交作业到完成作业的时间，越小越好
  - 响应比：周转时间/执行时间
  - 带权周转时间：响应比之和/进程数
  - CPU利用率
- 交互式系统：
  - 响应时间
  - 均衡性
- 实时系统：
  - 满足截止时间
  - 可预测性···

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607215707442.png" alt="image-20210607215707442" style="zoom:50%;" />

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210615222456694.png" alt="image-20210607215823335" style="zoom:50%;" />

### 调度算法

#### 批处理系统中的调度算法：

- **先来先服务（FCFS: First Come First Serve ）**

  - 长进程后面的短进程需要等很长时间，不利于用户体验  

- **短作业优先（SJF: Shortest Job First ）**

  - **非抢占式**
  - **缺点：**建立在 可以精确预测每个作业运行时间  的假设之上，这种假设显然是理想情况

- **最短剩余时间优先（SRTN: Shortest Remaining Time Nest  ）**

  - 最短作业优先 SJF 的**抢占式版本** 
  - 当一个新就绪的进程比当前运行进程具有更短的完成时间时，系统抢占当前进程，选择新就绪的进程执行  
  - 在所有进程同时可运行时，采用SJF调度算法可以得到最短的平均周转时间 
  - **缺点：**不公平 ：使长时间任务得不到运行 ；无法精确知道一个作业的运行时间 ；

- **高响应比优先（HRRN: Highest Response Ratio Next  ）**

  - 响应比R   = 周转时间 / 处理时间

    ​				=（处理时间 + 等待时间） / 处理时间  

    ​				= 1 +（等待时间 / 处理时间）

    调度时，首先计算每个进程的响应比R，之后总是选择 **R 最高**的进程执行 。

  - 是一种折衷权衡的算法



#### 交互式系统中的调度算法：

- **轮转调度（RR-Round Robin）**
  - 公平，有利于交互式计算，响应快
  - 进程切换需要时间开销，因此时间片太小会导致进程切换消耗过高，而如果时间片太长则会增大进程响应时间
  - 时间片大小应该略大于一次典型交互大小
- **最高优先级调度（HPF—Highest Priority First）**
  - 维护N个就绪队列，每个队列对应一个优先级类 ；处于同一优先级类内部的进程按照时间片轮转方式调度  
  - 每次调度运行出最高优先级队列的队首进程 ；高优先级进程抢占当前进程 
- **多级反馈队列（Multiple feedback queue）**
  - 比最高优先级调度多了一个时间片的区别：每一优先级的时间片大小不同；优先级越高，时间片越短
  - 若时间片用完的时候任务还没有执行完：进入下一优先级队列队尾；若时间片未用完时有新的高优先级任务入队，则高优先级抢占当前任务
- **最短进程优先（Shortest Process Next）**  
  - 与短作业优先类似，但是显然无法预先知道进程的运行时间；不过这个时间可以根据进程过去的行为推测
  - 假设测量到下一次的运行时间为$T_1$，使用老化算法减少之前估计时间的比重：新的估计运行时间：$T' = aT_0+(1-a)T_1$



#### 实时操作系统调度：

满足以下条件称这个实时操作系统是可调度的：
$$
\sum_{i = 1}^{m}\frac{C_i}{P_i}\leq1
$$
m个周期事件，每个事件i以周期$P_i$发生，且需要$C_i$秒CPU时间处理一个事件



## 进程通信

### 屏蔽中断法

不安全，且不适用多核

### 锁变量

每个进程要进入临界区时先看看锁是否被设置，未被设置则可进入。可能会同时进入。

场景：0检查，发现未被设置；**此时被调度到1**；1检查，发现未被设置；则0、1均进入

### 严格轮换法（单标志法）

一个进程是否能进入临界区由其它进程离开时设置的标志决定。忙等待，且存在效率问题。

场景：0进入，离开；1在阻塞；此时0想进入则必须要等待1进入之后再离开

### Peterson算法

![image-20210330214940360](https://github.com/cat538/images-auto/raw/main/img/image-20210609235544236.png)

这个和书上不太一样；按照书上，应当`turn = 自己的编号`

### TSL指令法

与锁变量法一致。锁变量的问题在于**检查锁和进入临界区两个操作不连续**，而使用硬件指令则可以使其变成原子操作，保证了正确。但是同样存在忙等待的问题。

### 生产者-消费者问题

共用一个缓冲区；进入前检查；

> 若**消费者**进入前检查为empty，则`sleep()`，即自我阻塞**（这与忙等待不停循环占用CPU资源不同）**，调度到生产者，生产者`insert_item()`之后发现缓冲区为**1**，判断消费者此前阻塞，于时`wakeup()`唤醒消费者；

> 若**生产者**进入前检查为full，则`sleep()`，即自我阻塞**（这与忙等待占用CPU资源不同）**，调度到消费者，消费者`remove_item()`之后发现缓冲区为**N-1**，判断消费者此前阻塞，于时`wakeup()`唤醒消费者；

考虑一个场景：

> 消费者检查缓冲区，读取到`item`项为0，但此时调度程序因时间片用完或其他原因暂停消费者调度到生产者；
>
> 此时生产者执行`insert_item()`之后发现缓冲区为**1**，因此执行`wakeup()`唤醒消费者，然而此时消费者并未sleep，于时信号丢失；
>
> 进程调度回消费者，因**此前读取到`item`项为0**，因此消费者sleep；此后将直至生产者因缓冲区满sleep后，二者都sleep

### 信号量（semaphore）

为解决上述问题，Dijkstra引入信号量，以及两种操作`P(down)`和`V(up)`，分别对应一般化后的`sleep()`和`wakeup()`。信号量表示系统中的某种资源。当为0时表明资源耗尽。

> 信号量可以解决互斥和同步问题，其中解决互斥问题的二元信号量又称为互斥量(mutex)

**用信号量解决生产者-消费者问题：**

与此前不同，P、V操作均为原子操作，即检查信号量数值和执行sleep阻塞（如果可能的话）/ 执行wakeup唤醒一个进程（如果可能的话），**检查数值、修改变量、阻塞/唤醒 三个动作变为一个不可分割的原子操作**。在上一场景中正因为可分割所以导致问题。

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210615112207750.png" alt="image-20210402165351254" style="zoom:50%;" />

**能否改变PV操作顺序：**

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210611102341015.png" alt="image-20210402165130297" style="zoom: 50%;" />

实现互斥的P操作需要在实现同步的P操作之后；否则可能会引起死锁。

**用信号量机制实现前驱关系：**

![image-20210402171355110](https://github.com/cat538/images-auto/raw/main/img/image-20210611102656769.png)

### 管程

> 管程可以理解成一个类，有数据，有函数接口。对数据的操作必须通过函数接口。
>
> 任一时刻管程中仅允许有一个活跃的进场，以保证对于临界区的互斥访问**(这一点是编译器保证的，即编译器保证对临界区的互斥访问)**
>
> 如果要实现生产者-消费者中的：缓冲区满生产者阻塞；缓冲区空消费者阻塞；则应当使用**条件变量(condition variables)**

信号量和管程的区别：

![image-20210615112207750](https://github.com/cat538/images-auto/raw/main/img/image-20210611110011573.png)

## 经典IPC问题

### 哲学家进餐

哲学家进餐前需要先检查左右两人是否进餐；如果左右两人都未进餐，则将信号量`V(s[i])`；检查完毕后`P(s[i])`；

这样一来如果哲学家左或右有人进餐，则该哲学家将会被阻塞

哲学家进餐完毕时检查左右两人，如果有因自己占有资源而阻塞的哲学家，则此时被唤醒

### 读者-写者

数据库可以同时被多个读者访问；但写者独占数据库；

第一个读者进入时将对于信号量`db`执行`P(db)`，最后一个离开时将`V(db)`；

这样一来除非最后一个读者离开，否则写者进入将被阻塞

 

## 死锁

死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象

### 死锁发生的四个必要条件

- 互斥条件：资源要么是分配个了单独一个进程，要么是可用的
- 不可抢占条件：资源只能主动释放
- 占有和等待条件：得到了资源的进程可以请求其他的资源
- 环路等待条件：不同进程之间的资源请求和占有形成环路

### 死锁检测和死锁避免

死锁检测不会阻止死锁的发生，而是让进程执行，对已经分配的资源进行检查，发生死锁了再考虑进行恢复。

#### 有向图判定环

成环的进程之间发生死锁，环指出去的进程不会死锁

#### 每类型多个资源死锁检测

对于 **当前矩阵C，请求矩阵R，现有资源向量E，可用资源向量A**

矩阵中的每一行代表一个进程所拥有/请求的资源

1. 寻找一个没有标记的进程P，对他而言R矩阵的对应行小于或等于A
2. 如果找到这样一个进程，把C矩阵中P进程对应行加到A中（**P运行完毕，释放资源到可用资源中**），并标记该进程
3. 如果没有找到这样的进程，算法终止

#### 死锁避免

**建立在系统预先知道进程所需要的资源的前提下**

**银行家算法是上一算法的扩展：**

只需要把上述算法中的请求矩阵R的意义更换为最大需求量即可。

其核心思想为：对每一个请求进行检查，检查如果满足这一请求是否会达到安全状态。

- 若是，那么就满足该请求； 
- 否则，就推迟对这一请求的满足。  

### 死锁预防

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210611110042306.png" alt="image-20210609230550547" style="zoom:50%;" />

# 第2章	内存管理

程序的装载：

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210615234804711.png" alt="image-20210609235544236" style="zoom: 67%;" />

内碎片与外碎片：

- 内部碎片是指已经分配给作业但不能被利用的内存空间
- 外部碎片是指系统中还没有分配给作业，但由于碎片太小而无法分配给申请内存空间的新进程的存储块  



## 空闲内存管理

### 位图

- 空闲置0，非空闲置1；节省空间
- 缺点：分配内存时需要搜寻连续0串比较麻烦

### 链表

维护一个记录已分配内存段和空闲内存段的链表  

**一个进程调入时，选择那个内存呢？**  

- 首次适配
- 下次适配：每次不是从头搜，而是从上一次的位置继续
- 最佳适配：找到能容纳进程的最小空闲区
- 最差适配：总是分配最大的空闲区
- 快速适配：为常用大小的空闲区单独维护链表



## 虚拟内存

一个内存地址(虚拟地址)---虚拟页面号--->MMU将VPN(Virtual Page Number)与TLB表项匹配(并行)------>找到物理地址/未找到物理地址

### 分页存储

#### 虚拟地址到物理地址的快速映射

- **引入TLB：**

  对于单级页表且未产生页缺失的一次访存：实际上需要访问两次物理内存：第一次从内存中读虚拟地址对应的页表项，第二次根据页表项的值+偏移量访问数据

  在引入TLB之后：访问TLB比访问内存快得多（应该是一个高速内存，cache中？）常用的页表项被记录在TLB中，类似cache的作用，每次查页表之前先查TLB，如果命中则只需要一次访问内存，可以极大提高查页表的速度。

#### 大内存的页表管理

- **多级页表：**分级越多越灵活，但是分级越多每次访存需要查表的次数也就越多。
- **倒排页表：**索引大小为物理空间大小，不同于普通页表中索引为虚拟地址空间大小；缺点是查表很慢，每次都需要搜整个表

#### 页面置换算法

- 颠簸（Thrashing，抖动）
  虚拟内存中，页面在内存与磁盘之间频繁调度，使得调度页面所需的时间比进程实际运行的时间还多，这样导致系统效率急剧下降，这种现象称为颠簸或抖动。

为了避免这种现象的发生，要使用合适的页面置换算法，减少页面在磁盘和内存之间的交换次数

**几种算法：**

- **最佳页面置换算法：**

  置换以后不再需要的或最远的将来才会用到的页面；效果最好，但无法实现。

  因为操作系统无法知道各个页面下一次将在什么时候被访问。作为一种标准来衡量其他算法的性能  

- **先进先出置换算法（FIFO）：**

  维护一个所有当前在内存中的页面的链表，最新进入的页面放在表尾，最早进入的页面放在表头。

  几乎没有考虑页面的使用频率，会淘汰频繁使用的页面

- **第二次机会算法（second chance）：**

  在FIFO的基础上考虑了R位。即，如果队首元素的R位为1，则说明其被访问过，则把他入队尾并置R=0；如果R=0，则置换。

- **时钟页面置换算法：**

  是第二次机会算法的一个更好的实现。

  考虑第二次机会算法把队首元素放到队尾这一操作，可构造一个环形队列，每次把队首指针后移即可。因工作起来像一个表盘得名

- **改进型时钟算法：**

  在考虑访问的基础上额外考虑了页面载入内存后是否被修改的问题：优先替换掉被没有修改的（因为写磁盘操作耗时长，在内存中的页面可能多次被修改，尽可能减少写入次数，因此修改标记为1的页面被置换的优先级更低）

  使用（R，M）两个标记位

  ![image-20210615222456694](https://github.com/cat538/images-auto/raw/main/img/image-20210611172400973.png)

- **最近最少使用（LRU）：**

  理论上维护一个链表，每次访存把访问的页面放到队首，置换的时候把队尾置换即可

  <img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612155920778.png" alt="image-20210611102341015" style="zoom:50%;" />

- **最不经常使用算法（NFU）及其改进：**

  <img src="https://github.com/cat538/images-auto/raw/main/img/image-20210611111227775.png" alt="image-20210611102656769" style="zoom:50%;" />

- **工作集页面置换算法：**

  <img src="https://github.com/cat538/images-auto/raw/main/img/image-20210611174233968.png" alt="image-20210611110011573" style="zoom: 50%;" />

  <img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612154002177.png" alt="image-20210611110042306" style="zoom: 50%;" />

**工作集时钟和工作集：**

前者在扫描到一个不在工作集中的页面的时候，并不直接替换，而是先判断其M位是否为1，如果为1，则说明其被修改过，先把其写回，继续扫描。因为，毕竟有可能存在一个旧的且干净的页面可以立即调用。（**利用了扫描页表和写回页表操作可以并行**）

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210611173558359.png" alt="image-20210615234804711" style="zoom:50%;" />



<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612155027584.png" alt="image-20210611111227775" style="zoom:50%;" />

#### 页面尺寸问题  

- 小页面：内碎片更小，浪费更少；但是意味着更多的页面$\Longrightarrow$更大的页表&TLB每个表项映射更小的内存，交换效率低
- 大页面：充分利用TLB表项，内存与磁盘交换效率更高（交换单位为页）；但是意味着更大的内碎片



假设s为进程平均大小，每个页表项需要e个字节，页面大小为p字节

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612173342464.png" alt="image-20210611172400973" style="zoom:50%;" />

求导可以解出最优页面大小  $p = \sqrt{2se}$  

#### 清除策略

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612155847757.png" alt="image-20210611173558359" style="zoom:50%;" />

#### 锁定

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612173738152.png" alt="image-20210611174233968" style="zoom:50%;" />



### 分段存储

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612174341908.png" alt="image-20210612154002177" style="zoom:50%;" />

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612212107186.png" alt="image-20210612155027584" style="zoom: 50%;" />

#### 分段和分页的对比：

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612204435047.png" alt="image-20210612155112652" style="zoom: 67%;" />

#### 段页式实现：

- MULTICS  

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612155112652.png" alt="image-20210612155920778" style="zoom:50%;" />

- 基于x86

不同于MUTICS中每段中都有一个页表，基于X86的实现中只有一张页表

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612211644255.png" alt="image-20210612155847757" style="zoom:50%;" />

# 第3章	文件

## 如何为文件分配磁盘

### 连续分配

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612212332372.png" alt="image-20210612173342464" style="zoom:50%;" />

### 链表分配

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612204341805.png" alt="image-20210612173738152" style="zoom:50%;" />

### FAT分配

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612215110538.png" alt="image-20210612174341908" style="zoom:50%;" />

**缺点：**

- 必须把整个表都存放在内存中
- FAT的管理方式不能较好地扩展并应用于大型磁盘中（对于大磁盘，FAT将变得很大）

## 链接

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613214825218.png" alt="image-20210612200432110" style="zoom: 50%;" />

### 硬链接

- 目录项直接指向要共享文件的i结点

### 软连接

- Create一个链接文件：文件数据块中存放的内容是另一文件的路径名的指向

- 可以跨操作系统、文件系统

### 两种链接方式对比

- **硬链接对比软链接的优点：**节省资源，不需要额外的磁盘访问；相比之下，符号链接则需先读取链接文件内容，再根据其内容一步步找到共享文件所在位置。
- **软链接对比硬链接的优点：**符号链接可以跨操作系统，甚至可以通过Internet。硬链接仅限于指向其自己分区中的文件。

## 文件系统

操作系统中负责管理和存储文件信息的软件机构称为[文件管理系统](https://baike.baidu.com/item/文件管理系统/8164847)，简称文件系统。文件系统由三部分组成：文件系统的接口，对对象操纵和管理的软件集合，对象及属性。

### 日志结构文件系统

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612220743798.png" alt="image-20210612204341805" style="zoom:50%;" />

### 日志文件系统

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612220815524.png" alt="image-20210612204435047" style="zoom:50%;" />

## 磁盘空间管理

### 块大小

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612215102405.png" alt="image-20210612212107186" style="zoom:50%;" />

### 空闲块管理

#### 空闲块表

用一张表记录磁盘中所有的空闲块，这张表大部分存储在磁盘中，在内存中保留表的一个块大小（书上：指针块）用于检索。

表的每一项包括空闲块的起始地址和块数（这样方便表示连续空闲块）

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607162004691.png" alt="image-20210612211644255" style="zoom:50%;" />

#### 位图

相比空闲表占用更少的内存

### 磁盘配额

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613220437742.png" alt="image-20210612212332372" style="zoom:50%;" />

## 文件系统备份

- 物理转储

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613220220024.png" alt="image-20210612220743798" style="zoom:50%;" />

- 逻辑转储

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613221559301.png" alt="image-20210612220815524" style="zoom:50%;" />



## 文件系统的性能

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613220922547.png" alt="image-20210612215102405" style="zoom:50%;" />

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613222947370.png" alt="image-20210612215110538" style="zoom:50%;" />

# 第4章	IO

## I/O的管理的目标和任务  

- 按照用户的请求，控制设备的各种操作，完成I/O设备与内存之间的数据交换，最终完成用户的I/O请求。
  - 设备分配与回收 
    - 记录设备的状态  
    - 根据用户的请求和设备的类型，采用一定的分配算法，选择一条数据通路  
  - 执行设备驱动程序，实现真正的I/O操作  
  - 设备中断处理：处理外部设备的中断  
  - 缓冲区管理：管理I/O缓冲区  

- 建立方便、统一的独立于设备的接口  
  - 方便性：向用户提供使用外部设备的方便接口，使用户编程时不考虑设备的复杂物理特性 
  - 统一性：对不同的设备采取统一的操作方式，即在用户程序中使用的是逻辑设备（屏蔽硬件细节  ）
- 充分利用各种技术（通道，中断，缓冲，异步I/O等）提高CPU与设备、设备与设备之间的并行工作能力，充分利用资源，提高资源利用率
  - 并行性
  -  均衡性（使设备充分忙碌）
- 保护数据
  - 设备传送或管理的数据应该是安全的、不被破坏的、保密的  

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613222211587.png" alt="image-20210613214825218" style="zoom:67%;" />

## 磁盘

### 磁盘结构

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613224800498.png" alt="image-20210607162004691" style="zoom:67%;" />

> - 一个255GB大小的磁盘有65535个柱面，每个柱面255个扇区。每个扇区512字节。这个磁盘有多少盘片和磁头？假设平均寻道时间为11ms,平均旋转延迟为7ms,读取速度100MB/s,计算从一个扇区读取400KB需要的平均时间。
>
> - **解：**$磁头数=  255 GB /（65536 * 255 * 512）= 16$
>
>   $磁头数 = 盘面数 = 盘片数*2\Longrightarrow盘片数 = 8$
>
>   读取操作完成的时间 = 寻道时间+旋转延迟+传输时间，寻道时间为11ms，旋转延迟为7ms，传输时间为4ms

### 磁盘低级格式化

- 柱面斜进：斜进距离应当为磁盘臂寻相邻道时间*磁盘速度；保证了寻道操作刚好可以到下一磁道0号扇区
- 交错：旋转速度较快，读取速度较慢；因此将逻辑上连续的信息在物理上交错存储，从而给控制器以喘息空间一边将缓冲区复制到主存
- 低级格式化：[前导码 | 数据 | ECC]

### 磁盘臂调度

- 电梯算法：对于任意一组请求，磁盘臂移动次数上界是柱面数的两倍

### 错误处理 

- 坏块的处理：驱动器启用备用扇区：把原本坏块映射到备用扇区，or 移动所有扇区以回避坏扇区（整个磁道仍可以在旋转一周中读出）；

  或者操作系统处理：操作系统获得一个坏扇区列表，操作系统确保不使用这些块即可

- 机械故障引起的寻道错误：机械臂重校准

### RAID

- RAID0，突出并行读写能力

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613225916717.png" alt="image-20210613220220024" style="zoom: 67%;" />

- RAID1 突出容错性，也可并行读（2倍）

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613225937628.png" alt="image-20210613220437742" style="zoom:67%;" />

- RAID2 面向字节，采用汉明码纠错

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613225801784.png" alt="image-20210613220922547" style="zoom:67%;" />

- RAID3 将汉明码变为奇偶校验，仍然可以纠错，且利用率更高
- RAID4 与3类似，但是面向条带。**RAID3和RAID4的缺点在于负责奇偶校验的驱动器负载很大，即使其它驱动器中的一个做了很小的改动，负责校验块的驱动器也要重新计算，写入。**
- RAID5 没有让一个驱动器专门负责校验

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613230653137.png" alt="image-20210613221559301" style="zoom: 67%;" />

- RAID6 比RAID5多使用一个校验块。写代价更高，但是纠错能力更强

## 硬件

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613231402475.png" alt="image-20210613222211587" style="zoom:50%;" />

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210330214940360.png" alt="image-20210613222947370" style="zoom:50%;" />

## 中断

- 轮询：CPU只能顺序执行任务，必须等待缓慢的IO操作，无法多道程序并行
- 中断：提高了CPU利用率，但是在多级流水线的CPU中，为维持精确中断要很大开销（下图a位精确中断，b为不精确）

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210607215823335.png" alt="image-20210613224800498" style="zoom: 67%;" />

- DMA（Data Memory Access）：

  CPU对DMA编程。DMA完成任务后通过中断通知CPU

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210402165130297.png" alt="image-20210613225801784" style="zoom:67%;" />

DMA两种使用总线的方式：

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210402171355110.png" alt="image-20210613225916717" style="zoom: 67%;" />

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210609230550547.png" alt="image-20210613225937628" style="zoom: 67%;" />

## 设备驱动程序

### 驱动程序功能

- 接收来自**与设备无关的软件**所发出I/O请求，并执行（**上层对下层调用**）
- 接收设备的请求（来自中断），并处理（**下层通知上层**）
- 驱动程序必须对设备进行初始化  
- 对电源需求和日志事件进行管理  
- 驱动程序在运行过程中有可能自身会被再次调用：因此必须可重入

**一个典型结构：**

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210612200432110.png" alt="image-20210613230653137" style="zoom: 67%;" />



### 宏内核与微内核中的驱动程序

- 宏内核中：
  - 最早期UNIX：驱动程序在内核中，这样效率更高，但是更混乱，且每加入一个设备都需要重新编译内核
  - 驱动程序单独编译：需要的时候内核动态装入，需要内核中有一个程序专门管理驱动程序；但有些特定的驱动程序还是需要重新编译内核。
- 微内核中：驱动程序运行在用户空间



## 与设备无关的I/O软件

与设备无关的软件的基本功能是执行对所有设备公共的I/O功能，并且向用户层软件提供一个统一的接口，如系统调用`Read`，`Write`等。

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210402165351254.png" alt="image-20210613231402475" style="zoom: 67%;" />

## 用户空间IO软件

- 库函数等组成：如C库中的`read`，`write`等（**与设备无关IO软件中的read，write系统调用区分**）
- 假脱机系统spooling（Simultaneous Peripheral Operation On-Line）：

## IO控制器

<img src="https://github.com/cat538/images-auto/raw/main/img/image-20210613220055811.png" alt="image-20210613220055811" style="zoom:50%;" />
