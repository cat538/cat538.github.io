# DISC : A Dynamic Shape Compiler for Machine Learning Workloads

阿里的工作，基于 MLIR 支持动态形状，发在 21年 EuroMLSys 类似的工作有 Nimble， Nimble 用的是 VM 方案

## 0. Abstract
许多 ML 模型都有动态形状特征。 然而，现有的 MLC 优化系统受到动态形状模型带来的很多问题的困扰，包括编译开销、内存使用、优化管道和部署复杂性。 本文提供了DISC，一个编译器系统来原生支持动态形状工作负载的优化。 DISC 丰富了一组 IR 以形成完全动态的形状表示。 它在编译时生成运行时流，以支持处理基于动态形状的逻辑，避免了运行时的解释开销，扩大了主机-设备协同优化的机会。 它通过形状传播和约束收集方法解决了动态形状的核融合问题。 **这是第一项演示如何基于 MLIR 基础设施构建端到端动态形状编译器的工作**。 实验表明，DISC 的加速比 TensorFlow/PyTorch 最高可达 3.3 倍，比 Nimble 最高可达 1.8 倍。

!!! warning "疑问"
    什么是在编译时生成运行时流？

## 7. Conclusion
DISC 解决动态形状优化问题。 它演示了如何构建基于 MLIR 的编译器系统。 DISC 补充 HLO 形成 DHLO——一种完全动态的形状表示， 作为支持通用 ML 框架的 hub IR。 运行时流程，包括 形状推断、 缓冲区管理 和 主机端控制 ， 由编译器生成。 这是一种旨在减少解释开销并丰富 host-device-joint 优化机会的新尝试。 通过 **形状传播** 和 **形状约束收集**， DISC 在没有完整形状信息的情况下应用高效的核融合优化。 实验表明，DISC 以 1.8 倍的加速比优于最先进的解决方案。

## 1. Intro
DL 工作负载受动态形状影响最大的操作是那些具有小规模计算的操作，例如 element-wise 操作 和 reduction 操作。 传统技术，如 XLA[5]，通常采用融合方法来减少片外内存访问和此类操作的频繁内核启动开销。 然而，现有的内核融合引擎只能生成具有在编译期间推断出的静态形状信息的 kernel 。 这导致融合引擎将为每个新出现的形状编译和生成内核，即使它们中的一些共享相同的计算模式。 当形状数量很大时，它会导致严重的编译开销。 由于这个原因，XLA 通常对动态形状工作负载关闭，以防止负优化。

请注意，像 GEMM/Conv 这样的大型操作不会受到动态形状的影响，因为它们通常会通过库调用（cuDNN、cuBLAS、oneDNN）而不是编译优化。 **我们在本文中关注小型操作优化目标**。

有一些基于 XLA 的动态形状问题的变通解决方案。 开发人员只能将具有静态形状的操作聚类以供 XLA 优化，并让具有动态形状特征的操作在不融合的情况下运行。 这在一定程度上失去了优化机会。 此外，一些工作负载在实践中只有动态形状的操作。 另一种解决方法是使用填充和切片将张量形成特定形状，这会引入冗余计算并可能导致负优化。

MLIR[12] 为新的机器学习编译器提供了基础设施。 它为新功能带来了高扩展性和对现有优化构建的兼容性。 同时，其设计理念自然支持动态形状优化。 然而，它带来的是基础设施，而不是动态形状问题本身的解决方案。 Nimble[15] 是一个基于 TVM 的编译框架，用于解决动态形状问题，它是与 DISC 的并行工作，DISC 有一个更早的 RFC 版本[7]。 它提供了一个编译器框架，能够在运行时适应动态形状的操作。 运行时控制逻辑是作为 VM 组件预先构建的。 Nimble 的一个问题是，它将运行时控制预先构建为 VM，这就失去了探索主机设备协同优化的机会。 同时，VM 方法带来了解释开销。

我们提出 DISC，一种用于机器学习工作负载的动态形状编译器。 我们基于 MLIR 基础设施构建 DISC，以从高级设计角度利用其对动态形状的原生支持。 DISC 解决了动态形状优化的几个主要问题。

1. 缺乏对现有 IR 的动态形状计算的完整表示。 请注意，MLIR 不直接提供动态形状 IR 表达式。 我们不会从头开始构建一套新的 IR，而是在 HLO 方言的基础上引入 DHLO，该 IR 已经在 XLA 中使用。 这种方法使我们能够重用 XLA 和 MLIR-HLO 方言的一些现有构建块。

2. 构建高效的运行时流程以支持动态形状逻辑。 我们不是在运行时构建 VM 来解释动态形状流，而是在编译时即时生成运行时流的代码。 这避免了 VM 的解释开销。 同时，这种方法扩大了主机设备协同优化的机会，因为 DISC 将设备计算和主机端逻辑一起编译。

3. 在不知道完整形状信息的情况下生成有效的融合核。 我们检查具有两个收集特征的两个操作的形状兼容性。 我们首先利用生产者和消费者之间的形状传播属性来融合相邻的操作。 此外，我们在将计算图降低到 DHLO 时收集形状约束。 额外的形状约束信息使我们能够形成更大范围的融合，以进一步减少片外内存访问和内核启动开销。

4. 最后，DISC 以 DHLO 为中心支持多种机器学习框架（TensorFlow 和 PyTorch）。 同时，DISC 支持静态和动态优化的混合。 当 DISC 发现具有静态形状的子图时，它将回退到静态优化以获得更好的性能。

实验结果表明，DISC 优于 Tensor-Flow/PyTorch，6 个流行模型的平均加速比为 2.27 倍，Transformer 的平均加速比为 1.8 倍。

**贡献**：

- 这是第一项演示如何使用MLIR 基础结构高效地构建支持动态形状的编译器的工作。
- 它提出了一种通过设计完全动态的IR 和编译时生成的运行时流程来支持动态形状处理的方法。
- 它解决了没有完整形状信息的融合问题，特别是使用额外的形状约束收集方法。
- 它支持多种机器学习框架和静态/动态优化的混合。

## 2. Background
现代机器学习模型的计算图由计算和内存密集型操作组成。 在本文中，我们将 GEMM 和 Conv 称为计算密集型运算，将其他运算称为内存密集型运算。 计算密集型操作通常在流行的机器学习框架中使用预构建库调用，例如 cuDNN 和 cuBLAS。 内存密集型操作通过具有内核融合和代码生成技术的 MLC 进行优化。 请注意，单个内存密集型操作（如 Add 操作）的权重太轻，无法为其构建库。 同时，内存密集型操作的组合在不同的工作负载中有所不同，并且为此类操作预构建融合内核是不可行的。

**面向静态形状的编译器**。 我们采用 XLA[5]，用于内存密集型操作的最先进的编译器优化引擎，来解释静态形状编译器的工作原理。 给定一个计算图，XLA 首先将其转化为 HLO IR。 然后它找到可以融合在一起的操作并生成融合内核，这些内核将根据融合模式进行缓存。 融合模式包含具有完整形状信息的操作序列。 当 XLA 遇到一个融合模式时，它会首先检查这个模式是否已经被缓存了。 如果命中，它将直接使用二进制文件，否则它将针对新模式进行编译并缓存编译结果。

**缺乏对动态形状的关注**。 XLA 的过程适用于静态形状场景，但对于动态形状工作负载效率较低。 一个典型的例子是具有不同输入/输出序列长度的 Seq2seq 模型。 虽然计算图没有变化，但 XLA 需要为不同长度的样本重新编译融合内核。 当形状数量很大时，编译时间和主机/设备内存使用缓存的开销使得面向静态形状的编译不可用。 其他遭受动态形状问题困扰的典型工作负载包括处理不同图像大小的 CV 工作负载（如对象检测），以及使用 Unique[4] ops 生成具有不同形状的输出张量的稀疏工作负载。

DISC 生成适应任何即将出现的形状的融合内核，并避免重新编译。 基本的见解是我们不需要考虑形状信息来检查两个融合模式是否相同以进行代码生成。 请注意，**DISC 仅针对具有静态 rank 的动态形状，因为我们没有发现动态 rank 是一种流行的行为**。

**MLIR 基础设施** 我们基于 MLIR 基础设施[12]构建 DISC，旨在帮助构建可重用和可扩展的编译器基础设施。 我们选择 MLIR，因为它对扩展是开放的，并且可以适应基于具有方言转换的其他 IR 的现有优化。 具体来说，它允许通过将 MLIR-HLO 方言降低到 HLO 来重用 XLA 的现有优化组件。

MLIR 只是 IR 框架，本身不提供解决动态形状操作优化等问题的方法。 DISC 展示了一种构建完整优化系统的方法，该系统以 MLIR 的动态形状工作负载为目标。


## 3. Overview of DISC
<div class="autocb" style="text-align:center;"><img src="./paper-disc.assets\autocb_0.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

DISC 的第一个组件是 computation graph bridging ， 它将用 DL 框架描述的计算图降低到 DISC 中使用的 hub IR（第 4.1 节）。 DISC 还在这一层收集形状约束信息，以帮助进行融合优化（第 4.2.1 节）。

中心 IR DHLO，从 HLO 方言扩展而来，以支持完全动态的形状。

动态形状工作负载的基本执行流程是在没有完整形状信息的情况下进行编译，并在运行时获取形状信息。 DISC 在编译时将形状计算和数据处理分开。 它符合形状计算逻辑并对其进行代码生成。 放置器组件将形状计算逻辑放在主机端，将张量计算内核放在设备端。 生成的形状推理函数将在执行模型时在主机端处理。

缓冲区管理组件管理计算图中张量的缓冲区生命周期。 DISC 在编译时生成有关缓冲区分配、重用和释放逻辑的代码，并在运行时执行编译后的流程。 基本的优化规则是一旦没有用户就释放缓冲区，并根据“形状兼容性”尽可能多地重用缓冲区。

主机端控制负责外部库降级、内核启动管理、设备管理以及编译引擎与AI框架的交互

## 4. System Design
动态形状编译器的第一个问题是，它缺少 IR 表达。 我们扩展 HLO ， 引入 DHLO 作为 IR 以支持完整的动态形状特征 (4.1)。 以 DHLO 作为中心 IR，DISC 可以支持多个前端和后端（4.4）。 为了满足动态形状支持的运行时要求，DISC 生成运行时流（4.2）以避免解释开销。 最后，DISC 分析形状提示以支持融合优化 (4.3)。

### 4.1. DHLO: IR Supplementation
MLIR 基础设施灵活且易于扩展以支持多种功能。 然而，它只提供基础设施而不具体方法来直接支持动态形状。 我们选择 HLO IR 为动态形状问题构建 MLIR dialect，因为 HLO 已经支持许多操作描述和不同的框架。 HLO 是为静态形状编译器优化而设计的，在某些情况下缺乏对动态形状的表达能力。 作为解决方案，我们使用一组 IR supplementation 扩展 HLO 并引入 DHLO。

IR supplementation 的见解是将编译时常量折叠替换为运行时张量数据流。 具体来说，要扩展 IR 表示的目标操作是那些在 HLO 中具有常量折叠属性的操作，如 slice、pad、broadcast 等。 在 DHLO 中，我们用张量参数替换常量属性以支持动态形状行为。 

<div class="autocb" style="text-align:center;"><img src="./paper-disc.assets\autocb_1.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

以 slice[6] 为例，如图 2 所示。slice op 从给定边界框索引的输入张量中提取子张量。 在 HLO 中，边界框的索引在编译时是常量（图 2 中所示的 `start_indices`、`limit_indices` 和 `strides`）。 但是，这些索引的形状因动态形状工作负载而异，并且常量折叠表达式是不可行的。 相反，我们将边界框的索引定义为切片的张量参数。 这种扩展适用于动态形状场景，因为张量值是在运行时生成的。

请**注意**，DHLO 只是一个扩展，并不能替代整个 HLO。 由于对于许多操作，如元素添加/乘法等，它们在 HLO 中的定义具有足够的表现力来支持动态形状，我们将它们保持原样。

### 4.2. Generated Runtime Flow
动态形状编译器的一个挑战是，**编译是一个静态动作，而我们的目标是处理动态行为**。 XLA 需要在编译前了解所有形状信息， 在编译时静态生成代码**并构建缓冲区管理 和 内核启动序列**。 如果没有预先知道的形状信息，此编译过程将不起作用。

动态形状编译器需要生成自适应处理运行时遇到的任何形状的代码。 Nimble[15] 设计了一个 VM 来解释具有动态形状的图形计算的运行时流程。 它解释张量形状并自适应地组织运行时逻辑。 **DISC 不使用解释器，而是编译并生成主机和设备端的计算代码，以及运行时流程（缓冲区管理、内核启动等）。 运行时流程的编译器方法减少了 Nimble 中 VM 解释的开销**。

#### 4.2.1. Adaptive Shape Inference
DISC 中的形状推断组件有两个阶段。 第一个是在不知道特定形状值的情况下在编译时识别形状约束。 第二个是**发出运行时代码来计算给定输入张量的特定形状值**。 前者用于代码生成优化，后者用于正确执行。

**<u>形状约束</u>**

编译时没有具体的形状值，我们就失去了一些优化机会。 这是当前动态形状相关编译器技术的常见问题。 DISC 表明，我们仍然可以获得一些额外的形状约束信息来帮助生成高效的内核。

DISC 探索两种形状约束。 第一个称为**维度大小相等约束**。 这种约束揭示了张量的某一维度数是否等于同一张量的另一维或另一个张量的任意维。 第二个称为**张量大小相等约束，它揭示了两个张量是否具有相同数量的元素**。 这种形状约束在 IR 优化和代码生成阶段都很有用。 IR 优化阶段的一个优化案例是，当我们知道两个 ops 操纵具有相同或兼容形状的张量时，我们可以决定将它们融合在一起。 在代码生成阶段，这些约束可以实现更积极的索引计算简化。

!!! warning "疑问"
    在 Nimble 中缺少这种约束信息， 因此阻止了进一步优化？


DISC 从两个来源收集形状约束。 在第一种情况下，我们推断由 DHLO 操作语义捕获的形状约束。 例如， `TransposeOp` 的输入张量和输出张量应具有相同的张量大小。 类似地，根据 op 定义，AddOp 的输入张量和输出张量应该具有相同的形状。 在第二种情况下，我们从框架中收集高级操作捕获的形状约束，并将这些信息注入计算图桥接中的 DHLO。 以Tensorflow中的 `SplitOp` 为例。 它沿一个维度均匀地划分一个张量，这意味着该运算的所有输出都具有相同的形状。 一个 `TF.SplitOp` 会被降级为多个独立的 `DHLO.SliceOp` ，它们实际上具有相同的形状。 然而，这种信息在没有明确的形状约束的情况下被降低到 DHLO 后会丢失。


**<u>Shape calculation</u>** 

与静态形状编译器只需要自己生成常量折叠形状信息的计算代码不同，DISC 分别生成形状推理和核计算子图的代码。 形状计算计算是轻量级的，DISC将其放在主机端（CPU），而子图操作张量放在设备端（GPU）。 布局逻辑与 Nimble[15] 类似。 不同之处在于，DISC 采用编译的方式将计算、形状推断和放置逻辑的代码一起生成，而不是像 Nimble 那样使用预先构建的 VM 解释器来进行运行时控制。 这避免了额外的解释开销。 同时，这种方法带来了主机端和设备端联合优化的机会。

#### 4.2.2. Dynamic Buffer Management
通过发出的代码在运行时计算每个缓冲区的形状，DISC 通过发出 `alloc` 和 `dealloc` 指令来动态管理缓冲区。 对于旨在减少缓冲区分配开销的缓冲区优化的考虑，我们采用两种方法：

1. 基于IR中的形状约束，进行缓冲区活性分析和优化；
2. 使用 cached allocator 降低 `alloc` 和 `dealloc` ，在我们的例子中这是 TensorFlow/PyTorch 提供的分配器。

#### 4.2.3. Host-side Control
主机端代码在统一的编译器流程中发出，从而可以在后续 pass 进行联合优化。 除了形状计算，还包括启动维度计算、内核启动、供应商库调用和设备管理指令，如初始化、同步、cubin 加载等。

### 4.3. Fusion and Code Generation
内存绑定操作的内核融合是当前 DLC 的主要优化之一。 一种常见的融合策略是允许将具有相同数量元素的内存绑定操作融合在一起。 但是，对于动态形状场景，在编译时不知道要处理的张量形状。 确定哪些操作可以融合在一起以获得性能优势并非易事。

**<u>Shape hints collection</u>** 我们通过两个提示确定两个操作是否具有相同的形状。 第一个是形状传播。 例如 Add op 的操作数必须与 Add 的消费者具有相同的张量形状。 DISC **维护一个表来指示每个操作的传播属性**。 具体来说，某些操作可能具有相同的形状传播属性，例如 Add 和 Sub。 我们根据表中的形状传播属性对操作进行分类，以避免重复枚举。 第二个是形状约束 DISC 收集，如 [4.2.1. 节](#421-adaptive-shape-inference)所述。 

**<u>Shape-adaptive fusion configuration</u>** 对于内存绑定模式的融合代码生成，我们倾向于选择对各种形状友好的模板，例如经典的循环融合和以 reduce 操作为 root 的输入融合。 然而，为了获得更好的性能，仍然有一些方面需要对不同的运行时形状做出不同的反应，比如启动维度的选择、是否进行循环矢量化加载/存储的决定，以及是否需要隐式广播等。对于这些方面，我们 生成不同版本的内核，并从主机端生成选择逻辑，以便在运行时为每个传入的形状启动适当的内核。

### 4.4. Multiple Framework Support
DISC 能够服务于多种 DL 框架，如 TensorFlow、PyTorch 等。 同时，静态和动态形状编译器都可以降低它。 我们使用 DHLO 作为 hub IR 将不同的部分连接在一起。 这个中间层简化了适配。

具体来说，DISC 不会将所有计算图降低到动态形状编译器。 相反，当形状在编译时已知或形状数量可接受时，它会将计算图降低为静态形状编译器。 这是因为静态形状编译器引擎通常可以通过丰富的信息获得比动态形状编译器更好的性能。

### 4.5. Static Shape Library Support
对于计算密集型操作，不同的形状可能需要不同的优化来实现最佳性能。 **Nimble[15] 选择在一组固定形状下调整内核**。 内核保证可以在其他形状上工作，但性能可能不是最好的。 为了平衡动态性和性能，我们实现了一个接口来根据不同的运行时形状从库中选择最佳内核。 该库包含供应商库（例如 cuBLAS/cuDNN） 和 针对每种形状手动调整的预生成内核。

## 5. Evaluation
### 5.2. Comparing with Nimble
我们用 Transformer 与 Nimble 进行比较。 表2 显示了计算密集型操作、内存密集型操作和 CPU 时间的性能分解。 请注意，我们在 Nimble 实现中使用 `cuDNN`/`cuBLAS` 库调用来进行计算密集型操作，而不是内核调优，因为我们没有找到 Nimble 报告中描述的计算密集型操作调度的开源代码。

<div class="autocb" style="text-align:center;"><img src="./paper-disc.assets\autocb_2.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

它表明 DISC 仅对内存密集型操作实现了 2.61 倍的加速，这是整体加速的主要原因之一。 **DISC 的优势在于，它从 形状传播 和 形状约束 中收集形状提示，以帮助进行有效的融合**。 形状自适应融合配置策略进一步有助于整体性能。

DISC 的另一个优势是低开销的运行时流程。 表2 显示 DISC 的 CPU 时间仅为 Nimble 的 36.6%。 CPU 时间的一小部分减少来自内核启动的减少，因为 DISC 用到的内核总数略有减少(表3)。 主要原因来自于， DISC 通过主机和设备协同优化生成更高效的运行时流程。

### 5.3. Gap to Static Optimization
DISC 可以自动回退到静态编译器以获得更好的性能。 为了评估使用静态编译器的动态编译器的性能，我们禁用回退功能，并比较静态和动态编译器与静态输入的 3 个典型工作负载的性能。

它表明，与静态优化相比，DISC 平均实现了 85% 的性能，范围从 74.5% 到 91.4%。 差距的原因之一是**它缺乏一些没有形状信息的融合优化机会（例如更积极的图形优化、融合决策和代码生成策略等）**，即使我们已经使用 DISC 收集了形状提示。

## 6. Related Work
有许多工作将 内核融合优化 应用于 ML 中的小型内核。 XLA[5] 将内核与一组操作规则即时融合，包括 逐元素操作 和 约简操作。 `FusionStitching`[19] 扩展了 JIT 融合的目标范围，在操作之间重用中间值。 一些主要针对大型计算密集型操作的作品[9,11,17,18]也具有针对小内核的融合能力。 这些技术适用于静态形状场景，并且在动态形状工作负载中会产生更严重的编译开销。

惰性编译 [2,14] 在未知形状有限是可以用来减少编译开销。 然而，它失去了部分核融合优化的机会，并且在未知形状过多时无法应用。

Nimble[15] 通过构建基于 TVM 的编译器系统解决了动态形状问题。 它提出了一种在运行时解释动态形状处理流程的 VM 方法。 相反，DISC 在编译时生成运行时流以避免解释开销，并提供更多主机设备协同优化的机会。 同时，与 Nimble 相比，DISC 更注重内存密集型融合。

IREE[1] 是一种基于开源 MLIR 的端到端编译器，可将 ML 模型降低为针对异构硬件加速器的实时移动/边缘推理优化的统一 IR。 IREE 为编译后的 ML 模型提供了灵活的部署解决方案，但仍处于早期阶段。