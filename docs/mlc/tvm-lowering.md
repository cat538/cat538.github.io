# TVM-lowering
> Ref:
>
> - [TVM è‡ªåº•å‘ä¸Šï¼ˆäºŒï¼‰ï¼šTIR çš„æ¦‚å¿µå’Œç¼–è¯‘åŸç†](https://zhuanlan.zhihu.com/p/533161438)
> - [ã€ä»é›¶å¼€å§‹å­¦æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨ã€‘å››ï¼Œè§£æTVMç®—å­](https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&mid=2247494373&idx=1&sn=6eb14998e8cfe45a144ba1b8c61346ac&chksm=9f835073a8f4d96555ed6382f25d8b5793e7b56da0f403867b7a38c48bbeedc23701c2e59721&scene=178&cur_album_id=1799364124980609027#rd)
> - [ã€ä»é›¶å¼€å§‹å­¦æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨ã€‘å…­ï¼ŒTVMçš„ç¼–è¯‘æµç¨‹è¯¦è§£](http://giantpandacv.com/project/%E9%83%A8%E7%BD%B2%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/%E3%80%90%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E3%80%91%E5%85%AD%EF%BC%8CTVM%E7%9A%84%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3/)
> - [TVM å­¦ä¹ æŒ‡å—ï¼ˆä¸ªäººç‰ˆï¼‰](https://mp.weixin.qq.com/s/NM5yvxW2JSbR06RmrR3ubw)


## 1. Lower Tir

> TIRä¸€èˆ¬è®¤ä¸ºæ˜¯ target irï¼ŒTensorIRæ˜¯åé¢åˆæçš„æ–°æ¦‚å¿µï¼Œåšä¸ºtvm scriptçš„ä¸€éƒ¨åˆ†ã€‚

è¿™èŠ‚ç”¨ä¸€ä¸ªä¾‹å­è¿½è¸ª tir è¡¨ç¤ºçš„ PrimFunc æ˜¯å¦‚ä½•ç»è¿‡ target translation è¢«ç¿»è¯‘ä¸ºç‰¹å®štargetçš„ä¸€ä¸ª `runtime.Module`

ä½¿ç”¨çš„ä¾‹å­ä»£ç å¦‚ä¸‹ï¼š

```py
import tvm
from tvm import te
SIZE = 1024

# 1. ä½¿ç”¨ TE å£°æ˜è®¡ç®—
# mm
k = te.reduce_axis((0, SIZE), 'k')
A = te.placeholder((SIZE, SIZE), name='A')
B = te.placeholder((SIZE, SIZE), name='B')
C = te.compute((SIZE, SIZE), lambda x, y: te.sum(A[x, k] * B[k, y], axis=k), name='MM')
# relu
D_IN = te.placeholder((SIZE, SIZE), name='RELU_IN')
D_OUT = te.compute((SIZE, SIZE), lambda i, j: te.max(D_IN[i, j], 0), "RELU_OUT")

# 2. ä» TE åˆ›å»º PrimFunc 
te_mm: tvm.tir.PrimFunc = te.create_prim_func([A, B, C]).with_attr({"global_symbol": "mmult"})
te_relu: tvm.tir.PrimFunc = te.create_prim_func([D_IN, D_OUT]).with_attr({"global_symbol": "relu"})

# 3. å°†åˆ›å»ºå‡ºæ¥çš„ PrimFunc æ·»åŠ åˆ°ä¸€ä¸ª IRModule ä¸­
ir_m: tvm.IRModule = tvm.IRModule({'mm': te_mm})
gv_relu = tvm.ir.GlobalVar("relu")
ir_m.update_func(gv_relu, te_relu)
print(ir_m.get_global_vars())
# è¿™é‡Œä¹Ÿå¯ä»¥ä½¿ç”¨ å…ˆæ„å»º Scheduleï¼Œ å†è°ƒç”¨ `tvm.lower` çš„æ–¹æ³• å¾—åˆ°ä¸€ä¸ª IRModule
# te_sch: te.Schedule = te.create_schedule(C.op) # C.op: te.tensor.ComputeOp
# ir_m: tvm.IRModule = tvm.lower(te_sch, [A, B, C], simple_mode=True,name='mmult')

# 4. Lower and Build
''' åœ¨è¿™ä¸€æ­¥å°† IRModule ==> runtime.Module'''
rt_m: tvm.runtime.Module = tvm.build(ir_m, target='llvm', name='func_set')

print(f"\033[31mtvm.build\033[0m: {type(ir_m)} \033[31m==>\033[0m {type(rt_m)}")

# print IRModuleï¼Œ å…¶ä¸­åŒ…å«ä¸€ä¸ª PrimFunc
# print(f"\033[31mAfter lowering, the IRModule\033[0m:\n{ir_m}")
ir_m.show()

# # print source code
# print(f"\033[31msource code\033[0m:\n{rt_m.get_source()}")
```


`tvm.build` å°†ä»£ç ä» IRModule è½¬æ¢æˆ runtime.Moduleï¼› 

- å…¶ä¸­ IRModule å®šä¹‰åœ¨ `include/tvm/ir/module.h` ä¸­ï¼› å¯ä»¥ç®€å•è§†ä½œä¸€ä¸ª `<name, BaseFunc>` çš„å“ˆå¸Œè¡¨(å³å¯åŒæ—¶åŒ…å«`PrimFunc` å’Œ `Func`)
- å…¶ä¸­ runtime.Module å®šä¹‰å¯¹åº”åœ¨ `include/tvm/runtime/module.h` ä¸­ï¼› å¯ä»¥ç®€å•è§†ä½œä¸€ä¸ª `<name, PackedFunc>` çš„å“ˆå¸Œè¡¨ã€‚ `ModuleNode` æ˜¯ä¸€ä¸ªæ¥å£ï¼Œ å¯¹åº”æœ‰å¤šç§ä¸åŒçš„å®ç°ï¼Œ å¦‚ `CUDAModuleNode`ï¼Œ `LLVMModuleNode` ç­‰


ä»¥ä½¿ç”¨teå£°æ˜ è®¡ç®—è¿‡ç¨‹ ä¸ºä¾‹ï¼Œå±•ç¤ºä¸€ä¸ª `te.tensor.ComputeOp` æ˜¯å¦‚ä½•è¢«ç¼–è¯‘æˆ `runtime.Module` çš„ï¼š

1. ä½¿ç”¨teå£°æ˜è®¡ç®—è¿‡ç¨‹
2. ä½¿ç”¨ `te.create_schedule` åˆ›å»ºä¸€ä¸ªSchedule å¯¹è±¡ï¼Œ æ¥ç€ä½¿ç”¨ `te.lower()` å°†ä¸€ä¸ª `te.Schedule` è½¬æˆä¸€ä¸ªIRModuleï¼›

    æˆ–è€…ä½¿ç”¨ `te.create_prim_func` åˆ›å»ºä¸€ä¸ª `tvm.tir.PrimFunc` å¯¹è±¡(å³ MLC è¯¾ç¨‹ ä¸­æ‰€è¯´çš„ä¸€ä¸ª**å…ƒå¼ é‡å‡½æ•°**)ï¼Œ ç„¶åä½¿ç”¨ IRModule çš„æ„é€ å‡½æ•°æŠŠè¿™ä¸ª PrimFunc æ”¾åˆ°IRModule ä¸­

3. æ¥ç€è°ƒç”¨ `tvm.build()` å¯¹ IRModuleè¿›è¡Œæ„å»ºï¼š åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œ IRModule æœ€ç»ˆå°†è¢«è½¬æ¢æˆä¸€ä¸ª `runtime.Module`ï¼› 

    è¿™é‡Œéœ€è¦æ³¨æ„ `tvm.build` å¯ä»¥æ¥å— `Schedule`, `PrimFunc`, `IRModule` ç­‰å¤šç§ç±»å‹ï¼ˆå®é™…ä¸Šéƒ½ä¼šè¢«è½¬æˆ IRModule ç„¶åå†ç¼–è¯‘ï¼‰ä½œä¸ºè¾“å…¥ï¼Œ å¦‚æœä¼ å…¥çš„æ˜¯ä¸€ä¸ª `Schedule` çš„è¯ï¼Œ åˆ™éœ€è¦ä¼ å…¥å‡½æ•°ç›¸åº”çš„è¾“å…¥å‚æ•°åˆ—è¡¨

ğŸ’¡**å› æ­¤æ¥ä¸‹æ¥ä¸»è¦çœ‹ ä½äº `python/driver/build_module.py` ä¸­çš„ `tvm.build` æ–¹æ³•**

---

`tvm.build()` åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤

```py
def build(
    inputs: Union[te.Schedule, PrimFunc, IRModule, Mapping[str, IRModule]],
    args: Optional[List[Union[Buffer, tensor.Tensor, Var]]] = None,
    target: Optional[Union[str, Target]] = None,
    target_host: Optional[Union[str, Target]] = None,
    runtime: Optional["tvm.relay.backend.Runtime"] = None,
    name: Optional[str] = "default_function",
    binds: Optional[Mapping[tensor.Tensor, Buffer]] = None,
):
    if isinstance(inputs, tvm.IRModule):
      input_mod = lower(inputs)
    if not isinstance(inputs, (dict, container.Map)):
      target = Target.current() if target is None else target
      target = target if target else "llvm"
      target_input_mod = {target: input_mod}
    else:
      target_input_mod = inputs

    annotated_mods = {}
    for tar, mod in target_input_mod.items():
      annotated_mods[tar] = mod.with_attr("runtime", runtime)
    
    # çœç•¥ get target_host çš„ä»£ç 
    target_host = "llvm"

    annotated_mods, target_host = Target.canon_target_map_and_host(annotated_mods, target_host)
    rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)
    annotated_mods, target_host = Target.canon_target_map_and_host(annotated_mods, target_host)

    to_return = rt_mod_host
    return OperatorModule.from_module(to_return, ir_module_by_target=annotated_mods, name=name)
```

1. è°ƒç”¨ `python/driver/build_module.py` ä¸­ `lower()`ï¼Œ è¿™æ˜¯ä¸€æ­¥ä½œç”¨æ˜¯æ‰§è¡Œ IRModuleï¼ˆor scheduleç­‰ï¼‰ åˆ° IRModule çš„å˜æ¢ï¼Œæ‰§è¡Œ tir å±‚çº§çš„ target æ— å…³ä¼˜åŒ–ã€‚ å…·ä½“æ¥è¯´ï¼Œ`lower()` ä¸­ä¼šè°ƒç”¨ `ffi.lower_module(inp, simple_mode)`ï¼Œè¿™é‡Œå¯¹åº”åˆ° C++ ä»£ç  `src/dirver/driver_api.cc` ä¸­çš„ `LowerModule` æ–¹æ³•ï¼š

    ```c++
    IRModule LowerModule(IRModule mod, bool simple_mode) {
        Array<transform::Pass> pass_list = CreatePassList(simple_mode);
        return LowerWithPassList(std::move(mod), pass_list);
    }
    TVM_REGISTER_GLOBAL("driver.lower_module").set_body_typed([](IRModule mod, bool simple_mode) {
        return LowerModule(std::move(mod), simple_mode);
    });
    ```

    å¯ä»¥çœ‹åˆ° åœ¨ `LowerModule` é€»è¾‘ä¸­ï¼Œ é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªpass åˆ—è¡¨ï¼Œ åŒ…å«äº†`tir::transform`ä¸­çš„ä¸€äº›å˜æ¢ï¼Œ ç„¶åè°ƒç”¨ `LowerWithPassList` æŠŠåˆ—è¡¨ä¸­çš„ pass åº”ç”¨åˆ°è¯¥ IRModule ä¸­ï¼šå³é¦–å…ˆå°† `pass_list` æ„é€ æˆä¸€ä¸ª `Sequential` å¯¹è±¡ï¼Œ ç„¶åè°ƒç”¨ `SequentialNode::operator()` ï¼Œ 

2. åœ¨ç¬¬ä¸€æ­¥çš„ lowering ä¹‹åï¼Œ`tvm.build()` æ¥æ”¶çš„inputså‚æ•° `Union[te.Schedule, PrimFunc, IRModule, Mapping[str, IRModule]]` è¢«è½¬æˆäº†ä¸€ä¸ª ç»è¿‡åˆæ­¥ä¼˜åŒ–çš„ IRModule ï¼Œ å¹¶æ‰§è¡Œäº† tir çº§åˆ«çš„ target independent ä¼˜åŒ–ã€‚ **æ¥ä¸‹æ¥å°±æ˜¯æ‰§è¡Œä»£ç ç”Ÿæˆçš„å·¥ä½œ**ï¼Œ é¦–å…ˆæ£€æŸ¥ target ç›¸å…³ä¿¡æ¯ï¼Œä¼šæ ¹æ® `tvm.build()` çš„è¾“å…¥è®¾ç½®ç›¸åº”çš„ target, target_host ç­‰å˜é‡

3. åœ¨æ‹¿åˆ° target ç­‰è§„èŒƒæ ¼å¼çš„ä¿¡æ¯ä¹‹åï¼Œä¼šæ‰§è¡Œ`rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)` ï¼Œè¿™é‡Œè°ƒç”¨çš„ `tir_to_runtime` å¯¹åº”åˆ°C++ä¸­çš„ `TIRToRuntime`:

    ```c++
    TVM_REGISTER_GLOBAL("driver.tir_to_runtime")
        .set_body_typed([](const Map<Target, IRModule>& inputs_arg, Target host_target) {
            return TIRToRuntime(inputs_arg, host_target);
        });
    ```

    æ¯”è¾ƒå…³é”®çš„ `TIRToRuntime` é€»è¾‘å¦‚ä¸‹ï¼š

    ```c++
    runtime::Module TIRToRuntime(const Map<Target, IRModule>& inputs_arg, const Target& target_host_arg) {
      std::vector<runtime::Module> device_modules;
      Map<Target, IRModule> inputs = inputs_arg;
      Target target_host = target_host_arg;
      // 1. æ£€æŸ¥å¹¶è®¾ç½®target_host
      // ...
      // 2. éå†è¾“å…¥çš„ {Target: IRModule}
      //  SplitMixedModule å°†ä¸€ä¸ª IRModule åˆ†ä¸º host ä¸ device ä¸¤éƒ¨åˆ†
      //  æ ¹æ® host ä¸ device ä¿¡æ¯æ›´æ–° mhost_all
      IRModule mhost_all = IRModule(Map<GlobalVar, BaseFunc>(),{},{},{},(*inputs.begin()).second->attrs);
      for (const auto& it : inputs) {
        if (it.second.defined()) {
          const auto& [target, ir_module] = it;
          auto& [host_mod, device_mod] = SplitMixedModule(ir_module, target, target_host);

          bool overrides_host_target = target->GetTargetDeviceType() == target_host->GetTargetDeviceType();
          bool non_host_target_kind  = target->kind != target_host->kind;
          if (overrides_host_target && non_host_target_kind)
            device_modules.push_back(codegen::Build(host_mod, target));
          else
            mhost_all->Update(host_mod);

          if (device_mod->functions.size() != 0)
            device_modules.push_back(codegen::Build(device_mod, target));
        }
      }
      // 3. Build host module
      runtime::Module mhost = codegen::Build(mhost_all, target_host);
      for (const auto& it : device_modules)
        if (it.operator->())
          mhost.Import(it);
      return mhost;
    }
    ```

    è¿™é‡Œæ¯”è¾ƒå…³é”®çš„ `codegen::build` åœ¨`src/target/codegen.cc` ä¸­ï¼Œ å®ç°å¦‚ä¸‹ï¼š

    ```c++
    runtime::Module Build(IRModule mod, Target target) {
      auto target_attr_map = tvm::TargetKind::GetAttrMap<FTVMTIRToRuntime>("TIRToRuntime");
      if (target_attr_map.count(target->kind))
        return target_attr_map[target->kind](mod, target);
      
      std::string build_f_name = "target.build." + target->kind->name;
      const PackedFunc* bf = runtime::Registry::Get(build_f_name);
      return (*bf)(mod, target);
    }
    ```

    å¯ä»¥çœ‹åˆ° é€šè¿‡ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥ æ‹¿åˆ° `build_f_name` (ä¾‹å¦‚ target æ˜¯ llvmï¼Œ è¿™é‡Œå¾—åˆ°å°±æ˜¯ "target.build.llvm"ï¼Œ cuda å°±æ˜¯ "target.build.cuda")ï¼Œ æ¥ç€ç”¨è¿™ä¸ªåå­—æŸ¥æ‰¾åˆ°å·²æ³¨å†Œçš„å‡½æ•°ï¼Œè¿›è¡Œ build

4. æ¥ä¸‹æ¥åˆ†åˆ«ä»¥ llvm åç«¯ï¼ˆä¸è®¾ç½®runtimeï¼‰ å’Œ cuda åç«¯ä¸ºä¾‹ çœ‹ä¸€ä¸‹å¦‚ä½•ç”Ÿæˆçš„ llvm IR or CUDA ä»£ç 

    ```c++
    // `src/target/llvm/llvm_module.cc`
    TVM_REGISTER_GLOBAL("target.build.llvm")
    .set_body_typed([](IRModule mod, Target target) -> runtime::Module {
      auto n = make_object<LLVMModuleNode>();
      n->Init(mod, target);
      return runtime::Module(n);
    });
    // `src/target/opt/build_cuda_on.cc`
    TVM_REGISTER_GLOBAL("target.build.cuda").set_body_typed(BuildCUDA);
    ```

    é¦–å…ˆçœ‹CUDAçš„ tir => bin ç¼–è¯‘æµç¨‹ï¼š
    
    ```c++
    runtime::Module BuildCUDA(IRModule mod, Target target) {
      // Step 1: Initialize CodeGen for CUDA  
      bool output_ssa = false;
      CodeGenCUDA cg;
      cg.Init(output_ssa);
      
      // Step 2: Add all tir::PrimFunc in IRModule to compile list
      for (auto kv : mod->functions) {
        auto f = Downcast<PrimFunc>(kv.second);
        cg.AddFunction(f);
      }

      // Step 3: Lower IRModule to CUDA source code
      std::string code = cg.Finish();

      // Step 4: Compile CUDA source code using NVCC and create runtime::Module
      std::string fmt = "ptx";
      std::string ptx = NVRTCCompile(code, cg.need_include_path());
      return CUDAModuleCreate(ptx, fmt, ExtractFuncInfo(mod), code);
    }
    ```

    **å¹¶è¡Œçº¿ç¨‹æ‰§è¡Œï¼ˆParallel Thread eXecutionï¼ŒPTXï¼‰ä»£ç æ˜¯ç¼–è¯‘åçš„GPUä»£ç çš„ä¸€ç§ IR ï¼Œ å®ƒå¯ä»¥å†æ¬¡ç¼–è¯‘ä¸ºåŸç”Ÿçš„GPUæŒ‡ä»¤**ã€‚PTXæä¾›äº†ä¸€ä¸ªç¨³å®šçš„ç¼–ç¨‹æ¨¡å‹å’ŒæŒ‡ä»¤é›†ï¼Œè¿™ä¸ªISAèƒ½å¤Ÿè·¨è¶Šå¤šç§GPUï¼Œå¹¶ä¸”èƒ½å¤Ÿä¼˜åŒ–ä»£ç çš„ç¼–è¯‘ç­‰ç­‰ã€‚
    
    æ¥ä¸‹æ¥çœ‹ LLVMï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¦‚æœ target="llvm"ï¼Œç”±äº LLVM IR ä»ç„¶åªæ˜¯ä¸€ç§ä¸­é—´è¡¨ç¤ºï¼Œè¿˜éœ€è¦æ ¹æ® target å½“ä¸­æ›´è¯¦ç»†çš„ç¡¬ä»¶å‚æ•°ï¼Œæ‰¾åˆ°ç›®æ ‡ç¼–è¯‘ç¡¬ä»¶ï¼Œç„¶åè°ƒç”¨ç›¸åº”çš„ CodeGenï¼ˆçœç•¥éƒ¨åˆ†è¾…åŠ©ä»£ç ï¼‰ï¼š
    
    ```c++
    void Init(const IRModule& mod, const Target& target) {
      // Step 1: Initialize CodeGen for LLVM with different target
      InitializeLLVM();
      tm_ = GetLLVMTargetMachine(target);
      std::unique_ptr<CodeGenLLVM> cg = CodeGenLLVM::Create(tm_.get());

      // Step 2: Add all tir::PrimFunc in IRModule to compile list
      std::vector<PrimFunc> funcs;
      for (auto kv : mod->functions) {
        if (!kv.second->IsInstance<PrimFuncNode>()) {
          // (@jroesch): we relax constraints here, Relay functions will just be ignored.
          DLOG(INFO) << "Can only lower IR Module with PrimFuncs, but got " << kv.second->GetTypeKey();
          continue;
        }
        auto f = Downcast<PrimFunc>(kv.second);
        funcs.push_back(f);
      }

      // Step 3: Lower IRModule to LLVM IR code
      module_ = cg->Finish();
    }
    ```
    
    å¯ä»¥çœ‹åˆ°è¿™é‡Œæ„é€ äº†ä¸€ä¸ª `LLVMModuleNode` å®ä¾‹ï¼Œ è°ƒç”¨äº†å®ƒçš„ `Init` æ–¹æ³•ï¼Œ å› æ­¤å¯çŸ¥è¯¥æ–¹æ³•å°±æ˜¯å°† IRModule lower ä¸º LLVMModuleNode çš„æ ¸å¿ƒå‡½æ•°ã€‚ å…³äº `LLVMModuleNode` çš„å®šä¹‰ï¼Œ å¯å‚è€ƒ [TVM-type](./tvm-type.md)ï¼Œä¸‹é¢æ˜¯ `Init` æ–¹æ³•çš„å…·ä½“å®ç°ï¼š


5. ä»ä¸Šä¸€æ­¥ä¸­å¯çŸ¥ï¼Œ TIR èƒ½ lower æˆç›®æ ‡æºä»£ç ï¼Œå…³é”®æ˜¯ CodeGenã€‚ä¸Šé¢æåˆ°çš„ CodeGenCUDAï¼Œä»¥åŠ CodeGenLLVM æ˜¯å®Œæˆ TIR lower ä¸º C++ ä»£ç çš„ç›¸å…³ç»“æ„ã€‚ å…¶ä¸­ `CodeGenCUDA`ç»§æ‰¿è‡ª `CodeGenC`ï¼Œä»¥å…¶ä¸ºä¾‹å­è¯´æ˜ï¼ˆ`tvm/src/target/source/codegen_c.[h, cc]`ï¼‰ï¼š
    
    ```c++
    class CodeGenC : public ExprFunctor<void(const PrimExpr&, std::ostream&)>,
                 public StmtFunctor<void(const Stmt&)>,
                 public CodeGenSourceBase {
    public:
      // expression
      void VisitExpr_(const VarNode* op, std::ostream& os) override;         // NOLINT(*)
      void VisitExpr_(const LoadNode* op, std::ostream& os) override;        // NOLINT(*)
      void VisitExpr_(const BufferLoadNode* op, std::ostream& os) override;  // NOLINT(*)
      void VisitExpr_(const LetNode* op, std::ostream& os) override;         // NOLINT(*)
      ...
      // statment
      void VisitStmt_(const LetStmtNode* op) override;
      void VisitStmt_(const StoreNode* op) override;
      void VisitStmt_(const BufferStoreNode* op) override;
      void VisitStmt_(const ForNode* op) override;
      void VisitStmt_(const WhileNode* op) override;
      void VisitStmt_(const IfThenElseNode* op) override;
      ...
    }
    ```

    å¯ä»¥çœ‹åˆ°ï¼Œ `CodeGenC` ä¼šéå†åˆ°ä¸¤ç§ TIR Nodeï¼šExpressionï¼ˆè¡¨è¾¾å¼ï¼‰ å’Œ Statementï¼ˆè¯­å¥ï¼‰ã€‚Expressionï¼ˆè¡¨è¾¾å¼ï¼‰ä¸­åŒ…å«äº†å¸¸è§çš„å˜é‡å£°æ˜ã€è¿ç®—ã€åˆ¤æ–­ã€å‡½æ•°è°ƒç”¨ï¼Œè€Œ Statementï¼ˆè¯­å¥ï¼‰ä¸­åŒ…å«äº†æ§åˆ¶æµï¼ˆif-elseï¼ŒLoop ç­‰ï¼‰ã€å†…å­˜ç®¡ç†ã€èµ‹å€¼ç­‰æ“ä½œã€‚

    ä¾‹å¦‚ï¼Œé‡åˆ°å››åˆ™è¿ç®—çš„ Expressionï¼ŒCodeGenC ç›´æ¥ç¿»è¯‘ä¸º " a OP b "çš„ä»£ç ï¼š

    ```c++
    template <typename T>
    inline void PrintBinaryExpr(const T* op, const char* opstr,
                                std::ostream& os, CodeGenC* p) {
      // If both a and b are scalars
      if (op->dtype.lanes() == 1) {
        // If OP is an alphabet string, then lower it as "OP(a, b)"
        if (isalpha(opstr[0])) {
          os << opstr << '(';
          p->PrintExpr(op->a, os);
          os << ", ";
          p->PrintExpr(op->b, os);
          os << ')';
        }
        // If OP is a symbol, like + - * / %, then lower it as "a OP b"
        else {
          os << '(';
          p->PrintExpr(op->a, os);
          os << ' ' << opstr << ' ';
          p->PrintExpr(op->b, os);
          os << ')';
        }
      }
      // If both a and b are vectors
      else {
        p->PrintVecBinaryOp(opstr, op->dtype, op->a, op->b, os);
      }
    }

    void CodeGenC::VisitExpr_(const AddNode* op, std::ostream& os) {  // NOLINT(*)
      PrintBinaryExpr(op, "+", os, this);
    }
    void CodeGenC::VisitExpr_(const SubNode* op, std::ostream& os) {  // NOLINT(*)
      PrintBinaryExpr(op, "-", os, this);
    }
    void CodeGenC::VisitExpr_(const MulNode* op, std::ostream& os) {  // NOLINT(*)
      PrintBinaryExpr(op, "*", os, this);
    }
    void CodeGenC::VisitExpr_(const DivNode* op, std::ostream& os) {  // NOLINT(*)
      PrintBinaryExpr(op, "/", os, this);
    }
    ```

    å¦‚æœé‡åˆ°é€‰æ‹© SelectNodeï¼ŒCodeGenC åˆ™ç¿»è¯‘ä¸º "(c ? a : b)" çš„ä»£ç ï¼š

    ```c++
    void CodeGenC::VisitExpr_(const SelectNode* op, std::ostream& os) {
      os << "(";
      PrintExpr(op->condition, os);
      os << " ? ";
      PrintExpr(op->true_value, os);
      os << " : ";
      PrintExpr(op->false_value, os);
      os << ")";
    }
    ```

## 2. Lower TE
ä¸Šä¸€èŠ‚ä¸­æˆ‘ä»¬ä½¿ç”¨ TE(Tensor Expression) å£°æ˜è®¡ç®—è¿‡ç¨‹ï¼Œ æ„é€ äº†ä¸€ä¸ª PrimFuncã€‚ åœ¨TVM ä¸­ï¼Œ PrimFunc è¿˜å¯ä»¥é€šè¿‡ç¼–å†™ TVMScriptï¼Œ æˆ–è€…é€šè¿‡ relay/relax lower è€Œæ¥ã€‚ 

TEæ˜¯ä½äº Relay IR / TOPI å’Œ TIR ä¹‹é—´æ¦‚å¿µï¼Œ æ˜¯TVM æä¾›çš„ä¸€ç§ç”¨äºç¼–å†™ Primfunc çš„ EDSLï¼Œ å…¶æŠ½è±¡ç¨‹åº¦æ¯” TIR æ›´é«˜ï¼Œæ— æ³•ç›´æ¥è¢«ç¼–è¯‘ä¸ºç¡¬ä»¶æºä»£ç ï¼Œå¿…é¡»å…ˆ lower ä¸º TIR çš„ Primitive Function å†è¿›è¡Œç¼–è¯‘ã€‚

åœ¨è¿™ä¸€èŠ‚ä¸­æˆ‘ä»¬å…³æ³¨ä½¿ç”¨ te æè¿°çš„è®¡ç®—è¿‡ç¨‹æ˜¯å¦‚ä½•è¢«è½¬æ¢æˆä¸€ä¸ª PrimFunc çš„ï¼Œå³å¯¹åº”åˆ° [Lower Tir](#1-lower-tir) ä¸­æåˆ°çš„ `te.create_prim_func`ï¼Œ ä¹Ÿå°±æ˜¯å®˜æ–¹ç»™å‡ºçš„ ç¼–è¯‘æµç¨‹ä¸­çš„çº¢æ¡†ä¸­çš„éƒ¨åˆ†ï¼š

<div class="autocb" style="text-align:center;"><img src="./tvm-lowering.assets\autocb_0.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

æµ‹è¯•ä»£ç ä¸ç¬¬ä¸€èŠ‚ä¸­ä»£ç ç›¸åŒï¼Œåªä¸è¿‡æ­¤æ—¶æˆ‘ä»¬å…³æ³¨æ›´ä¸Šå±‚çš„éƒ¨åˆ†ï¼š

```py
import tvm
from tvm import te
SIZE = 1024

# 1. ä½¿ç”¨ TE å£°æ˜è®¡ç®—
# mm
A = te.placeholder((SIZE, SIZE), name='A')  # te.tensor.Tensor
B = te.placeholder((SIZE, SIZE), name='B')  # te.tensor.Tensor
k = te.reduce_axis((0, SIZE), 'k')          # tir.expr.IterVar
C = te.compute((SIZE, SIZE), lambda x, y: te.sum(A[x, k] * B[k, y], axis=k), name='MM') # te.tensor.Tensor

# 2. ä» TE åˆ›å»º PrimFunc 
te_mm: tvm.tir.PrimFunc = te.create_prim_func([A, B, C]).with_attr({"global_symbol": "mmult"})

# 3. å°†åˆ›å»ºå‡ºæ¥çš„ PrimFunc æ·»åŠ åˆ°ä¸€ä¸ª IRModule ä¸­
ir_m: tvm.IRModule = tvm.IRModule({'mm': te_mm})

# è¿™é‡Œä¹Ÿå¯ä»¥ä½¿ç”¨ å…ˆæ„å»º Scheduleï¼Œ å†è°ƒç”¨ `tvm.lower` çš„æ–¹æ³• å¾—åˆ°ä¸€ä¸ª IRModule
te_sch: te.Schedule = te.create_schedule(C.op) # C.op: te.tensor.ComputeOp
ir_m: tvm.IRModule = tvm.lower(te_sch, [A, B, C], simple_mode=True,name='mmult')

print(ir_m.get_global_vars())
```

åœ¨å…³æ³¨ lowering ä¹‹å‰é¦–å…ˆçœ‹ä¸€ä¸‹ä¸€ä¸ª TE çš„æ„æˆ

1. é¦–å…ˆæ˜¯ `te.placeholder` å°†è¿”å›ä¸€ä¸ª `te.tensor.Tensor`ã€‚ å…¶æ•°æ®ç»“æ„å®šä¹‰ä½äº `include/tvm/te/operation.h`ä¸­ï¼Œ å…·ä½“å¦‚ä¸‹ï¼š

    ```c++
    class PlaceholderOpNode : public OperationNode {
     public:
      Array<PrimExpr> shape;
      DataType dtype;

      int num_outputs() const final{return 1;};
      Array<PrimExpr> output_shape(size_t i) const final{return shape;};
      Array<Tensor> InputTensors() const final{return {};};

      static constexpr const char* _type_key = "PlaceholderOp";
      TVM_DECLARE_BASE_OBJECT_INFO(PlaceholderOpNode, OperationNode);
    };
    ```

    placeholder é€šå¸¸ç”¨äºè®¡ç®—å›¾çš„ Input èŠ‚ç‚¹ä½¿ç”¨ï¼Œæ²¡æœ‰å‰åºèŠ‚ç‚¹ï¼Œå¯èƒ½ä¹Ÿæ˜¯teä¸­æœ€å¸¸ç”¨çš„Opã€‚ é™¤äº†`PlaceholderOp` ä¹‹å¤–ï¼Œ TE ä¸­è¿˜æœ‰ä¸€äº›å…¶ä»–çš„ Op å®šä¹‰ï¼Œä¾‹å¦‚åé¢ä¼šæåˆ°çš„ `ComputeOp`ï¼Œ ä»¥åŠ `ExternOp` ç­‰ï¼Œ è¿™äº› Op æ˜¯ TE AST çš„ç»„æˆéƒ¨åˆ†ã€‚

2. æ¥ä¸‹æ¥æ˜¯ `te.compute` ï¼Œ compute ä»ä¸€ä¸ªæˆ–è€…å¤šä¸ªå‰åºèŠ‚ç‚¹æ¥æ”¶æ•°æ®ï¼Œå¹¶æŒ‰åˆå§‹åŒ–çš„æ—¶å€™ä¼ å…¥çš„ lambda è¡¨è¾¾å¼è®¡ç®— Tensor å†…çš„æ•°æ®ã€‚å…¶API ç¬¬ä¸€ä¸ªä¼ å…¥å‚æ•°æ˜¯ Tensor çš„ shapeï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯ä¸€ä¸ª lambda è¡¨è¾¾å¼ï¼Œè¡¨æ˜ Tensor çš„æ•°æ®æ˜¯å¦‚ä½•è®¡ç®—æ¥çš„ï¼Œè¿”å›ä¸€ä¸ª`te.tensor.Tensor` ã€‚ å…¶ C++ éƒ¨åˆ†æ•°æ®ç»“æ„å®šä¹‰å…·ä½“å¦‚ä¸‹ï¼š

    ```c++
    class TVM_DLL ComputeOpNode : public BaseComputeOpNode {
    public:
      Array<PrimExpr> body; //compute expression
      // override functions
      int num_outputs() const final;
      Array<Tensor> InputTensors() const final;

      static constexpr const char* _type_key = "ComputeOp";
      TVM_DECLARE_FINAL_OBJECT_INFO(ComputeOpNode, BaseComputeOpNode);
    };
    ```
    
    å¯ä»¥çœ‹åˆ°å…¶å…³é”®æˆå‘˜åªæœ‰ä¸€ä¸ª bodyï¼Œæ˜¯ä¸€ä¸ª PrimExpr æ•°ç»„ï¼Œå› æ­¤æ¥ä¸‹æ¥çœ‹ python ç«¯æ˜¯æ€æ ·æŠŠä¸€ä¸ª lambda è¡¨è¾¾å¼è¡¨è¾¾çš„è®¡ç®—è½¬æ¢æˆäº† PrimExprï¼š

    ```py
    def compute(shape, fcompute, name="compute", tag="", attrs=None, varargs_names=None):
      out_ndim = len(shape)

      argspec = inspect.getfullargspec(fcompute)
      arg_names = argspec.args
      
      # 1. å°†ä¼ å…¥çš„ shape è½¬æˆ tir.IterVar åˆ—è¡¨
      dim_var = [tvm.tir.IterVar((0, s), x, 0) for x, s in zip(arg_names, shape[:out_ndim])]
      
      # 2. æ„é€ è®¡ç®—çš„ AST
      body = fcompute(*[v.var for v in dim_var])

      # 3. è°ƒç”¨ C++ API è·å– compute_op_node
      body = convert(body) # å°†List[PrimExpr] è½¬æˆ Array<PrimExpr>
      op_node = _ffi_api.ComputeOp(name, tag, attrs, dim_var, body)

      return op_node.output
    ```

    è¿™é‡Œçš„å…³é”®ç‚¹åœ¨äº `IterVar` ç»§æ‰¿äº† `ExprOp`ï¼ˆä½äº `python/tvm/tir/expr.py`ï¼‰ï¼Œ è€Œ `ExprOp` é‡è½½äº†å››åˆ™è¿ç®—ï¼Œç§»ä½è¿ç®—ï¼Œæ¯”è¾ƒè¿ç®—ç­‰æ“ä½œç¬¦ï¼Œå› æ­¤å¯ä»¥ç›´æ¥è¢« lambda è¡¨è¾¾å¼æ“ä½œï¼Œè°ƒç”¨é‡è½½çš„è¿ç®—ç¬¦è¿”å›è¡¨ç¤ºè¿ç®—ä¹‹åçš„è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ï¼š

    ```py
    Z = te.compute((n,), lambda i: X[i]*Y[i])
    ```

    é¦–å…ˆå¯¹äº `X[i]`å’Œ`Y[i]` ä¼šåˆ†åˆ«æ„é€ ä¸€ä¸ª `tir.expr.ProducerLoad` è¡¨è¾¾å¼ï¼Œæ¥ç€è¿™ä¸¤ä¸ªè¡¨è¾¾å¼çš„ä¹˜æ³•ä¼šè°ƒç”¨åˆ° `ExprOp` é‡è½½çš„ä¹˜æ³•è¿ç®—ç¬¦ï¼š

    ```py
    def multiply(lhs, rhs, span=None):
      return _ffi_api._OpMul(lhs, rhs, span)
    ```

    è¿”å›ä¸€ä¸ª `tir.Mul` Exprï¼›å…¶å®ƒçš„è¿ç®—ç±»ä¼¼ã€‚**å€¼å¾—æ³¨æ„çš„æ˜¯** TE ä¸­ä¹Ÿæä¾›äº†æ§åˆ¶ç±» PrimExpr çš„å°è£…ï¼Œä¾‹å¦‚ `te.if_then_else`ï¼›ä»¥åŠ `te.extern_primfunc` ç”¨å…¶å®ƒPrimFunc æ¥åˆ›å»º PrimExpr

3. åœ¨æ„é€ è¡¨ç¤ºè®¡ç®—çš„ AST ä¹‹åï¼Œæˆ‘ä»¬æŠŠè¿™ä¸ªä»lambdaæ„é€ å‡ºæ¥çš„ PrimExpr æ•°ç»„ä¼ å…¥äº†`_ffi_api.ComputeOp`ï¼Œ è¿”å›ä¸€ä¸ª ComputeOp ç±»å‹ï¼Œ `ComputeOp` æ˜¯ `te::Operation` çš„ä¸€ä¸ªå­ç±»ï¼Œå› æ­¤å¯ä»¥ä»å…¶`output`æ–¹æ³•æ‹¿åˆ°è®¡ç®—ç»“æœ `Tensor` ä½œä¸º `te.compute` çš„è¿”å›ç»“æœ

ğŸ’¡**åœ¨è¿™é‡Œæ€»ç»“ä¸€ä¸‹ TE çš„æ„æˆå…³é”®å…ƒç´ **ï¼š å³ `Tensor` å’Œ `Operation` ä¸¤ä¸ªç±»å‹ã€‚å‰è€…è¡¨å¾ä¸€ä¸ªå¼ é‡çš„å½¢çŠ¶ã€å…ƒç´ ç±»å‹ã€source operationç­‰ï¼›åè€…è¡¨ç¤ºäº§ç”Ÿ Tensor çš„ä¸€ç§æ“ä½œï¼ŒåŒ…æ‹¬è¡¨ç¤ºè¾“å…¥çš„æ“ä½œ PlaceholderOpï¼Œ è¡¨ç¤ºè®¡ç®—é€»è¾‘çš„æ“ä½œ ComputeOp ç­‰ã€‚

<div class="autocb" style="text-align:center;"><img src="./tvm-lowering.assets\autocb_1.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>


---

æ¥ä¸‹æ¥æˆ‘ä»¬å¼€å§‹å…³æ³¨ `te.create_prim_func` æ˜¯å¦‚ä½• å°† TE lower åˆ° PrimFunc çš„ï¼Œå¯¹åº”åˆ°`src/te/operation/create_prim_func.cc` ï¼š

```c++
PrimFunc CreatePrimFuncWithConstants(const Array<te::Tensor>& arg_list,
                                     const Array<runtime::NDArray>& constants,
                                     const Optional<Array<tir::Var>>& tir_var_list,
                                     std::optional<DataType> index_dtype_override) {
  // Infomations used in CreatePrimFunc and its sub-functions.
  CreateFuncInfo info(arg_list);
  // Root body stmts.
  Array<Stmt> root_stmts;
  // Analyzer
  arith::Analyzer analyzer;

  // Step 1. åç»­éå†è®¡ç®—å›¾ï¼š placeholderè¢«æ”¾åˆ°å‰é¢ï¼Œæœ€ç»ˆcomputeOpåœ¨æœ€å
  Array<te::Operation> order = CollectOrderedOps(arg_list);

  // Step 2. è¿™æ®µé€»è¾‘æ˜¯å¤„ç† TE ä¸­åæ¥å¼•å…¥çš„ ExternOpï¼Œåœ¨æœ¬ä¾‹ä¸­æ— éœ€è€ƒè™‘
  InitializeBufferBinds(order, &info);

  // Step 3. å¦‚æœæ˜¯ placeholderï¼Œåˆ›å»ºå¯¹åº”çš„ tir.Bufferï¼›å¦‚æœæ˜¯computeï¼Œåˆ›å»ºå¯¹åº”çš„ tir.Stmtï¼›å¦‚æœæ˜¯ externï¼Œåˆ™åˆ›å»ºä¸€ä¸ª tir.Stmt èŠ‚ç‚¹
  for (const te::Operation& op : order) {
    RewriteStageToBlock(op, &info, &root_stmts, &analyzer);
  }

  // åˆ›å»ºå¹¶è¿”å› PrimFunc
  auto func = GenerateAndCompletePrimFunc(arg_list, root_stmts, &info, tir_var_list);

  return func;
}
```

å›é¡¾ä¸‹ PrimFunc çš„ç»“æ„ï¼š

```c++
class PrimFuncNode : public BaseFuncNode {
 public:
  Array<tir::Var> params;
  tir::Stmt body;
  Type ret_type;
  Map<tir::Var, Buffer> buffer_map;

  static constexpr const char* _type_key = "tir.PrimFunc";
  TVM_DECLARE_FINAL_OBJECT_INFO(PrimFuncNode, BaseFuncNode);
};
```

`GenerateAndCompletePrimFunc` ä¼šå°† `arg_list`(`Array<te::Tensor>`) è½¬æˆä¸€ä¸ª `Array<tir::Var>` ä½œä¸ºå‡½æ•°çš„ paramsï¼› è€Œå‡½æ•° body å’Œ `buffer_map` å·²ä»å»ºç«‹çš„è®¡ç®—å›¾ä¸­å¾—åˆ°ï¼›å› æ­¤åˆ°è¿™é‡Œæˆ‘ä»¬å°±å®Œæˆäº†ä» TE åˆ° `PrimFunc` çš„è½¬æ¢ã€‚

ğŸ’¡æ€»ç»“æ•´ä¸ªè¿‡ç¨‹ï¼Œæœ€æ ¸å¿ƒçš„éƒ¨åˆ†åœ¨äºåç»­éå† TE è¡¨ç¤ºçš„è®¡ç®—å›¾ï¼ˆOperationä½œä¸ºèŠ‚ç‚¹ï¼Œé€šè¿‡ `InputTensors` æ–¹æ³•æ‹¿åˆ°æ‰€æœ‰å…¥è¾¹ï¼Œåš DFSï¼‰ï¼Œè½¬æ¢æˆå¯¹åº”çš„ `tir.Buffer` å’Œ `tir.Stmt` å³ tir ä¸­çš„ AST


## 3. Lower Relay
è¿™ä¸€èŠ‚å…³æ³¨ä¸€ä¸ªæ›´é«˜å±‚æ¬¡çš„æŠ½è±¡ï¼Œ TVM ä¸­å›¾çº§åˆ« IR Relay çš„ lowering

<div class="autocb" style="text-align:center;"><img src="./tvm-lowering.assets\autocb_2.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

ä»è¿™å¼ å›¾å¯ä»¥çœ‹åˆ°ï¼Œ Relay è¦åˆ° TIR æœ‰2æ¡è·¯å¾„ï¼Œç¬¬ä¸€æ¡å°±æ˜¯ç›´æ¥åˆ° TIRï¼Œ æ¯”å¦‚ PrimExpr æ´¾ç”Ÿçš„èŠ‚ç‚¹ IntImmNode å¯ä»¥ç›´æ¥æ˜ å°„åˆ° TIR ï¼Œå¦å¤–ä¸€æ¡å°±æ˜¯ Relay é‡Œé¢ç±»ä¼¼ Conv çš„ Op çš„è®¡ç®—é€»è¾‘æ˜¯ç”¨ TOPI æ¥è¡¨è¾¾çš„ï¼Œ TOPI æ˜¯ TVM ä¸­ç”¨ TE æ¥è¡¨ç¤ºå¸¸ç”¨ç®—å­çš„é¢„å®šä¹‰åº“ã€‚

### 3.1. TOPI
è€ƒè™‘è¿™ä¸ªä¾‹å­ï¼š

```py
n = te.var("i", dtype="int32")
m = te.var("j", dtype="int32")
A = te.placeholder((n, m), name="A")
k = te.reduce_axis((0, m), "k")
B = te.compute((n,), lambda i: te.sum(A[i, k], axis=k), name="B")

# ä½¿ç”¨ TOPI: è¿™ä¸€å¥ä¸ä¸Šé¢ä¸¤å¥ç­‰ä»·
C = topi.sum(A, axis=1) 

# å¯ä»¥åˆ©ç”¨ä¸Šä¸€èŠ‚çš„ä»£ç ï¼Œ å°† TE lower åˆ° tir æŸ¥çœ‹è¡¨ç¤ºï¼š
prim_func1 = te.create_prim_func([A,B])
prim_func2 = te.create_prim_func([A,C])
print(f"\033[31m{'='*20}prim_func1{'='*20}\033[0m\n{prim_func1}")
print(f"\033[31m{'='*20}prim_func2{'='*20}\033[0m\n{prim_func2}")

# Build ä¹‹åè¿è¡Œç»“æœå½“ç„¶ä¹Ÿæ˜¯ç›¸åŒçš„ï¼š
prim_func1 = te.create_prim_func([A,B])
prim_func2 = te.create_prim_func([A,C])

lib1, lib2 = tvm.build(prim_func1), tvm.build(prim_func2)

a_np = np.random.rand(128, 1024).astype("float32")
expected_res = np.sum(a_np, axis=1)
a_nd1, a_nd2 = tvm.nd.array(a_np), tvm.nd.array(a_np)
test_res1 = tvm.nd.empty((128,), dtype="float32")
test_res2 = tvm.nd.empty((128,), dtype="float32")

lib1(a_nd1, test_res1)
lib2(a_nd2, test_res2)
np.testing.assert_allclose(expected_res, test_res1.numpy(), rtol=1e-5)
np.testing.assert_allclose(expected_res, test_res2.numpy(), rtol=1e-5)
print("ğŸ‰\033[32mTest Pass...\033[0m")
```

å¯ä»¥çœ‹åˆ°ï¼Œå¯¹äºæ±‚å’Œè¿™æ ·å¸¸è§çš„ç®€å•æ“ä½œï¼Œå¦‚æœåªä½¿ç”¨ te çš„è¯ï¼Œä¹Ÿéœ€è¦å…ˆå®šä¹‰ä¸€ä¸ª reduce_axis, å†ç”¨ lambda é£æ ¼å»å£°æ˜ï¼Œæ¯”è¾ƒç¹çï¼Œæ›´ä¸å¿…è¯´åœ¨ç¥ç»ç½‘ç»œä¸­å¤§é‡ä½¿ç”¨çš„å…¶å®ƒæ›´å¤æ‚ä¸€ç‚¹çš„ç®—å­ï¼Œå¦‚æœç”¨ te å»å†™çš„è¯ï¼Œä¼šæ¯”è¾ƒéº»çƒ¦ã€‚ å› æ­¤ TVM æä¾›äº†ä¸€äº›ä½¿ç”¨ TE å®šä¹‰çš„ç°æˆçš„ç®—å­ï¼ŒæŠŠä»–ä»¬æ”¾åˆ°ä¸€èµ·ï¼ˆä»¥åŠä¸€äº› schedule æ“ä½œï¼‰ï¼Œç§°ä½œ TOPI(Tensor operator inventory)

TOPI ä¸­åŒ…å«äº†å¦‚ å·ç§¯ï¼Œ softmaxï¼Œ çŸ©é˜µä¹˜ ç­‰å¸¸è§çš„ç®—å­ï¼Œå¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½çš„è¡¨è¾¾ DL ä¸­å¸¸è§çš„è®¡ç®—è¿‡ç¨‹ã€‚

åœ¨çœ‹å…·ä½“å®ç°å‰å¯ä»¥é¦–å…ˆè§‚å¯Ÿä¸€ä¸‹ TOPI çš„ç›®å½•ç»“æ„ï¼ŒåŒ…å«äº† `nn.cc`ï¼Œ`elemwise.cc`ï¼Œ`schedule.cc`ç­‰ï¼Œåˆ†åˆ«å¯¹åº”äº†æœºå™¨å­¦ä¹ å¸¸è§ç®—å­ï¼Œelement wise è¿ç®—ï¼ˆå¦‚ä¸Šé¢ä¾‹å­ä¸­çš„ `topi.sum`ï¼‰ï¼Œ ç®—å­è°ƒåº¦ï¼›åœ¨è¿™äº›æ–‡ä»¶ä¸­ï¼Œä½¿ç”¨ `TVM_REGISTER_GLOBAL` æ³¨å†Œäº† TOPI ä¸­çš„å…·ä½“å®ç°ã€‚


ğŸ’¡è¿™é‡Œæˆ‘ä»¬ä»¥ `topi.matmul` ä¸ºä¾‹çœ‹ä¸€ä¸‹å®ç°ã€‚


`topi.matmul` å¯¹åº” C++ æ³¨å†Œåœ¨`src/topi/nn.cc` ä¸­ï¼Œå®ç°åœ¨`include/tvm/topi/nn/dense.h`ä¸­ï¼Œç®€åŒ–åå¦‚ä¸‹ï¼š

```c++
inline tvm::te::Tensor matmul(const tvm::te::Tensor& A, const tvm::te::Tensor& B,bool trans_a = false, bool trans_b = false,std::string name = "T_matmul", std::string tag = kMatMul) {
  tvm::Array<tvm::PrimExpr> output_shape{A->shape[trans_a ? 1 : 0], B->shape[trans_b ? 0 : 1]};
  auto k = tvm::te::reduce_axis(tvm::Range{0, A->shape[trans_a ? 0 : 1]}, "k");
  auto l = [&](tvm::tir::Var i, tvm::tir::Var j) {
    return tvm::sum((trans_a ? A[k][i] : A[i][k]) * (trans_b ? B[j][k] : B[k][j]), {k});
  };
  return tvm::te::compute(output_shape, l, name, tag);
}
```

å¯ä»¥çœ‹åˆ°å…¶å® `dense` è·Ÿæˆ‘ä»¬æ‰‹å†™çš„æ²¡æœ‰ä»€ä¹ˆä¸åŒï¼Œä½†æ˜¯å¯¹äº logsoftmax ä¹‹ç±»æœ‰å®ç°æŠ€å·§çš„ç®—å­ï¼ŒTOPI æœ‰å¾ˆå¥½çš„å®ç°å¹¶ä¸”æœ‰ç›¸åº”çš„è°ƒåº¦å¯ä»¥ä½¿ç”¨ã€‚

> TOPI ä¸­æœ‰äº›ç®—å­åœ¨C++ å’Œ python ç«¯åˆ†åˆ«å®ç°äº†ä¸€æ¬¡ï¼Œè¿™æ ·åšçš„åŸå› è§ï¼š https://discuss.tvm.apache.org/t/why-topi-is-implemented-in-both-c-and-python/50/7
>
> ç®€å•æ¥è¯´ï¼Œå½“ä¸€ä¸ªç®—å­åœ°è°ƒåº¦æ–¹å¼ç¨³å®šä¹‹åï¼Œä¼šè¢«æ”¾åœ¨C++éƒ¨åˆ†ï¼Œ æ­£åœ¨devåœ°æ”¾åœ¨pythonå®ç°ï¼›è€Œå¯¹äºä¸€äº›ç®€å•çš„ç®—å­ï¼Œå°±ä¿ç•™äº†åœ¨ C++ å’Œ py ä¸¤éƒ¨åˆ†çš„å®ç°


### 3.2. Relay-GraphExecutor
æœ¬èŠ‚ä½¿ç”¨å¦‚ä¸‹ä¾‹å­ï¼š

```py
import numpy as np
import tvm
from tvm import relay

# 1. å®šä¹‰ Relay Var
data = relay.var("data", shape=(1,784),dtype="float32")
weight1 = relay.var("weight1",shape=(128,784),dtype="float32")
bias1 = relay.var("bias1",shape=(128,),dtype="float32")
weight2 = relay.var("weight2",shape=(10,128),dtype="float32")
bias2 = relay.var("bias2",shape=(10,),dtype="float32")

# 2. ä½¿ç”¨ Relay Op å®šä¹‰ç½‘ç»œç»“æ„
dense1 = relay.nn.dense(data,weight1)
bias_add1 = relay.nn.bias_add(dense1, bias1)
relu1 = relay.nn.relu(bias_add1)
dense2 = relay.nn.dense(relu1,weight2)
bias_add2 = relay.nn.bias_add(dense2, bias2)
relu2 = relay.nn.relu(bias_add2)

# 3. æ„å»ºç½‘ç»œ
func = relay.Function([data,weight1,bias1,weight2,bias2],relu2)
print(f"\033[31m{'='*20}relay func{'='*20}\033[0m\n{func}")

# 4. æ„å»º IRModule
ir_mod = tvm.IRModule.from_expr(func)

# 5. è°ƒç”¨ relay.build è¿›è¡Œæ„å»º
# relay.build ç›®å‰æš‚æ—¶æ”¯æŒç¬¬ä¸€ä¸ªå‚æ•°ä¼ å…¥ `relay.Function`ï¼Œ ä½†æ˜¯ä¹‹åå°†åªæ”¯æŒ IRModule
with tvm.transform.PassContext(opt_level=2):
  rt_lib = relay.build(ir_mod=ir_mod,target="llvm")

# 6. ä½¿ç”¨ graph_executor åŠ è½½ build å¥½çš„è®¡ç®—å›¾å¹¶æ‰§è¡Œ
dev = tvm.cpu()
dtype = "float32"
graph_module = graph_executor.GraphModule(rt_lib["default"](dev))
# Set inputs: è¿™é‡Œåªè®¾ç½®ä¸€éƒ¨åˆ†å‚æ•°ï¼Œå› ä¸ºparams çš„å†…å­˜å·²ç»åœ¨ relay.build é˜¶æ®µ åˆ†é…å¥½å†…å­˜åŒ…å«åœ¨ graphmodule ä¸­ï¼Œ å› æ­¤è¿™é‡Œçš„ä»£ç ä¹Ÿèƒ½è·‘é€š

# Execute && Get outputs
graph_module.run()
graph_exec_output = graph_module.get_output(0)
print(graph_exec_output)
```

è¿™é‡Œä»¥ `dense` ç®—å­ä¸ºä¾‹ï¼Œ é¦–å…ˆå…³æ³¨ `dense1 = relay.nn.dense(data,weight1)` ï¼š

```py
def dense(data, weight, units=None, out_dtype=""):
  return _make.dense(data, weight, units, out_dtype)
```

åœ¨ C++ ç«¯ä½¿ç”¨ RELAY_REGISTER_OP æœºåˆ¶ç»Ÿä¸€ç®¡ç† Relay Opï¼Œ `dense`ç®—å­çš„æ³¨å†Œä½äº `src/relay/op/nn/nn.cc` ä¸­ï¼š

```c++
Expr MakeDense(Expr data, Expr weight, IndexExpr units, DataType out_dtype) {
  auto attrs = make_object<DenseAttrs>();
  attrs->units = units;
  attrs->out_dtype = out_dtype;
  static const Op& op = Op::Get("nn.dense");
  return Call(op, {data, weight}, Attrs(attrs), {});
}

TVM_REGISTER_GLOBAL("relay.op.nn._make.dense").set_body_typed(MakeDense);

RELAY_REGISTER_OP("nn.dense")
    .describe(/*çœç•¥*/)
    .set_attrs_type<DenseAttrs>()
    .set_num_inputs(2)
    .add_argument("data", "nD Tensor", "Input data.")
    .add_argument("weight", "2D Tensor", "Weight matrix.")
    .set_support_level(1)
    .set_attr<FInferCorrectLayout>("FInferCorrectLayout", DenseInferCorrectLayout)
    .add_type_rel("Dense", MatmulRel<DenseAttrs>)
    .set_attr<TOpPattern>("TOpPattern", kOutEWiseFusable);
```

å¯ä»¥çœ‹åˆ°æœ€ç»ˆè¿”å›çš„å°±æ˜¯ä¸€ä¸ª `CallNode`ï¼Œ Op æ˜¯ `dense`ã€‚

åŒæ—¶æ³¨æ„åˆ° `RELAY_REGISTER_OP("nn.dense")` åªæ˜¯è®¾ç½®äº†è¾“å…¥è¾“å‡º type å…³ç³»ï¼Œä»¥åŠå…¶å®ƒçš„ä¸€äº›ç›¸å…³å±æ€§ï¼Œ æ²¡æœ‰æŒ‡å®š `dense` è¿™ä¸ªç®—å­å…·ä½“çš„è®¡ç®—å’Œè°ƒåº¦ï¼Œ é‚£ä¹ˆä¸€ä¸ª Relay ç®—å­çš„è®¡ç®—å’Œè°ƒåº¦åœ¨å“ªé‡ŒæŒ‡å®šå‘¢ï¼Ÿ

ç­”æ¡ˆæ˜¯åœ¨ python ç«¯ï¼Œ ä»¥`dense`ä¸ºä¾‹ï¼Œ å…¶è°ƒåº¦å’Œè®¡ç®—çš„æŒ‡å®šä½äº `python/tvm/relay/op/nn/_nn.py` ä¸­ï¼Œ è¯¥æ–‡ä»¶ä¼šåœ¨ `import relay` æ—¶è¢«è‡ªåŠ¨åŠ è½½ï¼š

```py
# dense
reg.register_strategy("nn.dense", strategy.dense_strategy)
```

`strategy.dense_strategy` å®šä¹‰å¦‚ä¸‹ï¼š

```py
@override_native_generic_func("dense_strategy")
def dense_strategy(attrs, inputs, out_type, target):
  """dense generic strategy"""
  logger.warning("dense is not optimized for this platform.")
  strategy = _op.OpStrategy()
  strategy.add_implementation(
    wrap_compute_dense(topi.nn.dense),
    wrap_topi_schedule(topi.generic.schedule_dense),
    name="dense.generic",
  )
  return strategy
```

å…¶ä¸­ `topi.nn.dense` å’Œ `topi.generic.schedule_dense` å°±æ˜¯ ä¸Šä¸€èŠ‚ TOPI ä¸­é¢„å®šä¹‰å¥½çš„ TE è¡¨ç¤ºçš„ç®—å­åº“ä¸­çš„ç®—å­ã€‚ è€Œ `_op.OpStrategy` å¯¹åº” C++ ä¸­çš„æ•°æ®ç»“æ„ä½äº `include/tvm/relay/op_strategy.h` ä¸­ï¼š

```c++
class OpImplementationNode : public Object {
 public:
  FTVMCompute fcompute;
  FTVMSchedule fschedule;
  String name;
  int plevel;

  static constexpr const char* _type_key = "relay.OpImplementation";
  TVM_DECLARE_FINAL_OBJECT_INFO(OpImplementationNode, Object);
};
```

å…¶ä¸­ `FTVMCompute` æ˜¯ `runtime::TypedPackedFunc<Array<te::Tensor>(const Attrs& attrs, const Array<te::Tensor>& inputs, const Type& out_type)>;` ï¼Œ FTVMSchedule æ˜¯ `runtime::TypedPackedFunc<te::Schedule(const Attrs& attrs, const Array<te::Tensor>& outs, const Target& target)>;`ï¼›

ğŸ’¡**è¿™æ ·å°±å°† TOPI å’Œ Relay Op å»ºç«‹äº†è”ç³»**

æ¥ä¸‹æ¥å…³æ³¨ `relay.build`

---

å…ˆæš‚æ—¶å¿½ç•¥ `PassContext(opt_level=2)`ï¼Œ ç›´æ¥çœ‹ `relay.build`ï¼š

```py
def build(ir_mod,target=None, target_host=None,
          executor=Executor("graph"), runtime=Runtime("cpp"),
          workspace_memory_pools=None, constant_memory_pools=None,
          params=None, mod_name="default",
):
  raw_targets = Target.canon_multi_target_and_host(Target.target_or_current(target), target_host)
  target_host = raw_targets[0].host

  # å¦‚æœå½“å‰ dispatch context æ˜¯ fallback context (the default root context),
  # ä» TopHub ä¸­ load pre-tuned parameters
  if isinstance(autotvm.DispatchContext.current, autotvm.FallbackContext):
    tophub_context = autotvm.tophub.context(list(raw_targets))
  else:
    tophub_context = autotvm.utils.EmptyContext()

  with tophub_context:
    bld_mod = BuildModule()
    graph_json, runtime_mod, params = bld_mod.build(
      mod=ir_mod, target=raw_targets, params=params,
      executor=executor, runtime=runtime,
      workspace_memory_pools=workspace_memory_pools,
      constant_memory_pools=constant_memory_pools,
      mod_name=mod_name,
    )
    # build ä¹‹å bld_mod ä¸­åŒ…å« IRModuleï¼ˆå…¶ä¸­ä¸º PrimFuncï¼‰
    func_metadata = bld_mod.get_function_metadata()
    devices = bld_mod.get_devices()
    lowered_ir_mods = bld_mod.get_irmodule()
    executor_codegen_metadata = bld_mod.get_executor_codegen_metadata()
    # è¿™é‡Œåªçœ‹ graph_executor å»æ‰äº†aot ç›¸å…³
    if executor.name == "graph":
      executor_factory = _executor_factory.GraphExecutorFactoryModule(
        ir_mod, raw_targets, # åŸå§‹(Relay)IRModule; build target
        executor, graph_json, runtime_mod,  # executor-config; graphä¿¡æ¯; buildåçš„ runtime module
        mod_name, params, func_metadata,  # runtime.module name; æ¨¡å‹å‚æ•°; å‡½æ•°ä¿¡æ¯
      )
    return executor_factory
```

å‡½æ•°æœ€ç»ˆè¿”å›ä¸€ä¸ª `relay.backend.executor_factory.ExecutorFactoryModule` ï¼Œ æ˜¯relayçš„ graph executor factoryï¼ˆ `ExecutorFactoryModule` ç›®å‰æœ‰ graph å’Œ aot ä¸¤ç§ï¼Œ åœ¨æœ¬ä¾‹å­ä¸­ä¸º `graph_executor`ï¼‰

æ•´ä¸ªæ„å»ºæµç¨‹å¦‚ä¸‹ï¼š

1. TopHub å¯»æ‰¾å†å²ä¼˜åŒ–ä¿¡æ¯:

    > é¦–å…ˆ Relay ä¼šå¯»æ‰¾æ˜¯å¦æœ‰ AutoTVM é¢„å…ˆ Fintune çš„è®°å½•ï¼Œå¦‚æœæ²¡æœ‰é‚£ä¹ˆå°±ä½¿ç”¨autotvm.FallbackContextè¿™ä¸ªç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¦‚æœæœ‰é‚£ä¹ˆæ¥ä¸‹æ¥çš„æ‰€æœ‰æ“ä½œéƒ½åœ¨ tophub_context çš„ scope ä¹‹ä¸‹ (with tophub_context:)ã€‚å€¼å¾—ä¸€æçš„æ˜¯ Relay è€ƒè™‘äº†å¼‚æ„æƒ…æ™¯ä¸‹çš„ä»£ç ç”Ÿæˆï¼Œç”¨æˆ·å¯ä»¥æŒ‡å®šå¤šä¸ªç”Ÿæˆä»£ç çš„ç›®æ ‡ (target)ã€‚

    TODO:


2. åœ¨ `tophub_context`ä¸­ï¼Œåˆ›å»ºäº†ä¸€ä¸ª `BuildModule` ï¼Œè°ƒç”¨ `build` ã€‚ `bld_mod.build` åœ¨ python ç«¯çš„è¿”å›å€¼æœ‰ä¸‰ä¸ª: `executor_config, mod, params`ï¼› å…¶ä¸­ `executor_config` æ˜¯ä¸€ä¸ª json-like form çš„configï¼Œ ç”¨äºç»™åç»­ç”Ÿæˆç»™ graph_executor æä¾›ä¿¡æ¯ï¼› `mod` æ˜¯åŒ…å«å„ç§å¿…éœ€è¿è¡Œæ—¶åº“çš„ `runtime.module`ï¼› `params` æ˜¯ä¼˜åŒ–åçš„è®¡ç®—å›¾çš„å‚æ•°ã€‚

3. `BuildModule()` å¯¹åº”åœ¨ C++ ä¸­çš„ `src/relay/backend/build_module.cc` ä¸­:

    ```c++
    class RelayBuildModule : public runtime::ModuleNode {
     protected:
      // return The updated Relay IR module after optimization.
      IRModule Optimize(IRModule relay_module, const Array<Target>& raw_targets);

      // Compile a Relay IR module to runtime module. ç»“æœä¿å­˜åœ¨ `this->ret_`
      void BuildRelay(IRModule relay_module, const String& mod_name);

     protected:
      std::unique_ptr<ExecutorCodegen> executor_codegen_;
      Executor executor_;     // Executor to build for
      Runtime runtime_;       // Runtime to codegen for
      WorkspaceMemoryPools workspace_memory_pools_;
      ConstantMemoryPools constant_memory_pools_;
      std::unordered_map<std::string, runtime::NDArray> params_; // parameters
      BuildOutput ret_; // building output
      CompilationConfig config_;
    };
    ```

    `bld_mod.build` ç›´æ¥å¯¹åº”ä¸Šè¿° `Build` å‡½æ•°ï¼Œè¯¥å‡½ç®€å•åœ°æŠŠå‡½æ•°å‚æ•°å¦‚ runtimeï¼Œ executorï¼Œ config ç­‰èµ‹å€¼ç»™å¯¹åº”çš„filedsï¼Œ æ¥ç€è°ƒç”¨ä¸Šè¿°ä»£ç ä¸­çš„ `BuildRelay` å‡½æ•°ï¼Œè¿™æ˜¯æ•´ä¸ª build ä¸­çš„å…³é”®éƒ¨åˆ†

4. `BuildRelay` å‡½æ•°ä¸»è¦é€»è¾‘å¦‚ä¸‹ï¼š

    ```c++
    void BuildRelay(IRModule relay_module, const String& mod_name) {
      // 1. Relay IRModule -> IRModule ä¼˜åŒ– (TODO: å±•å¼€)
      relay_module = OptimizeImpl(std::move(relay_module));

      Function func = Downcast<Function>(relay_module->Lookup("main"));
      LOG(DEBUG)<<"After `OptimizeImpl`: relay_module->Lookup('main')" << PrettyPrint(func); // my print

      IRModule func_module = WithAttrs(IRModule::FromExpr(func),{/*executor ç­‰ attrs...*/});
      
      // 2. ä¸ºä¼˜åŒ–åçš„å‡½æ•°æ‰§è¡Œ codegen
      // 2.1. å¦‚æœæ˜¯ graph_executor åˆ›å»ºä¸€ä¸ª `GraphCodegen` å¯¹è±¡
      executor_codegen_ = MakeExecutorCodegen(executor_->name);
      executor_codegen_->Init(nullptr, config_->primitive_targets);
      // è¿™é‡Œçš„codegen å¯¹åº” GraphExecutorCodegen::Codegen
      //  a) è®¾ç½® memory_plan_
      //  b) LowerTE, lower ä¹‹åçš„ IR åœ¨ tir level 
      executor_codegen_->Codegen(func_module, func, mod_name);
      // ä¸º ret_ è®¾ç½® graph_json
      executor_codegen_->UpdateOutput(&ret_);
      // ret_ åŒ…æ‹¬: 1) graph_json å­—ç¬¦ä¸²; 2) runtime.mod; 3)[string: NDArray] params å­—å…¸;
      // è¿™é‡Œè®¾ç½® executor_codegen_ åœ¨ codegen é˜¶æ®µæ„é€ çš„ params 
      ret_.params = executor_codegen_->GetParams();

      // 2.2. æ‹¿åˆ° lowerd_funcs ï¼ˆæ­¤æ—¶Relayå‡½æ•°å·²ç»ä¸‹é™ä¸º PrimFuncï¼‰
      auto lowered_funcs = executor_codegen_->GetIRModule();

      const Target& host_target = config_->host_virtual_device->target;
      const runtime::PackedFunc* pf = runtime::Registry::Get("codegen.LLVMModuleCreate");
      // 2.3. å¦‚æœç”±äºä¼˜åŒ–ç­‰åŸå› ï¼Œ lowered_funcs é›†åˆä¸ºç©ºæ—¶ï¼Œè¿”å›ç©º module
      if (lowered_funcs.size() == 0) {/* çœç•¥...*/} 
      // 3. å¦åˆ™æ‰§è¡Œ TIRToRuntimeï¼Œ å¯ä»¥å‚è€ƒ tir ä¸‹é™ä¸€èŠ‚ä¸­çš„æ­¥éª¤
      else {ret_.mod = tvm::TIRToRuntime(lowered_funcs, host_target);}

      // 4. æ¥ä¸‹æ¥æ˜¯å¯¹ external module çš„å¤„ç†
      ...
    }
    ```

    `BuildRelay` åŒ…å«äº† Optimize ï¼Œ Codegen ä¸¤ä¸ªè¿‡ç¨‹ï¼š
    
    1. åœ¨ `Build` ä¹‹å‰ï¼š Relay é˜¶æ®µçš„ IRModuleï¼š

        ```py
        def @main(%data: Tensor[(1, 784), float32], %weight1: Tensor[(128, 784), float32], %bias1: Tensor[(128), float32], %weight2: Tensor[(10, 128), float32], %bias2: Tensor[(10), float32]) {
          %0 = nn.dense(%data, %weight1, units=None);
          %1 = nn.bias_add(%0, %bias1);
          %2 = nn.relu(%1);
          %3 = nn.dense(%2, %weight2, units=None);
          %4 = nn.bias_add(%3, %bias2);
          nn.relu(%4)
        }
        ```

    2. åœ¨ `Optmize` ä¹‹åï¼Œ äºæ‰“å°å‡ºè¿™æ—¶çš„ IR å‘ç°æ˜¯ä»¥ Tensor ä¸ºæ“ä½œå•ä½ï¼Œå³è½¬ä¸ºäº† TEçš„è¡¨ç¤ºï¼Œå¹¶ä¸”åœ¨TEå±‚çº§è¿›è¡Œäº†ç®—å­èåˆï¼Œå¯ä»¥çœ‹åˆ°ï¼Œåœ¨Relayä¸­çš„ `nn.dense` Op, ä»¥åŠ `nn.bias_add` Op, `nn.relu` Op åœ¨è¿™é‡Œçš„ IR ä¸­éƒ½è¢«è½¬ä¸ºTEè¡¨ç¤ºï¼Œå¹¶ä¸”ä¸‰ä¸ªç®—å­è¢«åŒ…è£¹åˆ°äº†ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œåœ¨æ¥ä¸‹æ¥çš„ codegen ä¸­ï¼Œ ä¸‰ä¸ªTEå‡½æ•°å°†ä¼šè¢«èåˆæˆä¸€ä¸ªè®¡ç®—è¿‡ç¨‹ï¼š

        ```c++
        fn (
          %data: Tensor[(1, 784), float32], 
          %weight1: Tensor[(128, 784), float32], 
          %bias1: Tensor[(128), float32], 
          %weight2: Tensor[(10, 128), float32], 
          %bias2: Tensor[(10), float32], 
          dst_layout="NC5n", executor=meta[Executor][0], runtime=meta[Runtime][0], hash="e88b28184aebb4db", 
          src_layout="NC", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=1d4d3b79920, kind='llvm', keys={'cpu'}, host=Target(id=1d4d3b79a00, kind='llvm', keys={'cpu'})))
        ) -> Tensor[(1, 10), float32] {

          // æ•°æ® layout è½¬æ¢
          %6 = fn (%p02: Tensor[(128, 784), float32],Primitive=1, hash="e9662aa5b8e67b96", src_layout="NC", dst_layout="NC8n"
          ) -> Tensor[(16, 784, 8), float32] {
            layout_transform(%p02, src_layout="NC", dst_layout="NC8n")
          }  
          %7 = %6(%weight1);
          
          // å¯¹åº” Relay function IR ä¸­çš„
          // %0 = nn.dense(%data, %weight1, units=None);
          // %1 = nn.bias_add(%0, %bias1);
          // %2 = nn.relu(%1);
          %8 = fn (%p01: Tensor[(1, 784), float32], %p11: Tensor[(16, 784, 8), float32], %p21: Tensor[(128), float32], Primitive=1, hash="f360b4c42be956c4", weight_layout="NC8n"
          ) -> Tensor[(1, 128), float32] {
            %3 = nn.contrib_dense_pack(%p01, %p11, units=None, out_dtype="float32", weight_layout="NC8n");
            %4 = expand_dims(%p21, axis=0);
            %5 = add(%3, %4);
            nn.relu(%5)
          } 

          // æ•°æ® Layout è½¬æ¢
          %9 = fn (%p03: Tensor[(10, 128), float32], Primitive=1, hash="86451ec737a6a453", src_layout="NC", dst_layout="NC5n"
          ) -> Tensor[(2, 128, 5), float32] {
            layout_transform(%p03, src_layout="NC", dst_layout="NC5n")
          } /* ty=fn (Tensor[(10, 128), float32]) -> Tensor[(2, 128, 5), float32] */;
          %10 = %8(%data, %7, %bias1);
          %11 = %9(%weight2);

          // å¯¹åº” Relay function IR ä¸­çš„
          // %3 = nn.dense(%2, %weight2, units=None);
          // %4 = nn.bias_add(%3, %bias2);
          // nn.relu(%4)
          %12 = fn (%p0: Tensor[(1, 128), float32], %p1: Tensor[(2, 128, 5), float32], %p2: Tensor[(10), float32], Primitive=1, hash="32a532a5919d3a8b", weight_layout="NC5n"
          ) -> Tensor[(1, 10), float32] {
            %0 = nn.contrib_dense_pack(%p0, %p1, units=None, out_dtype="float32", weight_layout="NC5n");
            %1 = expand_dims(%p2, axis=0);
            %2 = add(%0, %1);
            nn.relu(%2)
          } 
          %12(%10, %11, %bias2)
        } 
        ```

    3. æ¥ç€æ˜¯ `CodeGen` (`GraphExecutorCodegen` çš„æ–¹æ³•)ä¸­å¯¹ TE çš„ lowerï¼Œ å¯¹åº”åˆ° `tec::LowerTE` å‡½æ•°çš„è°ƒç”¨:
    
        ```c++
        // In GraphExecutorCodegen:
        // relay::backend::LoweredOutput Codegen(tvm::IRModule mod, relay::Function func,tvm::runtime::String mod_name)
        
        ...

        IRModule lowered_mod = tec::LowerTE(mod_name_, config_, [this](BaseFunc func) {
          if (func->GetAttr<String>(attr::kCompiler).defined()) {
            UpdateConstants(func, &params_);
          }
          tec::UpdateFunctionMetadata(func, this->function_metadata_);
        })(mod);
        LOG(DEBUG) << "after complile TE:" << std::endl << PrettyPrint(lowered_mod); // dmhj

        ...
        ```

        TE è¢« lower ä¹‹åçš„ IR ç”± tir Stmt ç»„æˆï¼Œ TE å‡½æ•°è¢«è½¬æ¢æˆ PrimFunc(å…ƒå¼ é‡å‡½æ•°)ï¼Œ åœ¨ ä¸‹é¢çš„ IR ä¸­ å¯ä»¥çœ‹åˆ°å‡ºç°äº† `Pointer`, `Buffer`, `AllocateNode` ç­‰ Stmt èŠ‚ç‚¹ï¼Œè¿™æ˜¯åœ¨ TE å’Œ Relay å±‚çº§ä¸ä¼šå‡ºç°çš„æŠ½è±¡

        ```c++
        def @main(
          %data: Tensor[(1, 784), float32] , 
          %weight1: Tensor[(128, 784), float32] , 
          %bias1: Tensor[(128), float32] , 
          %weight2: Tensor[(10, 128), float32] , 
          %bias2: Tensor[(10), float32] , 
          
          dst_layout="NC5n", executor=meta[Executor][0], runtime=meta[Runtime][0], hash="e88b28184aebb4db", src_layout="NC", 
          virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=1d233c937a0, kind='llvm', keys={'cpu'}, host=Target(id=1d233c94220, kind='llvm', keys={'cpu'})))
        ) -> Tensor[(1, 10), float32] {
          %0 = (%weight1,) ;
          %1 = call_lowered(@tvmgen_default_fused_layout_transform, %0, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="e9662aa5b8e67b96", "src_layout"="NC", "dst_layout"="NC8n"}}, "all_prim_fn_vars"=['tvmgen_default_fused_layout_transform']}) ;
          %2 = (%data, %1, %bias1) ;
          %3 = (%weight2,) ;
          %4 = call_lowered(@tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu, %2, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="f360b4c42be956c4", "weight_layout"="NC8n"}}, "all_prim_fn_vars"=['tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu']}) ;
          %5 = call_lowered(@tvmgen_default_fused_layout_transform_1, %3, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="86451ec737a6a453", "src_layout"="NC", "dst_layout"="NC5n"}}, "all_prim_fn_vars"=['tvmgen_default_fused_layout_transform_1']}) ;
          %6 = (%4, %5, %bias2) ;
          call_lowered(@tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu_1, %6, metadata={"relay_attrs"={__dict__={"Primitive"=1, "hash"="32a532a5919d3a8b", "weight_layout"="NC5n"}}, "all_prim_fn_vars"=['tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu_1']}) 
        }

        @tvmgen_default_fused_layout_transform = primfn(p0_1: handle, T_layout_trans_1: handle) -> ()
          buffers = {
            p0: Buffer(p0_2: Pointer(float32), float32, [128, 784], []),
            T_layout_trans: Buffer(T_layout_trans_2: Pointer(float32), float32, [16, 784, 8], [])
          }
          buffer_map = {p0_1: p0, T_layout_trans_1: T_layout_trans} {
          for (ax0.ax1.fused: int32, 0, 12544) "parallel" {
            T_layout_trans_3: Buffer(T_layout_trans_2, float32, [100352], [])[ramp((ax0.ax1.fused*8), 1, 8)] = 
              p0_3: Buffer(p0_2, float32, [100352], [])[
                ramp(((floordiv(ax0.ax1.fused, 784)*6272) + floormod(ax0.ax1.fused, 784)), 784, 8)
              ]
          }
        }

        @tvmgen_default_fused_layout_transform_1 = primfn(p0_5: handle, T_layout_trans_5: handle) -> ()
          buffers = {
            p0_4: Buffer(p0_6: Pointer(float32), float32, [10, 128], []),
            T_layout_trans_4: Buffer(T_layout_trans_6: Pointer(float32), float32, [2, 128, 5], [])
          }
          buffer_map = {p0_5: p0_4, T_layout_trans_5: T_layout_trans_4} {
          for (ax0.ax1.fused_1: int32, 0, 256) "parallel" {
            T_layout_trans_7: Buffer(T_layout_trans_6, float32, [1280], [])[ramp((ax0.ax1.fused_1*5), 1, 5)] = 
              p0_7: Buffer(p0_6, float32, [1280], [])[
                ramp(((floordiv(ax0.ax1.fused_1, 128)*640) + floormod(ax0.ax1.fused_1, 128)), 128, 5)
              ]
          }
        }

        @tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu = primfn(p0_9: handle, p1_1: handle, p2_1: handle, T_relu_1: handle) -> ()
          attr = {"from_legacy_te_schedule": True, "target": Target(id=1d233c937a0, kind='llvm', keys={'cpu'}, host=Target(id=1d233c94220, kind='llvm', keys={'cpu'})), "tir.noalias": True, "hash": "f360b4c42be956c4", "global_symbol": "tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu"}
          buffers = {
            p0_8: Buffer(p0_10: Pointer(float32), float32, [1, 784], []),
            p1: Buffer(p1_2: Pointer(float32), float32, [16, 784, 8], []),
            p2: Buffer(p2_2: Pointer(float32), float32, [128], []),
            T_relu: Buffer(T_relu_2: Pointer(float32), float32, [1, 128], [])
          }
          buffer_map = {p0_9: p0_8, p1_1: p1, p2_1: p2, T_relu_1: T_relu} {
          for (ax1.outer.ax0.outer.fused: int32, 0, 4) "parallel" {
            allocate(compute: Pointer(global float32x8), float32x8, [4]), storage_scope = global;
            allocate(compute.global: Pointer(global float32x8), float32x8, [1]), storage_scope = global {
              for (y.inner.outer.x.inner.outer.fused: int32, 0, 4) {
                compute.global_1: Buffer(compute.global, float32x8, [1], [], align=32)[0] = broadcast(0f32, 8)
                for (k.outer: int32, 0, 784) {
                  compute.global_1[0] = (compute.global_1[0] + (broadcast(p0_11: Buffer(p0_10, float32, [784], [])[k.outer], 8)*p1_3: Buffer(p1_2, float32, [100352], [])[ramp((((ax1.outer.ax0.outer.fused*25088) + (y.inner.outer.x.inner.outer.fused*6272)) + (k.outer*8)), 1, 8)]))
                }
                compute_1: Buffer(compute, float32x8, [4], [])[y.inner.outer.x.inner.outer.fused] = compute.global_1[0]
              }
              for (ax1.inner.outer: int32, 0, 4) {
                let cse_var_1: int32 = ((ax1.outer.ax0.outer.fused*32) + (ax1.inner.outer*8))
                T_relu_3: Buffer(T_relu_2, float32, [128], [])[ramp(cse_var_1, 1, 8)] = max((compute_1[ax1.inner.outer] + p2_3: Buffer(p2_2, float32, [128], [])[ramp(cse_var_1, 1, 8)]), broadcast(0f32, 8))
              }
            }
          }
        }

        @tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu_1 = primfn(
          p0_13: handle, p1_5: handle, p2_5: handle, T_relu_5: handle
        ) -> ()
          buffers = {
            p0_12: Buffer(p0_14: Pointer(float32), float32, [1, 128], []),
            p1_4: Buffer(p1_6: Pointer(float32), float32, [2, 128, 5], []),
            p2_4: Buffer(p2_6: Pointer(float32), float32, [10], []),
            T_relu_4: Buffer(T_relu_6: Pointer(float32), float32, [1, 10], [])
          }
          buffer_map = {p0_13: p0_12, p1_5: p1_4, p2_5: p2_4, T_relu_5: T_relu_4} {
          for (ax1.outer.ax0.outer.fused_1: int32, 0, 2) "parallel" {
            let cse_var_1_1: int32 = (ax1.outer.ax0.outer.fused_1*5)
            allocate(compute.global_2: Pointer(global float32x5), float32x5, [1]), storage_scope = global {
              compute.global_3: Buffer(compute.global_2, float32x5, [1], [], align=16)[0] = broadcast(0f32, 5)
              for (k.outer_1: int32, 0, 128) {
                compute.global_3[0] = (compute.global_3[0] + (broadcast(p0_15: Buffer(p0_14, float32, [128], [])[k.outer_1], 5)*p1_7: Buffer(p1_6, float32, [1280], [])[ramp(((ax1.outer.ax0.outer.fused_1*640) + (k.outer_1*5)), 1, 5)]))
              }
              T_relu_7: Buffer(T_relu_6, float32, [10], [])[ramp(cse_var_1_1, 1, 5)] = max((compute.global_4: Buffer(compute.global_2, float32x5, [1], [], align=16)[0] + p2_7: Buffer(p2_6, float32, [10], [])[ramp(cse_var_1_1, 1, 5)]), broadcast(0f32, 5))
            }
          }
        }
        ```

        å›¾ä¸­ çš„ IR çœç•¥äº† attributes ä»¥åŠ shape ä¿¡æ¯ç­‰

    4. æ¥ä¸‹æ¥é€šè¿‡ Visitor çš„æ–¹å¼DFSéå†åˆšæ‰å¾—åˆ°çš„ IR ï¼Œ å°† IR ä¸­çš„ CallNode, VarNode å’Œ ConstantNode ç­‰æŒ‰ç…§ç›¸åº”çš„è§„åˆ™è½¬æ¢æˆå¯¹åº”çš„ GraphNode; **è¿™é‡Œå€¼å¾—æ³¨æ„çš„æ˜¯ Relay GraphExecutor æ˜¯ä¸æ”¯æŒæ§åˆ¶æµçš„ï¼Œå› æ­¤å¦‚æœ Relay IR ä¸­å«æœ‰ If, Match ç­‰ï¼Œ åœ¨è¿™é‡Œä¼šæ„å»ºå¤±è´¥**ï¼š

    ```c++
    std::vector<GraphNodeRef> VisitExpr_(const VarNode* op) override {
      Expr expr = GetRef<Expr>(op);
      return var_map_[expr.get()];
    }

    std::vector<GraphNodeRef> VisitExpr_(const IfNode* op) override {
      LOG(FATAL) << "Graph executor does not support control flow (found IfNode)";
    }

    std::vector<GraphNodeRef> VisitExpr_(const ConstructorNode* op) override {
      LOG(FATAL) << "Graph executor does not support ADTs (found ConstructorNode)";
    }

    std::vector<GraphNodeRef> VisitExpr_(const GlobalVarNode* op) override {
      LOG(FATAL) << "All GlobalVarNodes should be removed before graph executor's Codegen is called";
    }
    ```
    
    æ¥ä¸‹æ¥ï¼Œ GraphNode ä¼šè¢«ç»„ç»‡åœ¨ `GraphExecutorCodegen` çš„ `std::vector<GraphObjectPtr> nodes_` ä¸­ã€‚ è¿™ä¸ªå›¾æœ€ç»ˆè¢«å†™å…¥ graph_json ä¸­:

        ```json
        {
          "nodes": [
            {
              "op": "null",
              "name": "data",
              "inputs": []
            },
            {
              "op": "null",
              "name": "weight1",
              "inputs": []
            },
            {
              "op": "null",
              "name": "bias1",
              "inputs": []
            },
            {
              "op": "null",
              "name": "weight2",
              "inputs": []
            },
            {
              "op": "null",
              "name": "bias2",
              "inputs": []
            },
            {
              "op": "tvm_op",
              "name": "tvmgen_default_fused_layout_transform",
              "attrs": {
                "hash": "e9662aa5b8e67b96",
                "num_inputs": "1",
                "src_layout": "NC",
                "dst_layout": "NC8n",
                "func_name": "tvmgen_default_fused_layout_transform",
                "flatten_data": "0",
                "num_outputs": "1"
              },
              "inputs": [
                [1,0,0]
              ]
            },
            {
              "op": "tvm_op",
              "name": "tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu",
              "attrs": {
                "hash": "f360b4c42be956c4",
                "num_inputs": "3",
                "weight_layout": "NC8n",
                "func_name": "tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu",
                "flatten_data": "0",
                "num_outputs": "1"
              },
              "inputs": [
                [0,0,0],
                [5,0,0],
                [2,0,0]
              ]
            },
            {
              "op": "tvm_op",
              "name": "tvmgen_default_fused_layout_transform_1",
              "attrs": {
                "hash": "86451ec737a6a453",
                "num_inputs": "1",
                "src_layout": "NC",
                "dst_layout": "NC5n",
                "func_name": "tvmgen_default_fused_layout_transform_1",
                "flatten_data": "0",
                "num_outputs": "1"
              },
              "inputs": [
                [3,0,0]
              ]
            },
            {
              "op": "tvm_op",
              "name": "tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu_1",
              "attrs": {
                "hash": "32a532a5919d3a8b",
                "num_inputs": "3",
                "weight_layout": "NC5n",
                "func_name": "tvmgen_default_fused_nn_contrib_dense_pack_expand_dims_add_nn_relu_1",
                "flatten_data": "0",
                "num_outputs": "1"
              },
              "inputs": [
                [6,0,0],
                [7,0,0],
                [4,0,0]
              ]
            }
          ],
          "arg_nodes": [0,1,2,3,4],
          "heads": [
            [8,0,0]
          ],
          "attrs": {
            "storage_id": [
              "list_int",
              [0,1,2,3,4,5,6,7,8]
            ],
            "shape": [
              "list_shape",
              [
                [1,784],
                [128,784],
                [128],
                [10,128],
                [10],
                [16,784,8],
                [1,28],
                [2,128,5],
                [1,10]
              ]
            ],
            "device_index": [
              "list_int",
              [1,1,1,1,1,1,1,1,1]
            ],
            "dltype": [
              "list_str",
              ["float32","float32","float32","float32","float32","float32","float32","float32","float32"]
            ]
          },
          "node_row_ptr": [0,1,2,3,4,5,6,7,8,9]
        }
        ```


5. æœ€ç»ˆ `executor_factory = _executor_factory.GraphExecutorFactoryModule()` ä¼šå°†
    
    1. è¾“å…¥çš„ Relay IR
    2. jsonè¡¨ç¤ºçš„ è®¡ç®—æ‰§è¡Œå›¾
    3. å¯¹åº”çš„æ‰§è¡Œå™¨
    4. TIRToRuntime build å‡ºçš„ runtime.module
    5. ä»£ç ç”Ÿæˆçš„ target
    6. ä¼˜åŒ–åçš„è®¡ç®—å›¾çš„è¾“å…¥å‚æ•°
    7. mod_name, func_metadata 

    æ‰“åŒ…æˆä¸€ä¸ªmoduleï¼Œ å¯ä»¥æ ¹æ®è¯¥moduleä¸­çš„ä¿¡æ¯æ„å»ºä¸€ä¸ª graph_executorï¼Œ å¹¶ åˆ©ç”¨ graph_executor åŠ è½½æ‰§è¡Œ graph

ğŸ’¡<u>**æ€»ç»“ä¸€ä¸‹**</u>: 

1. c++ ç«¯çš„ `BuildRelay` å‡½æ•°æ˜¯é€šç”¨æ¥å£ `relay.build` çš„æ ¸å¿ƒï¼Œ åœ¨ä¸Šé¢è¿‡ç¨‹ä¸­ï¼Œ æˆ‘ä»¬æ‰“å‡ºäº† Relay, TE, TIR, graph_json ç­‰å‡ ç§ä¸åŒçš„ä¸­é—´è¡¨ç¤ºï¼Œ ä» Relay åˆ° TEï¼Œ ä»TE åˆ° TIRï¼Œ å†ä» TIR ä¸­çš„å…ƒå¼ é‡å‡½æ•°è¢«ç¿»è¯‘æˆæœºå™¨ç ï¼Œ æ¯ä¸€æ­¥éƒ½ä¼šæ‰§è¡Œç›¸åº”éƒ¨åˆ†çš„ä¼˜åŒ–ã€‚ è‡³äºå…·ä½“åšäº†å“ªäº›ä¼˜åŒ–ï¼Œ TODO:

2. ä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯é€šè¿‡è¿™æ¡è·¯å¾„ï¼Œæˆ‘ä»¬åªèƒ½ç¼–è¯‘ é™æ€æ¨¡å‹ï¼Œ æ— è®ºæ˜¯æ§åˆ¶æµè¿˜æ˜¯ åŠ¨æ€ shapeï¼Œ æ”¯æŒçš„éƒ½ä¸æ˜¯å¾ˆå¥½ï¼› Relay çš„åç»­å·¥ä½œ nimble åœ¨è¿™ä¸€æ–¹é¢åšå‡ºäº†æ”¹è¿›ï¼Œå¯ä»¥å‚è€ƒ: [nimble](./paper-nimble.md)ã€‚ ç®€å•æ¥è®²ï¼Œæˆ‘ä»¬ä¸å†ä¾èµ–è¿™ä¸ªç®€å•åœ° graph_executor, è€Œæ˜¯æ„å»ºäº†ä¸€ä¸ªè™šæ‹Ÿæœºè¿›è¡Œè¿è¡Œæ—¶çš„åˆ†æã€å†…å­˜åˆ†é…ã€ç®—å­æ´¾å‘ç­‰ï¼Œåœ¨ Relax ä¸­ä¹Ÿæ˜¯è¿™æ ·åšçš„ï¼Œå› æ­¤æ¥ä¸‹æ¥çš„ä¸€èŠ‚ä»¥ Relax ä¸ºä¾‹ï¼Œ çœ‹ä¸€ä¸‹ TVM å¦‚ä½•æ”¯æŒåŠ¨æ€shapeï¼Œ åŠ¨æ€æ§åˆ¶æµï¼Œ å¦‚ä½•ä½¿ç”¨ VM è¿›è¡Œç›¸åº”æ”¯æŒã€‚

## 4. Lower Relax