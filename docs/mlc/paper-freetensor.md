# FreeTensor: A Free-Form DSL with Holistic Optimizations for Irregular Tensor Programs

## 0. Abstract
张量程序在许多领域都有重要用途。 PyTorch、TensorFlow 和 JAX 等现有框架采用基于 算子 的方式来简化编程、提高性能并执行自动微分。 然而，随着张量程序的快速发展，基于算子的编程由于引入了大量的冗余计算或内存访问而对不规则模式 (**irregular patterns**) 显示出显着的局限性。

我们提出了 FreeTensor，一种 free-form 的 DSL， 它通过**引入细粒度控制流**来支持冗余避免编程。 通过部分评估、依赖感知转换和细粒度自动微分等优化，FreeTensor 能够在 CPU 和 GPU 上生成高性能张量程序。 实验表明，对于典型的不规则张量程序，在没有微分的情况下，现有张量编程框架的加速高达 5.10 倍（平均 2.08 倍），微分后高达 127.74 倍（平均 36.26 倍）。

!!! warning "疑问"
    什么是不规则模式 irregular patterns ？


## 8. Conclusion
我们提出了 FreeTensor，一种用于不规则张量程序的free-form DSL。 FreeTensor **通过启用细粒度控制流**来支持粒度无关的 tensor 运算，并集成了一系列优化，包括部分求值、依赖感知转换 和 自动代码生成，以生成适用于不同架构的高性能代码。 FreeTensor 还支持细粒度自动微分以生成高效的梯度程序。 实验表明，在没有微分的情况下，现有张量编程框架的加速高达 5.10×（平均 2.08×），微分后高达 127.74×（平均 36.26×）。


## 1. Intro
张量程序广泛应用于不同领域，包括深度学习、计算机图形学、科学计算等。 优化张量程序至关重要，因为张量程序通常在需要大规模并行处理的数千个元素上运行才能实现高性能。 然而，这种跨各种架构的优化不仅需要大量的人力，还需要算法和架构方面的专业知识。

大多数现有的张量编程框架，都将典型的张量计算封装到 算子 中，例如矩阵乘 和 卷积。 在这些框架中，算子经过手工高度优化以实现高性能，并通过 cuDNN、cuBLAS 或 Intel MKL 等库提供给用户。

这种基于算子的框架可以覆盖某些硬件上的常见 tensor program， 但仍有重大的性能挑战尚未解决。 由于大多数优化都是在算子内部完成的，因此传统上，用户需要将一个算子应用于 tensor 中的所有元素，并将多个算子链接起来才能实现一个程序。 然而，随着模型的规模越来越大，**最近的模型倾向于在张量的一部分上进行计算以节省计算量**。 为了使用基于算子的框架来表达此类模型，张量需要来回转换，引入大量的计算和访寸开销。

我们以 Longformer 模型 [8] 为例，如图 1(a) 所示。 与传统注意力使用所有 token 计算相关性不同，Longformer 计算距离不大于阈值的成对附近 token 的相关性，因此它能够处理更长的序列。 附近 token 的范围可以看作是一个滑动窗口。 典型的基于算子的框架的一种常见实现是首先沿滑动窗口填充和复制特征矩阵 Q，如图 1(b) 所示，相应的代码如图 1(c) 所示。 由于张量 Q 被复制滑动窗口大小折叠，因此引入了显着的内存冗余。

这种类型的张量程序在新兴的深度学习模型中越来越普遍。 为简单起见，我们称它们为**不规则张量程序**。 与常见的张量程序相比，此类程序通常具有以下特点：
1. <u>细粒度操作。 需要、使用和重用的数据不在一个整体张量级别，而是由上下文决定的。</u>
2. <u>多种操作的组合。 这些张量程序通常需要组合多个张量操作来实现相应的功能。</u>

尽管用户可以在基于算子的框架中使用自定义算子，但目前的框架仅提供有限的表达力来支持不规则张量程序。 例如，JAX 和 PyTorch 中的 `vmap` 支持迭代张量并将操作应用于它的每个部分，但迭代应该是无依赖的。 TVM [12] 完全建立在自定义 算子 之上，**但每个 算子 都仅限于完美嵌套的循环，外侧是无依赖循环，内侧是 reduce 循环**。 由于这些限制，用户仍然不得不引入冗余的算子。

!!! warning "疑问"
    TVM [12] 完全建立在自定义 算子 之上，但每个 算子 都仅限于完美嵌套的循环，外侧是无依赖循环，内侧是 reduce 循环?

    这里是什么意思？


在实践中，当难以用基于算子的框架来表达张量程序时，用户仍然可以用通用的编程语言（如 Python 和 C++）表达计算。 主要原因是此类语言中的细粒度控制流可以轻松消除冗余。 在这项工作中，**我们称这样的程序为自由形式的张量程序**。 然而，如果不仔细优化，这样的程序性能会不好。 必须为每个硬件后端手动完成特定于体系结构的优化，例如缓存或 scratchpad memory（SPM）的并行化和显式利用。 此外，典型张量应用中所需的自动微分 automatic differentiation (AD) 加剧了这个问题。 原程序和它的梯度应该分开实现。 Julia [9] 等通用编程语言提供了一种与张量交互和计算梯度的简单方法。 然而，对它们进行优化仍然是一项艰巨的任务。

为了应对这一挑战，我们提出 FreeTensor，这是一种用于张量程序的避免冗余的 DSL。 与现有工作不同，我们引入细粒度张量操作以减少冗余计算和内存访问，同时将张量保持为一等公民以保持编程简单性。 **为了分析细粒度控制流引入的复杂依赖， FreeTensor 编译器利用多面体技术进行自动分析**，因此我们应用了一系列优化，包括并行化、循环转换和内存层次转换来生成 高性能代码。 此外，由于微分在张量程序中至关重要，因此 FreeTensor 支持细粒度自动微分，并通过优化来通过存储或重新计算中间张量之间的平衡来减少内存冗余。

**贡献**：

- 提出一种名为 FreeTensor 的 Free-form 的 DSL，它通过提供**粒度无关(granularity-oblivious)**的张量操作来支持避免冗余的张量编程。
- 在 FreeTensor 中提供编译优化以生成高效的张量程序，包括对具有递归的 dimension-free 程序的 部分求值、对细粒度控制流的依赖感知转换 以及 针对不同体系结构的自动代码生成。
- 支持细粒度自动微分 combined with efficient selective intermediate tensor materialization。
- 评估表明，与现有的张量编程框架相比，FreeTensor 在无微分的情况下实现了高达 5.10 倍的加速比（平均 2.08 倍），对于典型的不规则张量程序在有微分的情况下实现了高达 127.74 倍的加速比（平均 36.26 倍） .

本文的其余部分安排如下。 第 2 节用一个详细的例子描述了这个问题。 第 3 节和第 4 节描述了我们在 FreeTensor 中的 DSL 和代码生成💡。 第 5 节解决了 AD 中的性能问题。 第 6 节评估 FreeTensor 的性能。 第 7 节讨论了一些相关工作。 第 8 节总结了本文。


## 2. Background and Motivation
### 2.1. Background
现有的张量编程框架，包括 TensorFlow [3]、PyTorch [29]，将张量程序表示为对高度优化的库的调用，包括 cuDNN [15]、cuBLAS [16] 和 Intel MKL [26]。 由于张量程序的快速发展需要许多新的算子，因此提出了像 TVM [12] 这样的**代码生成框架**来减少人工工作。

然而，这些框架缺乏对新兴的不规则张量程序的有效支持，这些程序具有对完整张量进行部分操作或复杂控制依赖的特点。 为了迎合当前的框架，这些程序中引入了冗余计算和内存访问。 尽管像 Julia [9] 这样的通用编程语言可以部分消除这些冗余，但由于缺乏领域知识，它们仍然无法生成高性能代码。

### 2.2. Motivating Example
我们以图 2 中的 SubdivNet [19] 为例来说明现有框架的局限性以及 FreeTensor 的工作原理。 SubdivNet 的主要组成部分是 mesh 上的多重卷积。 类似于传统卷积结合每个像素及其相邻像素的特征，SubdivNet 中的网格卷积结合每个 face 及其相邻 faces 的特征。 为了克服 faces 之间的顺序不变性，SubdivNet 引入了循环差分计算，如图 2(a) 的红框所示。 对于每个中心面 $e_i$， 通过邻接数组找到其三个邻面$e_j$、 $e_{j+1}$ 和 $e_{j+2}$ 的特征向量， 循环计算它们的差。

在这种情况下，特征向量 $e_j$、 $e_{j+1}$ 和 $e_{j+2}$ 被获取并针对中央 face 使用，**但如果没有额外的索引访问，则永远不会被其他中央 face 重用**。 理想情况下，它们应该单独创建和使用，而不是在每次计算之前都从中央面周围收集。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_0.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

然而，基于 算子 的框架中的典型实现需要共同操作这些数据，如图 2(b) 所示。 具体来说，如图2(c)所示，该程序的Pytorch实现包括以下步骤：

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_1.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

- 第 1 步：依次调用 `flatten`、 `index_select` 和 `reshape`，构造一个3-D 张量 `(adj_feat)` 来存储相邻面的特征。 结果张量 `adj_feat[i, j, k]` 中的每个元素存储了第 i 个 face 的 第 j 个 邻居 feature 的第 k 个因子。
- 第 2 步：对 `adj_feat` 张量进行切片，对其重新排序，然后连接，现在面 $e_{j+1}$ 与原始面 $e_j$ 具有相同的索引。
- 第 3 步：做一个减法并计算它们的绝对值，最后求和。

尽管每个算子都受益于供应商提供的库中高度优化的本机代码，但每个中间值都应存储为全尺寸张量，如图 2(b) 所示。 这引入了显著的内存访问冗余：张量 `adj_feat` 的大小为 `n_faces * 3 * n_feat`，这比输入和输出张量大得多，并且会产生巨大的内存访问开销。 此外，还包括冗余算子 `flatten`、 `index_select`、`reshape` 和 `cat` ，它们仅用于重新排列现有数据，但不执行有意义的计算。

即使 TVM 支持高度自定义的算子，张量上的间接索引仍然阻止它在不组合传统算子的情况下表示程序，如图 2(b) 所示。 像 Julia 这样的通用编程语言能够在细粒度控制流中表示这种情况。 但是，它需要大量的手动优化和并行化。

### 2.3. Challenge of FreeTensor
为了解决上述问题，我们**采用细粒度的控制流避免冗余内存访问**，如图 3(b) 所示。 具体来说，我们迭代每个 face i 及其邻居 j，并直接从输入张量 e 中索引第 j 和 (j+1) 个面。 之后进行细粒度的张量运算计算差值，结果直接累加到一个张量 y。 这里，$e_j$、$e_{j+1}$ 和 $e_{j+2}$ 是单独的张量，如图 3(a) 所示，其中每个张量操作都是细粒度的并单独执行。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_2.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

FreeTensor 采用这种细粒度的方法来操作每个张量。 与基于 算子 的实现相比，FreeTensor 中的程序以按需方式访问张量元素，没有多余的操作来预先重新排列它们。 然而，FreeTensor 带来的复杂控制流给高效代码生成带来了重大挑战。 我们在这里总结了主要挑战。

- **存在依赖性的优化**。 FreeTensor 引入的细粒度控制流使得高效代码生成变得更加困难。 我们希望 FreeTensor 无需太多手动操作即可自动生成高性能代码。 然而，<u>复杂的控制和数据依赖阻碍了转换</u>。

- **复杂控制流的高效自动微分**。 具有复杂控制流的程序的自动微分 (AD) 会进一步引入大量冗余，这抵消了自由格式语言提供的好处。 如何设计高性能的AD机制更具挑战性。

## 3. Free-Form DSL
本节介绍我们如何为不规则张量程序设计 Free-Form DSL。 作为张量程序的 DSL，张量被视为简化编程的一等公民。 为了支持对部分张量的操作以消除冗余计算和内存访问，FreeTensor 通过引入细粒度控制流和部分张量索引来支持任何粒度的张量操作。 此外，为了生成高性能代码，FreeTensor 为用户提供了额外的元信息和编程指导，以辅助底层编译。 本节的其余部分将详细说明上述设计。

### 3.1. Tensors as First-Class Citizens
**张量定义**。 FreeTensor 将张量视为一等公民以减轻编程难度。 更具体地说，张量（各种元素类型）是 FreeTensor 中的主要数据类型。 我们称维度为 $N$ 的张量为 $N-D$ 张量，标量被视为 0-D 张量。 张量存储在紧凑的内存布局中，一旦创建张量形状就不可改变。 **为了保证张量之间没有重叠，张量按值进行复制**。 张量元素可以是任何基本标量数据类型，包括 整数、单/双/半浮点数等，涵盖了典型张量程序的需求。

**张量索引**。 图 4 显示了 FreeTensor 如何定义和索引张量。 张量可以定义在不同的设备上，包括 CPU、GPU 等。FreeTensor 提供了用户友好的 NumPy [18] 风格的索引规则，能够索引张量中的任何子区域。 **这种索引规则允许用户对 部分张量 进行索引，从而灵活地支持对 部分张量 的操作**，以避免不必要的计算和内存访问。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_3.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

FreeTensor 的 DSL 中的所有操作，包括算术运算符（`+`、`-`、`*`、`/` 等）、内置函数（sum、abs 等）和函数调用，都直接在张量上执行。 然后将这些操作降低为高性能本机代码，这将在[第 4 节](#4-generating-high-performance-code)中介绍。

### 3.2. Granularity-Oblivious Tensor Operations
由于不规则张量程序通常操作张量的一部分而不是整个张量以节省计算量，因此支持部分张量操作是必要的。 传统的基于算子的框架的用户被期望调用尽可能粗粒度的算子。 如第 2 节所述，使用此类张量算子实现不规则张量程序将带来大量计算和访存冗余。 为了解决这个问题，我们在 FreeTensor 中引入了 Granularity-Oblivious Tensor Operations，以提供编写避免冗余的张量程序的能力。

为了实现 Granularity-Oblivious 的张量操作，我们**在 DSL 中引入了以下语义：整数范围的 for 循环、分支 和 始终内联的函数调用**。 我们将在第 4 节中详细解释为什么要引入这些关键特性。借助这些语义，FreeTensor 可以支持任何粒度的张量操作。 图 5 显示了如何使用 FreeTensor 实现图 1 中的 Longformer 示例。 在这种情况下，我们使用 for 循环 `j` 沿输入序列进行迭代，并使用循环 `k` 沿滑动窗口进行迭代。 K 的元素直接通过索引 `j+k` 访问，无需事先复制整个张量。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_4.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

FreeTensor 还提供了一个称为 `libop` 的张量算子库，支持 element-wise operations, reductions, matrix multiplications 等简单算子 和 softmax 等复杂算子。 我们在纯 DSL 代码中实现 `libop`，而不是直接映射到本机代码实现。 在编译时，对 libop 的函数调用将作为嵌套循环完全内联，然后与程序的其余部分一起优化。 例如，图 3(b) 中的 tensorwise zeros、abs、- 和 += 都是由 `libop` 提供的。

!!! note "note"
    libop: 类似 TOPI 之于 TE？


### 3.3. Dimension-Free Programming
张量维数是张量计算的关键属性，张量程序的大多数操作都与围绕张量维数的变换密切相关。 我们在张量的元数据中记录与维度相关的属性，它也享有一流的支持。 可以分别使用 `.ndim`、`.shape`、`.dtype` 和 `.mtype` 属性访问 维度、形状、元素类型和设备放置。 **特别是，张量形状保持其表达形式**。 例如，将 $N\times 2$ 的二维张量 A 展平为一维张量 B 后，**我们知道 B 的长度应该是 $2N$ ，而不是 Any**。 我们可以安全地断言 $2N$ 是偶数并将 B 重塑回 $N\times 2$ 形状。

**在 FreeTensor 中，我们用有限递归表达对任意维度的计算**。 图6 给出了如何使用有限递归编写 Dimension-Free 张量程序的示例。 如 图6(a) 所示，如果在编写张量程序时无法确定张量的形状，用户将无法编写简单的嵌套循环程序，这会带来很大的编程复杂度。 在 FreeTensor 中，我们建议用户<u>**使用有限递归编写具有未确定维度的张量程序**</u>，如 图6(b) 所示。 这种递归将进一步扩展为在编译时使用 部分求值 的嵌套循环，这将在第 4.1 节中说明。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_5.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

## 4. Generating High Performance Code
FreeTensor 允许用户编写无冗余计算或内存访问的张量程序。 DSL 编写的程序将被解析为 stack-scoped AST，作为 FreeTensor 的IR，以执行进一步的优化并生成高性能的 native code。 通过这种设计，每个张量仅在其定义节点的子树中存在，称为 `TensorDef` 节点。 stack-scoped 的限制为 IR 转换带来了显著的简化：

1. 能够在不破坏 allocation-freeing pair 的情况下转换 AST；
2. 通过将一个张量的生命周期限制在一个子树上，**可以消除大部分依赖分析中的假依赖**。

!!! warning "疑问"
    这里所说的依赖分析中的假依赖是？

    可能需要具体了解一下编译优化过程中的依赖分析是怎么做的。


图7 显示了 `LongformerFwd` 函数的 AST，其代码在 图5 中。我们内联所有函数调用以执行跨函数的整体优化。 图8 显示了 图5 中示例的结果程序。之后，我们对 AST 进行了多次优化。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_6.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

### 4.1. Partial Evaluation for Dimension-Free Programming
如 [3.3 节](#33-dimension-free-programming)所述，用户可以编写具有有限递归的函数。 FreeTensor 通过根据张量的元数据对程序 部分求值 来支持这种特性。 通过使用元数据为张量提供一流的支持，程序中所有张量的维数在编译时都是已知的，这使得对用递归实现的一般维数程序应用 部分求值 成为可能。

我们以 图6(b) 中的代码为例来说明评估过程，如 图9 所示。图9(a) 是原始程序，带有递归函数调用 add。 假设 A 是一个 3-D 张量，那么我们的编译器知道 `if` 条件总是假的，所以 `if` 分支中的所有语句都会被丢弃，而 `else` 分支中的语句将始终被执行。 然后评估最后一行的函数调用 add，生成如 图9(b) 所示的优化程序。 然后编译器重复图 9(b) 中的这种 部分求值 过程。 请注意，`A[i]` 是一个二维张量。 最后，应用 部分求值 后的最终程序如图 9(c) 所示，其中递归函数调用转换为嵌套循环。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_7.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

### 4.2. Dependence-Aware Transformation
内联后，我们需要对 AST 执行一系列转换，以从 FreeTensor IR 生成高效代码。 我们为各种优化应用了丰富的转换集合，包括循环转换、并行化、内存层次结构、内存布局等，如表 1 所示。这些转换类似于 Halide [31] 和 TVM 的调度优化 [12]，但细粒度的控制流程对如何正确应用这些转换带来了重大挑战。 例如，**TVM 仅支持对完美嵌套循环的转换**，这意味着转换时不需要考虑复杂的依赖关系。 

!!! note "note"
    完美嵌套循环指 循环体仅在最内层循环


然而，在应用细粒度控制流之后，引入了复杂的依赖。 仍然以 图8 为例，在第4、13、16行融合循环可以带来更好的局部性。 融合第 4 行和第 13 行的循环是可能的，但融合第 13 行和第 16 行的循环是不正确的，因为后者依赖前者产生的 `dot_max` 。 融合程序如 图10 所示，其中将偏移量 "+w" 应用于迭代器 k，以使索引保持一致。

由于依赖关系决定了转换是否正确，因此 FreeTensor 在应用转换之前执行依赖性分析。 **与基于算子的框架不同，我们需要以 instance-of-statement-wise 精度而不是statement-wise 精度来分析程序**，其中 instance-of-statement 是指特定循环迭代中的语句。 这意味着**传统的数据流图级分析对于 FreeTensor 来说是不够的**。

关于如何以 instance-of-statement 的精度分析依赖关系以及如何在给定依赖关系的情况下指导程序转换，已经有很多研究。 [28] 和 [4] 中总结了早期研究。 后来引入了多面体分析的数学理论系统地分析相关性，并设计了多个多面体分析求解器来实现分析的自动化。 给定定义为 Presburger 公式的内存访问，可以通过求解它们的方程和不等式来导出依赖关系 [40]。 多面体分析理论和求解器的著作包括 Omega [30]、PolyLib [23]、PPL [6] 和 isl [39]。

在 FreeTensor 中，我们使用 isl 进行依赖分析，并在我们的 IR 中实现 [28] 和 [4] 中讨论的依赖感知程序转换的想法。 在本节的其余部分，我们将说明 FreeTensor 如何采用这些技术来执行**依赖感知转换，包括循环转换、并行化转换和内存转换**。

#### 4.2.1. 循环变换
<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_8.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

以 图11 中的程序为例。 (2) 和 (1) 之间存在先写后读 (RAW) 依赖关系，(3) 和 (1) 之间存在 RAW 依赖关系。 在转换循环时，我们需要保持两者的依赖性。
在多面体分析中，每个内存访问 (1)、(2) 或 (3) 都定义为自迭代空间$\mathbb{Z}^{(N−2)\times (M−2)}$ 到数组索引空间$Z^{N\times M}$ 的映射，描述哪个在迭代中访问数组哪个索引：

$M_{(1)} = \{(i,j)\rightarrow (i+1,j): 1\leq i < N-1, 1\leq j < M-1\}$
$M_{(2)} = \{(i,j)\rightarrow (i-1,j+1): 1\leq i < N-1, 1\leq j < M-1\}$
$M_{(3)} = \{(i,j)\rightarrow (i-1,j-1): 1\leq i < N-1, 1\leq j < M-1\}$

通过使用 `isl` 组合这些映射，我们推断(2) 和 (1) 之间的原始依赖关系为：

$$
\begin{align*}
M_{(2)\rightarrow (1)}
&=\{\mathbf{p}\rightarrow \mathbf{q}: \exists \mathbf{r}: (\mathbf{p}\rightarrow \mathbf{r})\in M_{(1)} \wedge (\mathbf{q}\rightarrow \mathbf{r}\in M_{(2)}\wedge \mathbf{p}>_{lex} \mathbf{q}) \}\\
&=\{(i,j)\rightarrow (i-2,j+1): 1\leq i < N-1, 1\leq j < M-1\}
\end{align*}
$$

其中 >𝑙𝑒𝑥 表示字典序更大，∧ 表示逻辑与。

从 $M_{(2)\rightarrow (1)}$ ，我们知道 (1) 在 i 中应该比 (2) 晚 2 次迭代，在 j 中应该早 1 次迭代。 我们在转换循环时保留此限制。 例如，我们不能对这两个循环重新排序，否则该语句将访问一个尚未计算的元素。 (3) 和 (1) 之间依赖关系的限制是相似的。

为了更具体地解释依赖性如何限制循环转换，我们以 图12 中的示例为例，讨论是否可以在嵌套循环上应用重新排序转换。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_9.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

- 对图 12(a) 中的程序应用重新排序是正确的，因为沿着每个循环的反向方向没有依赖性。
- 对图 12(b) 中的程序应用重新排序是不正确的，因为存在依赖关系 $(𝑖, 𝑀 − 1) → (𝑖 + 1, 0)$
- 对图 12(c) 中的程序应用重新排序是正确的，因为加法交换律允许我们以任何顺序将 `b[i,j]` 还原为 a。 FreeTensor 引入了一个 `ReduceTo` 节点来处理任何类似 `a=a+b` 的语句，`ReduceTo` 节点之间的任何 `WAW` 依赖都可以忽略。
- 对图 12(d) 中的程序应用重新排序是正确的，因为具有 WAW 相关性的 t 是错误的相关性。 FreeTensor 的栈范围 AST 可以很容易地过滤掉错误的依赖。 在这种情况下，张量 t 存在 WAW 相关性 (𝑖1, 𝑗1, 𝑘1) → (𝑖2, 𝑗2, 𝑘2)。 由于 t 的生命周期在循环 j 内，FreeTensor 对 t 的依赖执行投影 {(𝑖, 𝑗, 𝑘) → (𝑘) : 𝑖, 𝑗, 𝑘 ∈ Z}，导致依赖 (𝑘1) → (𝑘2) . 因此，FreeTensor 可以对循环 i 和 j 应用重新排序变换。

#### 4.2.2. 并行化转换
并行化转换对于高性能代码生成至关重要。 并行化转换的挑战不仅来自细粒度控制流引入的复杂依赖性，还来自不同硬件架构上的各种并行模型。 我们以图 13 中的示例来说明 FreeTensor 如何应用并行化转换。

<div class="autocb" style="text-align:center;"><img src="./paper-freetensor.assets\autocb_10.png" style="zoom: 50%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

- 图 13(a) 显示了一个没有依赖性的可并行化程序。
- 图 13(b) 显示了一个具有跨线程依赖性的不可并行化示例。
- 在图13(c)中，是否可以应用并行化转换与具体的并行模型和内存层次有关。 例如，如果 b 是线程本地的，则循环 i 无法并行化，因为 b 仅在其中一个线程上可见； 但是如果 b 存储在共享内存中，则可以并行化此循环，因为 b 在所有线程上都是可见的。
- 图 13(d) 显示了一个 reduce 以及相同的索引，可以使用并行 reduce 算法。
- 图 13(e) 显示了随机访问 reduce ，它可以使用原子指令并行化。

#### 4.2.3. 内存转换
需要应用两种类型的内存转换：**内存布局优化**和**内存层次结构优化**。 内存布局转换通过重新排序张量中的元素来帮助改善数据访问中的空间局部性。 例如，我们可以将 (𝑁 × 𝑀) 形张量转置为 (𝑀 × 𝑁 ) 形，这样 𝑁 维就可以连续迭代。

不同于 **TVM 中通过改变 算子 的组合来执行内存布局优化**的设计，我们将这些优化实现为细粒度的 AST 转换，这提供了更多与其他转换一起执行整体优化的机会。 内存层次结构转换有助于在处理器上使用高速缓存和暂存器内存。

!!! warning "疑问"
    这里需要去了解 TVM 中 的内存布局优化具体怎么做的，找一个例子？

`cache` 和 `cache_reduce` transformations 将新张量引入 AST，我们必须推断它们的大小。 对于 图14(b) 中的程序，问题是如何推断新引入的张量 `a.cache` 的形状为 M 并且 c[j] 映射到 a[i+j]。 为了解决这个问题，我们分析了张量的每个索引的下界和上界，在这个程序中是i+j。 0、i、i+j都是i+j的下界，n+m-2、i+m-1、i+j都是它的上界。 我们遵守所有这些界限。 由于我们在外循环和内循环之间进行 cache ， 其中迭代器 i 已定义但 j 未定义，因此我们寻找最紧的边界，即 `[i, i+m-1]`，或 `[i, i+m)`. 因此，我们知道我们正在将 `a[i:i+m]` 缓存到 m 形张量 `a.cache` 中。

### 4.3. Code Generation
我们提供的所有转换都暴露给用户。 我们提供了一个 API 来查询程序中的语句以应用转换。 我们还认识到，使用这些转换优化程序可能需要一些专业知识，并且大多数用户可能期望自动策略来应用这些转换。 FreeTensor 实现了**基于规则的自动转换**策略的原型来应对此类挑战。 我们目前实施 6 种 pass 以尝试应用转换。 这些 pass 由考虑特定架构的启发式方法驱动，并逐一调用。 多亏了 4.2 节中的依赖分析，我们可以积极地尝试转换而不用担心它们的正确性。  passes 包括：

1. `auto_fuse` ：尝试使用融合附近的循环以增加局部性。 可能需要启用 swap 等转换来启用 fuse。
2. `auto_vectorize` ：找到一些连续访问数据的循环，使用循环转换将它们重新排序为最内层循环，然后向量化或并行化该循环。
3. `auto_parallelize` ：用 merge 转换合并一些外层循环，然后用 parallelize 转换绑定到线程上。 对于像 GPU 这样具有多级并行性的后端，我们在绑定它们之前使用 split 拆分循环。
4. `auto_mem_type` ：尝试将张量放置在尽可能靠近处理器的位置。 寄存器优于 scratch-pad memory，后者又优于 main memory。
5. `auto_use_lib` ：尝试 调用外部库。 可能需要启用 fission 等转换来启用 该 pass。
6. `auto_unroll` ：展开非常短的循环，为后端编译器释放优化机会。

对于任何用户程序，这些过程会自动调用，但用户可以自由覆盖它们并手动应用其他转换。 除了这些基本策略之外，我们正在研究类似于 Ansor [44] 的机器学习引导解决方案，这将是我们未来的工作。

我们在转换后对 AST 进行进一步优化，包括简化数学表达式、合并或删除冗余内存访问以及删除冗余分支。 我们还执行一些特定于后端的后处理，包括插入线程同步语句、生成并行缩减语句以及计算暂存器中张量的偏移量。

之后，我们从 AST 生成 OpenMP 或 CUDA 代码，并调用专用后端编译器（如 gcc 或 nvcc）进行进一步的低级优化和本机代码生成。 **一个DSL函数最终被编译为共享库，可以从Python中动态加载运行**。

## 5. Automatic Differentiation

!!! note "note"
    暂时跳过这一节

### 5.1. Fine-Grained Automatic Differentiation
张量应用需要自动微分 (AD)。 AD 帮助用户从原始程序生成梯度程序，其中梯度程序用于计算每个输入相对于程序输出的梯度。 梯度程序由正向传播和反向传播组成。 正向传递计算输出，同时在执行期间保留一些中间张量。 向后传递计算梯度并重用前向传递保留的中间张量。

受 Enzyme [27] 和 Zygote [20] 的启发，我们设计了一种通用 AD，能够区分 FreeTensor 引入的细粒度控制流。 图 15(b) 给出了从图 15(a) 中的原始程序生成的反向传播示例。 我们记住，微分程序仍然可以通过 FreeTensor 进行优化。 因此，我们将 AD 设计为 AST 的 pass 。 生成的程序也是一个 AST，享有与原始程序相同的优化机会。

阻碍优化微分程序的问题之一在于中间张量。 在 AD 的过程中，一些中间张量应该在前向传递中具体化，然后在反向传递中取回。

在某些文献中，此过程也称为检查点或将 tensor 保存到 tape 中。 但是，一个中间张量在程序中可能会被多次写入，因此必须将其具体化为多个版本。 例如，图 15(a) 中的标量 t（被视为 0-D 张量）将在其第 i 个分配后在版本 i 中被具体化。 一些现有的作品如 Tangent [36] 和 Zygote [20] 在运行时维护一个版本号，这阻碍了进一步的并行化。 相反，我们分析了 FreeTensor 中的符号版本号，类似于 Enzyme [27]。 具体来说，利用多面体分析，我们寻找对 t 的 WAR 依赖，其中每个 WAR 依赖对应一个版本。 因此，版本号在编译时作为符号表达式已知，这有助于进一步并行化。

### 5.2. Selective Intermediate Tensor Materialization
在图 15 中， `t` 存储在原始程序中，直到与 `t.tape` 一起重复使用。 在上面的例子中， `t` 是一个标量，可能存储在缓存甚至寄存器中。 然而，随着每次迭代 i 更新 t，前向传递将具体化其所有版本以供将来使用。 因此，t 的具体化张量，即 `t.tape`，具有较大的形状 n，这在内存占用和内存使用方面都会产生很大的开销。

相反，在这种情况下，计算 t 只需要对 a[i] 和 b[i] 进行一次加法和两次访问，其中 a[i] 和 b[i] 被很好地缓存，因为它在计算 a 时共享。 grad[i] 和 b.grad[i]。 受先前提出的用于减少基于算子的框架的内存使用的重新计算方法的启发 [13]，我们提出了一种用于中间张量物化的选择性策略。

我们方法的核心思想是我们将确定中间张量是在编译时具体化还是重新计算。 我们平衡物化和重新计算之间的开销，并选择合适的策略。 对于图15所示的程序，我们对其非密集计算采用重计算策略。 生成的程序如图 15(c) 所示。 将张量具体化的开销取决于张量有多少个版本。 图 15 中的 t 更新了 n 次，因此它必须在 n 个版本中具体化，由于我们的符号版本号分析，版本号在编译时是已知的。

## 6. Evaluation
...

## 7. Related Works
<u>**基于算子的框架**</u>。 有多个基于算子的框架，包括 Chainer [34]、PyTorch [29]、MXNet [11]、TensorFlow [3]、JAX [17] 和 TVM [12]。 Chainer 和 PyTorch 作为高性能张量算子库运行，可以从 Python 命令式调用。 MXNet 和 TensorFlow 将程序转换为数据流图，其中每个节点代表对库中张量算子的调用。 可以在执行前对图进行优化。 JAX 通过引入 JIT 来优化复杂或动态程序，从而改进优化。 TVM 通过引入 计算-调度 编程模型支持高度定制的算子，用户首先指定计算的数学定义，然后使用显式或机器学习引导的转换对其进行优化 [14]。

XLA [1]、TensorRT [2]、TASO [21]、Rammer [24] 和 PET [42] 通过 re-combining 张量算子来优化张量程序。 与这些工作相比，我们一开始就尽量不引入太多的算子。

<u>**基于多面体分析的编译器**</u>。 多个编译器采用基于多面体分析的优化。 Pluto [10]、PPCG [41] 和 CHiLL [32] 正在优化 C 语言通用程序的编译器。 PPCG 设计一个分析成本模型并通过求解一个分析模型来执行优化，而 CHiLL 则在多面体分析的指导下实现用户指定的转换。

Tensor Comprehensions [37] 和 Tiramisu [5] 将多面体分析引入到张量程序中。 他们通过使用多面体分析优化现有的算子来改进基于算子的框架。 我们采用多面体分析来指导我们对用户定义的不规则张量程序进行 AST 转换。

<u>**通用编程语言中面向张量的设计**</u>。 通用编程语言也有一些改进，以更好地支持张量。 Julia [9] 提供了对张量的有效支持，其中对张量操作的连续调用可以自动与宏融合。 Triton [33] 改进了 CUDA 并提供了一个平铺编程模型，用于在 GPU 上实现张量运算。

<u>**自动微分**</u>。 有几种方法可以实现自动微分 [7, 35]。 大多数基于算子的框架实现的 AD 都是基于图的，其中一个节点代表对张量运算库的调用，一条边代表一个张量 [25, 29]。 AD 过程将所有节点替换为其梯度对应物，并使用链式法则反转图的顺序。

Tangent [36]、Myia [35]、Enzyme [27] 和 Zygote [20] 通过直接变换 IR 为一般张量程序实现 AD。 我们在 FreeTensor 中采用了这种技术，并进一步解决了它的性能问题。