# MLIR-TOY Example

> **Ref**:
>
> - [MLIRçš„æ³•å®ï¼šDialects](https://zhuanlan.zhihu.com/p/102212806)
> - [ã€ä»é›¶å¼€å§‹å­¦æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨ã€‘åäºŒï¼ŒMLIR](http://giantpandacv.com/project/%E9%83%A8%E7%BD%B2%E4%BC%98%E5%8C%96/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8/%E3%80%90%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E8%AF%91%E5%99%A8%E3%80%91%E5%8D%81%E4%BA%8C%EF%BC%8CMLIR%20Toy%20Tutorials%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80/)

## 1. Chapter1: Toy è¯­è¨€å’Œ AST

è¿™ä¸ªæ•™ç¨‹ç”¨çš„æ˜¯kaleidoscope çš„å˜å½¢ï¼Œ ä¸€ä¸ªä¾‹å­å¦‚ä¸‹ï¼š

```py
# RUN: toyc-ch1 %s -emit=ast 2>&1 | FileCheck %s

# User defined function that æ“ä½œ **ä»»æ„** å½¢çŠ¶çš„å‚æ•°ï¼ˆç±»æ¯” function templateï¼‰
def multiply_transpose(a, b) {
  return transpose(a) * transpose(b);
}

def main() {
  # `a` shape <2, 3>; å…¶ shape ä»å­—é¢é‡æ¨æ–­è€Œæ¥
  var a = [[1, 2, 3], [4, 5, 6]];
  # b ä¸ a å®Œå…¨ç›¸åŒ, literal array is **implicitly reshaped**
  var b<2, 3> = [1, 2, 3, 4, 5, 6];

  # This call will specialize `multiply_transpose` with <2, 3> for both
  # arguments and deduce a return type of <2, 2> in initialization of `c`.
  var c = multiply_transpose(a, b);
  # A second call to `multiply_transpose` with <2, 3> for both arguments will
  # reuse the previously specialized and inferred version and return `<2, 2>`
  var d = multiply_transpose(b, a);
  # A new call with `<2, 2>` for both dimension will trigger another
  # specialization of `multiply_transpose`.
  var e = multiply_transpose(b, c);
  # call `multiply_transpose` with ä¸åŒ¹é…çš„ shape will å¯¼è‡´ä¸€ä¸ª inference error
  var f = multiply_transpose(transpose(a), c);
}
```

æ‰§è¡Œ`.\bin\toyc-ch1 ..\mlir\test\Examples\Toy\Ch1\ast.toy -emit=ast`

ä¸Šé¢ Toy ç¨‹åºäº§ç”Ÿçš„ AST(å»æ‰æºç ä½ç½®ä¿¡æ¯):

```c++
Module:
Function
    Proto 'multiply_transpose' 
    Params: [a, b]
    Block {
    Return
        BinOp: * 
        Call 'transpose' [ var: a ]
        Call 'transpose' [ var: b ]
    } // Block
Function
    Proto 'main' 
    Params: []
    Block {
    VarDecl a<> 
        Literal: <2, 3>[ <3>[ 1.000000e+00, 2.000000e+00, 3.000000e+00], <3>[ 4.000000e+00, 5.000000e+00, 6.000000e+00]] 
    VarDecl b<2, 3> 
        Literal: <6>[ 1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00] 
    VarDecl c<> 
        Call 'multiply_transpose' [ var: a var: b ]
    VarDecl d<> 
        Call 'multiply_transpose' [ var: b var: a ]
    VarDecl e<> 
        Call 'multiply_transpose' [ var: b var: c ]
    VarDecl f<> 
        Call 'multiply_transpose' [ 
            Call 'transpose' [ var: a ]
            var: c 
        ]
    } // Block
```



## 2. Chapter2. ç”Ÿæˆåˆçº§ MLIR
é¦–å…ˆè¯´äº†ç¼–è¯‘å™¨é¢†åŸŸçš„è½¯ä»¶ç¢ç‰‡åŒ–é—®é¢˜ï¼š

> åƒ LLVM è¿™ç§ç¼–è¯‘å™¨ï¼Œ æä¾›äº†a fixed set of predefined types and (usually low-level / RISC-like) instructionsã€‚ ä½†å°½ç®¡ä¸åŒçš„å‰ç«¯å¯ä»¥é‡ç”¨LLVMï¼Œç”ŸæˆLLVMIRè¿™ä¸€ç»Ÿä¸€çš„ä¸­é—´è¡¨ç¤ºï¼Œä½†æ˜¯ åƒC++ è¿™æ ·çš„è¯­è¨€éœ€è¦è‡ªå·±å®ç° high level AST(ä¾‹å¦‚ clang AST, Rust AST)ï¼Œ å®Œæˆè¯­è¨€ç‰¹å®šçš„ç±»å‹æ£€æŸ¥ã€åˆ†æ(å¦‚C++çš„æ¨¡æ¿ç‰¹åŒ–ï¼ŒRustçš„ç”Ÿå‘½å‘¨æœŸæ£€æŸ¥)ç­‰ã€‚ 
>
> æœ€ç»ˆæ¯ä¸€é—¨é«˜çº§è¯­è¨€éƒ½è¦å»è®¾è®¡å®ç°ä¸€å¥—è‡ªå·±çš„ASTï¼Œ å°½ç®¡è¿™äº›ASTåœ¨å¾ˆå¤šåœ°æ–¹ç›¸ä¼¼ï¼Œå°½ç®¡å†è¿™äº›ASTä¸Šçš„ä¼˜åŒ–å¾ˆç±»ä¼¼ï¼Œä½†æ˜¯å½¼æ­¤ä¹‹é—´æ— æ³•é‡ç”¨ï¼Œé€ æˆè½¯ä»¶ç¢ç‰‡åŒ–ã€‚ 
>
> MLIR å¤©ç”Ÿä¸ºå¯æ‰©å±•ã€å¯é‡ç”¨è€Œè®¾è®¡ï¼Œ MLIRä¸­æœ‰å¾ˆå°‘çš„å†…ç½®ç±»å‹å’ŒæŒ‡ä»¤ï¼Œ å³æ‰€è°“çš„ (little builtin, everything customizable) è®¾è®¡åŸåˆ™ã€‚å®ƒçš„æ„¿æ™¯æ˜¯æä¾›ä¸€å¥—æ„å»ºIRçš„åŸºç¡€è®¾æ–½ï¼Œ å³ä½¿ç”¨MLIR æ¥æ„å»ºIRï¼Œ è¿™æ ·ä¸åŒçš„IR ä¹‹é—´æœ‰å·®å¼‚ï¼Œä½†æ˜¯èƒ½å…±ç”¨å¾ˆå¤šéƒ¨åˆ†ï¼Œèƒ½åˆ©ç”¨å·²ç»å……åˆ†æˆç†Ÿçš„ç¼–è¯‘å™¨é¢†åŸŸçš„æˆæœå’Œè¿™ä¹ˆå¤šå¹´ç§¯ç´¯ä¸‹æ¥çš„æœ€ä½³å®è·µï¼Œè€Œä¸æ˜¯å»é‡å¤"å‘æ˜"ä¸€äº›"æ–°æŠ€æœ¯"å‡ºæ¥ã€‚
>
> the system should encourage one to design reusable abstractions and assume they will be used outside of their initial scope.


ä¸Šé¢æåˆ° MLIR è¢«è®¾è®¡ä¸ºå¯æ‰©å±•çš„åŸºç¡€è®¾æ–½ï¼Œæ²¡æœ‰å°é—­çš„å±æ€§é›†ï¼Œç±»å‹é›†ï¼Œæ“ä½œé›†ï¼› MLIR é€šè¿‡ æ–¹è¨€ Dialects çš„æ¦‚å¿µæ¥æ”¯æŒè¿™ç§å¯æ‰©å±•æ€§ã€‚ **ä¸€ä¸ª Dialect å°±æ˜¯ç”¨æˆ·(æˆ–è€…MLIRé¢„å®šä¹‰)åœ¨ä¸€ä¸ªå‘½åç©ºé—´ä¸‹æä¾›çš„ä¸€ç»„æŠ½è±¡**ï¼Œ é€šè¿‡ Dialect æ¥ç»Ÿä¸€ä¸åŒçº§åˆ«çš„IRã€‚


é¦–å…ˆçœ‹ä¸€ä¸ª Dialect çš„ä¾‹å­ï¼š æ‰§è¡Œ chapter2 çš„ç¨‹åº: `./bin/toyc-ch2 ../mlir/test/Examples/Toy/Ch2/codegen.toy -emit=mlir -mlir-print-debuginfo` å¾—åˆ°ç¬¬ä¸€ç« ä¸­ç¨‹åºç¤ºä¾‹çš„ **Toy Dialect è¡¨ç¤º**å¦‚ä¸‹ï¼ˆä¸‹é¢çš„ä»£ç åˆ é™¤æ‰äº† debug-info ï¼‰

```c++
module {
  toy.func @multiply_transpose(%arg0: tensor<*xf64>, %arg1: tensor<*xf64>) -> tensor<*xf64> {
    // 1. è½¬ç½®ä¸¤ä¸ªè¾“å…¥çŸ©é˜µ
    %0 = toy.transpose(%arg0 : tensor<*xf64>) to tensor<*xf64>
    %1 = toy.transpose(%arg1 : tensor<*xf64>) to tensor<*xf64>
    // 2. ç›¸ä¹˜
    %2 = toy.mul %0, %1 : tensor<*xf64>
    toy.return %2 : tensor<*xf64>
  }
  toy.func @main() {
    // var a<2, 3> = [[1, 2, 3], [4, 5, 6]];
    %0 = toy.constant dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>
    %1 = toy.reshape(%0 : tensor<2x3xf64>) to tensor<2x3xf64>
    // var b<2, 3> = [1, 2, 3, 4, 5, 6];
    %2 = toy.constant dense<[1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00]> : tensor<6xf64>
    %3 = toy.reshape(%2 : tensor<6xf64>) to tensor<2x3xf64>
    // var c = multiply_transpose(a, b);
    // var d = multiply_transpose(b, a);
    %4 = toy.generic_call @multiply_transpose(%1, %3) : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>
    %5 = toy.generic_call @multiply_transpose(%3, %1) : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>
    // print(d);
    toy.print %5 : tensor<*xf64>
    toy.return
  }
}
```

åœ¨ MLIR ä¸­ï¼Œ `Operations` æ˜¯æŠ½è±¡å’Œè®¡ç®—çš„æ ¸å¿ƒï¼Œ MLIR ä¸­çš„ instructions, functions, modules éƒ½ä½¿ç”¨ `Operation` æ¥è¡¨ç¤ºã€‚ ä»¥ä¸Šé¢ MLIR toy dialect ä¸­çš„ `transpose` æ“ä½œä¸ºä¾‹ï¼Œæ¥çœ‹çœ‹ MLIR è¡¨è¾¾å¼æ˜¯ç”±ä»€ä¹ˆç»„æˆçš„ï¼š `transpose(a)` çš„ MLIR è¡¨è¾¾å¼ç”±æ“ä½œç»“æœåç§°ã€Dialectå‘½åç©ºé—´ã€æ“ä½œåã€å‚æ•°åˆ—è¡¨ã€è¾“å…¥å‚æ•°ç±»å‹ã€è¾“å‡ºç±»å‹å’Œæ“ä½œåœ¨æºæ–‡ä»¶ä¸­çš„ä½ç½®ç»„æˆã€‚

```py
%t_tensor = "toy.transpose"(%tensor) {inplace = true} : (tensor<2x3xf64>) -> tensor<3x2xf64> loc("example/file/path":12:1)
```

- `%t_tensor`ï¼šè¿™ä¸ª Operation å®šä¹‰çš„ç»“æœçš„åå­—ï¼Œå‰é¢çš„%æ˜¯é¿å…å†²çªï¼Œè§ https://mlir.llvm.org/docs/LangRef/#identifiers-and-keywords ã€‚ä¸€ä¸ª Operation å¯ä»¥å®šä¹‰ 0 æˆ–è€…å¤šä¸ªç»“æœï¼ˆåœ¨ Toy è¯­è¨€ä¸­ï¼Œåªæœ‰å•ç»“æœçš„ Operationï¼‰ï¼Œå®ƒä»¬æ˜¯ SSA å€¼ã€‚è¯¥åç§°åœ¨è§£ææœŸé—´ä½¿ç”¨ï¼Œä½†ä¸æ˜¯æŒä¹…çš„ï¼ˆä¾‹å¦‚ï¼Œå®ƒä¸ä¼šåœ¨ SSA å€¼çš„å†…å­˜è¡¨ç¤ºä¸­è¿›è¡Œè·Ÿè¸ªï¼‰ã€‚
- `"toy.transpose"` ï¼šOperation çš„åå­—ã€‚å®ƒåº”è¯¥æ˜¯ä¸€ä¸ªå”¯ä¸€çš„å­—ç¬¦ä¸²ï¼ŒDialect çš„å‘½åç©ºé—´å‰ç¼€ä¸º `.`ã€‚ è¿™å¯ä»¥ç†è§£ä¸º Toy Dialect ä¸­çš„ transpose Operationã€‚
- `(%tensor)`ï¼šé›¶ä¸ªæˆ–å¤šä¸ªè¾“å…¥æ“ä½œæ•°ï¼ˆæˆ–å‚æ•°ï¼‰çš„åˆ—è¡¨ï¼Œå®ƒä»¬æ˜¯ç”±å…¶å®ƒæ“ä½œå®šä¹‰æˆ–å¼•ç”¨å—å‚æ•°çš„ SSA å€¼ã€‚
- `{ inplace = true }`ï¼šé›¶ä¸ªæˆ–å¤šä¸ªå±æ€§çš„å­—å…¸ï¼Œè¿™äº›å±æ€§æ˜¯å§‹ç»ˆä¸ºå¸¸é‡çš„ç‰¹æ®Šæ“ä½œæ•°ã€‚ åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªåä¸º `inplace` çš„å¸ƒå°”å±æ€§ï¼Œå®ƒçš„å¸¸é‡å€¼ä¸º trueã€‚
- `(tensor<2x3xf64>) -> tensor<3x2xf64>`ï¼šå‡½æ•°å½¢å¼è¡¨ç¤ºçš„æ“ä½œç±»å‹ï¼Œå‰è€…æ˜¯è¾“å…¥ï¼Œåè€…æ˜¯è¾“å‡ºã€‚<2x3xf64>å·ä¸­é—´çš„å†…å®¹æè¿°äº†å¼ é‡çš„å°ºå¯¸2x3å’Œå¼ é‡ä¸­å­˜å‚¨çš„æ•°æ®ç±»å‹f64ï¼Œä¸­é—´ä½¿ç”¨xè¿æ¥ã€‚
- `loc("example/file/path":12:1)`ï¼šæ­¤æ“ä½œçš„æºä»£ç ä¸­çš„ä½ç½®ã€‚**éœ€è¦æ³¨æ„çš„æ˜¯**ï¼š MLIR ä¸­çš„ loc ä¿¡æ¯ï¼ˆæºç ä½ç½®ä¿¡æ¯ï¼‰åœ¨å®é™…åº”ç”¨ä¸­æ˜¯ä¸èƒ½å»é™¤çš„ï¼Œ è¿™ä¸ åœ¨ LLVMç­‰å…¶å®ƒç¼–è¯‘å™¨ä¸­ ä¸­é™„åŠ çš„ Debug ä¿¡æ¯ä¸åŒã€‚

> In MLIR, every operation has a mandatory source location associated with it. Contrary to LLVM, where debug info locations are metadata and can be dropped, in MLIR, the location is a core requirement, and APIs depend on and manipulate it. Dropping a location is thus an explicit choice which cannot happen by mistake.
> 

ğŸ’¡<u>**é‚£æˆ‘ä»¬çš„ `codegen.toy` ä¸­çš„toyè¯­è¨€æºç æ˜¯æ€ä¹ˆæ ·è½¬æ¢æˆä¸Šé¢è¿™ä¸ª Toy Dialect çš„å‘¢**</u>ï¼š

<div class="autocb" style="text-align:center;"><img src="./mlir-toy.assets\autocb_0.png" style="zoom: 45%;box-shadow: rgba(0, 0, 0, 0.5) 10px 10px 10px; border-radius: 10px;" /></div>

ç®€å•æ¥è¯´ï¼Œæˆ‘ä»¬éå† toy è¯­è¨€çš„ ASTï¼Œ å°†å¯¹åº”çš„è¡¨è¾¾å¼ Expr è½¬æ¢æˆ Toy dialect ä¸­çš„ operationã€‚å°±å…·ä½“å®ç°æ¥è¯´ï¼Œä»toy è¯­è¨€çš„ AST(å³ `toy::ModuleAST`) åˆ° MLIR è¡¨è¾¾å¼(å³`mlir::ModuleOp`) çš„ç”Ÿæˆè¿‡ç¨‹åœ¨å‡½æ•° `dumpMLIR` ä¸­å®ç°ã€‚

> ğŸ’¡åœ¨ç»§ç»­æ¥ä¸‹æ¥çš„å†…å®¹ä¹‹å‰ï¼Œ å…ˆæ¥çœ‹ä¸€ä¸‹ MLIR Toy Example çš„ä»£ç ç»“æ„ï¼Œä»¥ç¬¬äºŒç« ä¸ºä¾‹ï¼š
>
> - <u>**include**</u>
>     - **toy**
>         - `Dialect.h`:  Toy Dialect çš„å®šä¹‰ï¼Œ ä»¥åŠ Toy Dialect ä¸Šçš„ Operation çš„å®šä¹‰ï¼›å®é™…ä¸Šè¯¥æ–‡ä»¶åªæ˜¯ç®€å•çš„åŒ…å« ç”± tablegen ç”Ÿæˆçš„ä»£ç 
>         - `MLIRGen.h`:  å£°æ˜äº† **ä» Toy AST ç”Ÿæˆ Toy Dialect çš„æ¥å£ `mlirGen`**
>         - `Ops.td`:     **æ•´ä¸ª Example ä¸­æœ€æ ¸å¿ƒçš„éƒ¨åˆ†**ï¼Œ å£°æ˜äº† Toy Dialectï¼Œ ä»¥åŠ Toy Dialect ä¸Šçš„ Operationï¼› å°†ç”± mlir-tablegen ç”Ÿæˆc++ ä»£ç 
>         - `AST.h`:      Toy è¯­è¨€çš„ AST å®šä¹‰ï¼Œ æ¥è‡ª <u>Kaleidoscope</u>ï¼Œ ä¸éœ€è¦å…³å¿ƒ
>         - `Lexer.h`:    ä¸€ä¸ª Tokenizer çš„å®ç°ï¼Œæ¥è‡ª <u>Kaleidoscope</u>ï¼Œ ä¸éœ€è¦å…³å¿ƒ
>         - `Parser.h`:   ä¸€ä¸ªé€’å½’ä¸‹é™ Parserï¼Œæ¥è‡ª <u>Kaleidoscope</u>ï¼Œ ä¸éœ€è¦å…³å¿ƒ
> 
> - <u>**mlir**</u>
>     - `Dialect.cpp`:  **ä» Toy AST ç”Ÿæˆ Toy Dialect çš„å…·ä½“å®ç°**ï¼Œ ä¸»è¦åœ¨ `MLIRGenImpl` class ä¸­å®ç°ï¼Œ è¿™ä¸ªç±»æš´éœ²ä¸€ä¸ª `mlir::ModuleOp mlirGen(ModuleAST &moduleAST)` ï¼›å†…éƒ¨å®ç°å¯¹æ¯ä¸€ç§ Toy AST(å¦‚ ExprAST, FunctionAST ç­‰) çš„è½¬æ¢
>     - `MLIRGen.cpp`:  ä¸»è¦æ˜¯ Toy Dialect ä¸Šçš„ Operation çš„å…·ä½“å®ç°ï¼Œ ç›®å‰ä¸æ˜¯ç‰¹åˆ«æ‡‚TODOï¼› è¿˜å®ç°äº†æ¯ç§ Operation çš„ print å…·ä½“å®ç°ï¼Œ ç”¨äºdump
> - <u>**parser**</u>
>     - `AST.cpp`:  Toy è¯­è¨€çš„ AST å®šä¹‰ï¼Œ æ¥è‡ª <u>Kaleidoscope</u>ï¼Œ ä¸éœ€è¦å…³å¿ƒ
> - `toyc.cpp`: toy è¯­è¨€ç¼–è¯‘å™¨çš„ cliï¼Œ å®ç°äº† `emit-MLIR` å’Œ `emit-AST` ç­‰
> 

1. dumpMLIR å®ç°åœ¨ `examples/toy/Ch2/toys.cpp` ä¸­ï¼š

    ```c++
    int dumpMLIR() {
      mlir::MLIRContext context;
      // 1. å°†æˆ‘ä»¬è‡ªå®šä¹‰çš„ toy Dialect åŠ è½½åˆ°è¿™ä¸ª MLIR Context
      context.getOrLoadDialect<mlir::toy::ToyDialect>();

      // 2. ä» cli è¯»å–çš„ inputFilename æ˜¯ '.toy' æ–‡ä»¶æ—¶ï¼Œ è°ƒç”¨ mlirGen
      auto moduleAST = parseInputFile(inputFilename);
      mlir::OwningOpRef<mlir::ModuleOp> module = mlirGen(context, *moduleAST);

      // 3. dump
      module->dump();
      // è¾“å…¥æ˜¯ .mlir ç­‰å…¶å®ƒæƒ…å†µæ—¶ï¼›çœç•¥
      ...
    }
    ```

2. ä»ä¸Šé¢å¯ä»¥çœ‹åˆ°ï¼Œå…³é”®åœ¨äº `mlirGen` æ–¹æ³•ï¼Œå…¶å®ç°åœ¨ æ–‡ä»¶ `examples/toy/Ch2/mlir/MLIRGen.cpp` çš„ `MLIRGenImpl::mlirGen` æ–¹æ³•ä¸­:

    ```c++
    /// ä½¿ç”¨ RTTI åˆ¤æ–­è¡¨è¾¾å¼ç±»å‹ï¼Œ Dispatch åˆ°å¯¹åº”çš„ codegen æ–¹æ³•
    mlir::Value mlirGen(ExprAST &expr) {
      switch (expr.getKind()) {
      case toy::ExprAST::Expr_BinOp:
        return mlirGen(cast<BinaryExprAST>(expr));
      case toy::ExprAST::Expr_Var:
        return mlirGen(cast<VariableExprAST>(expr));
      case toy::ExprAST::Expr_Literal:
        return mlirGen(cast<LiteralExprAST>(expr));
      case toy::ExprAST::Expr_Call:
        return mlirGen(cast<CallExprAST>(expr));
      case toy::ExprAST::Expr_Num:
        return mlirGen(cast<NumberExprAST>(expr));
      default:
        emitError();
        return nullptr;
      }
    }
    ```

3. codeGen çš„å…·ä½“è¿‡ç¨‹å°±æ˜¯éå†æ•´ä¸ªASTï¼Œ ç”Ÿæˆå¯¹åº”çš„ MLIR Operationï¼Œ æ’å…¥åˆ° `OpBuilder::block` ä¸­ã€‚ ä¸‹é¢æ˜¯ä¸‰ä¸ªä¾‹å­ï¼š

    ```c++
    // 1. å°† toy AST ä¸­çš„ `NumberExprAST` è½¬æˆ `ConstantOp`
    mlir::Value mlirGen(NumberExprAST &num) {
      return builder.create<ConstantOp>(loc(num.loc()), num.getValue());
    }
    // 2. å°† toy AST ä¸­çš„ `BinaryExprAST` è½¬æˆ `AddOp` or `MulOp`
    mlir::Value mlirGen(BinaryExprAST &binop) {
      mlir::Value lhs = mlirGen(*binop.getLHS());
      if (!lhs) return nullptr;
      mlir::Value rhs = mlirGen(*binop.getRHS());
      if (!rhs) return nullptr;
      switch (binop.getOp()) {
      case '+':
        return builder.create<AddOp>(loc(binop.loc()), lhs, rhs);
      case '*':
        return builder.create<MulOp>(loc(binop.loc()), lhs, rhs);
      }
    }
    // 3. å°† toy AST ä¸­çš„ `CallExprAST` è½¬æˆ `TransposeOp` æˆ–å…¶å®ƒ Op
    mlir::Value mlirGen(CallExprAST &call) {
      // é¦–å…ˆä¸º operands è¿›è¡Œ Codegen
      SmallVector<mlir::Value, 4> operands;
      for (auto &expr : call.getArgs()) {
        auto arg = mlirGen(*expr);
        operands.push_back(arg);
      }
      // Builtin calls 
      if (call.getCallee() == "transpose") {
        return builder.create<TransposeOp>(loc(call.loc()), operands[0]);
      }
      // å¦åˆ™ this is a call to a user-defined function.
      ...
    }
    ```

    è¿‡ç¨‹ä¸­ç”Ÿæˆçš„ Operation ä¼šæŒ‰é¡ºåºè¢« insert åˆ° `mlir::OpBuilder::block` ä¸­ã€‚ æœ€ç»ˆéå†ç”Ÿæˆçš„ MLIR Operationï¼Œ æ‰§è¡Œæ‰“å°ï¼Œå°±å¾—åˆ°äº†ä¸Šé¢æ‰“å‡ºæ¥çš„ MLIR è¡¨è¾¾å¼ã€‚ è¿™é‡Œçš„é—®é¢˜æ˜¯ `AddOp` `ConstantOp` ç­‰ Op æ˜¯ toy dialect ä¸­çš„å†…å®¹ï¼Œ å› æ­¤æˆ‘ä»¬éœ€è¦å®ç°å®šä¹‰è¿™äº›æ•°æ®ç»“æ„ï¼Œ é‚£ä¹ˆå…·ä½“è¯¥å¦‚ä½•åˆ©ç”¨ MLIR è¿™ä¸ªæ¡†æ¶ï¼Œå»å®šä¹‰æˆ‘ä»¬è‡ªå·±çš„ dialect å‘¢ï¼Ÿ


### 2.1. å®šä¹‰ä¸€ä¸ª Toy Dialect
æ¥ä¸‹è¿™éƒ¨åˆ†æ˜¯ å®˜æ–¹æ–‡æ¡£ç¿»è¯‘ï¼š

> ğŸ’¡**å®šä¹‰ä¸€ä¸ª Toy Dialect**
> 
> ä¸ºäº†æœ‰æ•ˆåœ°ä¸MLIRäº¤äº’ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸€ä¸ªæ–°çš„toyæ–¹è¨€ã€‚è¿™ç§æ–¹è¨€å°†æ¨¡æ‹Ÿtoyè¯­è¨€çš„ç»“æ„ï¼Œå¹¶ä¸ºé«˜çº§åˆ†æå’Œè½¬æ¢æä¾›ä¸€æ¡ç®€å•çš„é€”å¾„ã€‚
>
> ```c++
> /// Toy dialect ç»§æ‰¿è‡ª mlir::Dialect
> /// å¹¶ä¸” åœ¨æ„é€ å‡½æ•°ä¸­ registers ä¸€ç³»åˆ—è‡ªå®šä¹‰çš„ å±æ€§ã€æ“ä½œã€ç±»å‹
> /// å®ƒä¹Ÿå¯ä»¥é€šè¿‡é‡å†™ä¸€äº› virtual methods æ”¹å˜ä¸€äº› general behavior
> /// (åœ¨ä¸‹ä¸€ä¸ª chapter ä¸­å°†ä¼šè®¨è®º)
> class ToyDialect : public mlir::Dialect {
>  public:
>   explicit ToyDialect(mlir::MLIRContext *ctx);
> 
>   static llvm::StringRef getDialectNamespace() { return "toy"; }
> };
> ```
>
> ç°åœ¨å¯ä»¥åœ¨å…¨å±€æ³¨å†Œè¡¨ä¸­æ³¨å†Œè¯¥æ–¹è¨€ï¼š
>
> ```c++
> mlir::registerDialect<ToyDialect>();
> ```
>
> **ä»ç°åœ¨å¼€å§‹åˆ›å»ºçš„ä»»ä½•æ–°çš„ `MLIRContext` éƒ½å°†åŒ…å«toyæ–¹è¨€çš„ä¸€ä¸ªå®ä¾‹**ï¼Œå¹¶è°ƒç”¨ç‰¹å®šçš„ hooks æ¥è§£æå±æ€§å’Œç±»å‹ã€‚
>
> ---
> 
> ğŸ’¡**å®šä¹‰ä¸€ä¸ª Toy Dialect ä¸Šçš„ Operation**
> 
> æœ‰äº† toy dialectï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹æ³¨å†Œè¯¥ Dialect ä¸Šçš„æ“ä½œäº†ã€‚è¿™å°†å…è®¸æä¾›è¯­ä¹‰ä¿¡æ¯ç»™å‰©ä½™ç³»ç»Ÿè°ƒç”¨ã€‚ä»¥ `toy.constant` æ“ä½œçš„åˆ›å»ºè¿‡ç¨‹ä¸ºä¾‹ï¼š
>
> ```c++
> %4 = "toy.constant"() {value = dense<1.0> : tensor<2x3xf64>} : () -> tensor<2x3xf64>
> ```
>
> `toy.constant` æ“ä½œæ²¡æœ‰å‚æ•°ï¼Œæœ‰ä¸€ä¸ªåä¸ºvalue çš„ [dense elements](https://mlir.llvm.org/docs/Dialects/Builtin/#denseintorfpelementsattr)å±æ€§ç”¨æ¥è¡¨ç¤ºconstant valueï¼Œè¿”å›ä¸€ä¸ª [RankedTensorType](https://mlir.llvm.org/docs/Dialects/Builtin/#rankedtensortype)ã€‚`ConstantOp` ç»§æ‰¿è‡ª CRTP `mlir::op`ï¼Œè¯¥ç±»è¿˜éœ€è¦ä¸€äº›å¯é€‰çš„ Traits(`mlir::OpTrait`) æ¥çº¦æŸå…¶è¡Œä¸ºã€‚è¿™äº›ç‰¹å¾å¯ä»¥æä¾›é¢å¤–çš„accessors, verificationç­‰åŠŸèƒ½ã€‚
>
>
> ```c++
> class ConstantOp : public mlir::Op<ConstantOp,
>                      /// ConstantOp takes no inputs.
>                      mlir::OpTrait::ZeroOperands,
>                      /// ConstantOp returns a single result.
>                      mlir::OpTrait::OneResult,
>                      /// result of getType is `Type`.
>                      mlir::OpTrait::OneTypedResult<Type>::Impl> {
> 
>  public:
>   /// Inherit the constructors from the base Op class.
>   using Op::Op;
> 
>   /// ä¸ºè¿™ä¸ª operation æä¾›ä¸€ä¸ª unique name
>   /// MLIR ä½¿ç”¨è¿™ä¸ªåå­—åœ¨å…¨å±€æ³¨å†Œè¯¥ Operation
>   static llvm::StringRef getOperationName() { return "toy.constant"; }
> 
>   /// è¿”å› constant value by fetching it from the attribute.
>   mlir::DenseElementsAttr getValue();
> 
>   /// Operations é™¤äº† traits è¿˜å¯æä¾›é¢å¤–çš„ verificationï¼›
>   /// è¿™é‡Œæˆ‘ä»¬å°†ç¡®ä¿ specific invariants of the constant
>   /// operation are upheld. ä¾‹å¦‚ï¼Œ è¿”å›ç±»å‹å¿…é¡»æ˜¯ TensorType.
>   LogicalResult verify();
>
>   /// æä¾›ä»input values æ„å»ºè¯¥ operation çš„æ¥å£
>   /// builder å°†ä¼šä½¿ç”¨è¿™ä¸ªæ¥å£ï¼Œä»è€Œèƒ½å¤Ÿç®€å•åœ°ç”Ÿæˆè¯¥ operation å®ä¾‹:
>   ///   ``mlir::OpBuilder::create<ConstantOp>(...)``
>   /// This method populates the given `state` that MLIR uses to create
>   /// operations. This state is a collection of all of the discrete elements
>   /// that an operation may contain.
>   /// Build a constant with the given return type and `value` attribute.
>   static void build(mlir::OpBuilder &builder, mlir::OperationState &state,
>                     mlir::Type result, mlir::DenseElementsAttr value);
>   /// Build a constant and reuse the type from the given 'value'.
>   static void build(mlir::OpBuilder &builder, mlir::OperationState &state,
>                     mlir::DenseElementsAttr value);
>   /// Build a constant å¹¿æ’­ given 'value'.
>   static void build(mlir::OpBuilder &builder, mlir::OperationState &state,
>                     double value);
> };
> ```
>
> å¹¶ä¸”æˆ‘ä»¬åœ¨Toy Dialectæ„é€ å‡½æ•°ä¸­æ³¨å†Œæ­¤æ“ä½œï¼š
>
> ```c++
> ToyDialect::ToyDialect(mlir::MLIRContext *ctx)
>    : mlir::Dialect(getDialectNamespace(), ctx) {
>   addOperations<ConstantOp>();
> }
> ```

ä¸è¿‡åœ¨è¿™é‡Œæˆ‘ä»¬ä¹Ÿå¯ä»¥çœ‹åˆ°ï¼Œä¸ºäº†é€‚é…å„ç§æ¥å£ï¼Œå®šä¹‰ä¸€ä¸ª `ConstantOp` å·²ç»ååˆ†å¤æ‚äº†ã€‚ MLIR ä¸ºäº†è§£å†³è¿™ç§å¤æ‚æ€§ï¼Œ æä¾›äº†ä¸€ä¸ªåŸºäº TableGen çš„ Operation Definition Specification (ODS) Frameworkï¼Œ ç”¨æˆ·é€šè¿‡ODS å£°æ˜ dialect åŠå…¶ Operationsï¼Œ MLIR æ¡†æ¶é€šè¿‡`mir-tblgen` å·¥å…·å°†è¯¥å£°æ˜å¼è¯­è¨€è‡ªåŠ¨è½¬åŒ–ä¸ºC++ ä»£ç ï¼Œ ç®€åŒ–äº†ç”¨æˆ·è‡ªå®šä¹‰ dialect çš„æµç¨‹ã€‚ 

è¿™ç§æ–¹å¼æ˜¯ MLIR æ¨èçš„å®šä¹‰ Dialect çš„æ–¹å¼ï¼Œ åœ¨ Toy è¯­è¨€ä¸­æˆ‘ä»¬çš„ toy Dialectï¼Œä¹Ÿæ˜¯é€šè¿‡è¿™ç§æ–¹æ³•æ¥å®šä¹‰çš„ã€‚å…·ä½“çš„æ–‡ä»¶åœ¨ `mlir/examples/toy/Ch2/include/toy/Ops.td` ï¼Œ 

```c++
def Toy_Dialect : Dialect {
  let name = "toy";
  let cppNamespace = "::mlir::toy";
  let emitAccessorPrefix = kEmitAccessorPrefix_Prefixed;
}

// Inherits from the base `Op` class in `OpBase.td`
// And provides:
//   * Toy operation çš„ parent dialect(å³ toy dialect).
//   * Toy operation çš„ mnemonic(åŠ©è®°è¯)ï¼Œ or the name without the dialect prefix.
//   * A list of traits for the operation.
class Toy_Op<string mnemonic, list<Trait> traits = []> :
    Op<Toy_Dialect, mnemonic, traits>;
```

å…¶ä¸­ `ConstantOp` çš„å®šä¹‰å¦‚ä¸‹ï¼š

```rust
// ConstantOp(å…·ä½“çš„ Operation) ç»§æ‰¿ 'Toy_Op'.
// è¿™é‡Œä¸º constant operation æä¾›äº†ä¸€ä¸ªåŠ©è®°è¯ å’Œä¸€ä¸ª traits åˆ—è¡¨.
// Constant operation æœ‰ trait 'NoSideEffect' å› ä¸ºå®ƒæ˜¯ pure operation, so that may be removed if dead.
def ConstantOp : Toy_Op<"constant", [NoSideEffect]> {
  // summary and description. å¯è¢«ç”¨äºè‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£
  let summary = "constant";
  let description = [{
    Constant operation turns a literal into an SSA value. The data is attached
    to the operation as an attribute. For example:

    ```mlir
      %0 = toy.constant dense<[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]>
                        : tensor<2x3xf64>
    ```
  }];

  // The constant operation æ¥æ”¶ä¸€ä¸ªå±æ€§ä½œä¸ºå”¯ä¸€çš„è¾“å…¥
  let arguments = (ins F64ElementsAttr:$value);

  // The constant operation è¿”å›ä¸€ä¸ª TensorType ç±»å‹çš„å€¼
  let results = (outs F64Tensor);

  // Indicate that the operation has a custom parser and printer method.
  let hasCustomAssemblyFormat = 1;

  // Add custom build methods for the constant operation. These method populates
  // the `state` that MLIR uses to create operations, i.e. these are used when
  // using `builder.create<ConstantOp>(...)`.
  let builders = [
    // Build a constant with a given constant tensor value.
    OpBuilder<(ins "DenseElementsAttr":$value), [{
      build($_builder, $_state, value.getType(), value);
    }]>,

    // Build a constant with a given constant floating-point value.
    OpBuilder<(ins "double":$value)>
  ];

  // https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/#verifying-operation-semantics
  let hasVerifier = 1;
}
```

å¯ä»¥æ³¨æ„åˆ°è¿™é‡Œ ä¸ä¸Šé¢çš„ C++ ä»£ç ç›¸æ¯”ç¼ºå°‘äº† `ZeroOperands` and `OneResult` traits;

æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨ `mlir-tblgen` å·¥å…·è‡ªåŠ¨å°† `.td` æè¿°æ–‡ä»¶è½¬æˆ C++ ä»£ç ï¼š

1. `mlir-tblgen -gen-dialect-decls ../mlir/example/toy/Ch2/include/toy/Ops.td -I ../mlir/include`

    ç”Ÿæˆäº†`ToyDialect` çš„c++ä»£ç å®šä¹‰ï¼š

    ```c++
    /*===- TableGen'erated file -------------------------------------*- C++ -*-===*\
    |*                                                                            *|
    |* Dialect Declarations                                                       *|
    |*                                                                            *|
    |* Automatically generated file, do not edit!                                 *|
    |*                                                                            *|
    \*===----------------------------------------------------------------------===*/

    namespace mlir {
    namespace toy {

    class ToyDialect : public ::mlir::Dialect {
      explicit ToyDialect(::mlir::MLIRContext *context);

      void initialize();
      friend class ::mlir::MLIRContext;
    public:
      ~ToyDialect() override;
      static constexpr ::llvm::StringLiteral getDialectNamespace() {
        return ::llvm::StringLiteral("toy");
      }
    };
    } // namespace toy
    } // namespace mlir
    MLIR_DECLARE_EXPLICIT_TYPE_ID(::mlir::toy::ToyDialect)
    ```

    è¿™äº›ä»£ç åœ¨ `Dialect.cpp` ä¸­ è¢«åŒ…å«è¿›å»: `#include "toy/Dialect.cpp.inc"`

2. `mlir-tblgen -gen-op-defs ../mlir/example/toy/Ch2/include/toy/Ops.td -I ../mlir/include`

    ç±»ä¼¼ï¼Œç”Ÿæˆ Operations çš„å®šä¹‰ï¼Œ ä»¥ `ConstantOp`ä¸ºä¾‹ï¼Œ ç”Ÿæˆçš„ä»£ç åœ¨ `toy/Ops.cpp.inc` å’Œ `toy/Ops/h/inc` ä¸­ï¼Œå¤ªé•¿ä¸æ”¾åœ¨è¿™é‡Œ



## 3. Chapter 3: High-level åˆ†æå’Œè½¬æ¢
MLIR ä¸­ä½¿ç”¨ è¡¨è¾¾å¼åŒ¹é… å’Œ é‡å†™ æ¥å®Œæˆ MLIR åˆ†æ/è½¬æ¢ã€‚è¿™ä¸ªæ•™ç¨‹ä¸­åˆ†åˆ«ä»‹ç»ä½¿ç”¨ C++ æ¨¡å¼åŒ¹é…å’Œé‡å†™ä»¥åŠåŸºäº [DRR æ¡†æ¶](https://mlir.llvm.org/docs/DeclarativeRewrites/) æ¥å®šä¹‰é‡å†™è§„åˆ™ï¼Œç„¶åä½¿ç”¨ ODS æ¡†æ¶æ¥è‡ªåŠ¨ç”Ÿæˆä»£ç ã€‚

è¿™é‡Œä»¥ toy è¯­è¨€ä¸­çš„ä¸€ä¸ªè¿ç»­ä¸¤æ¬¡è½¬ç½®çš„ç¨‹åºä¸ºä¾‹ï¼š

```py
def transpose_transpose(x) {
  return transpose(transpose(x));
}
```

ä¸åšè½¬æ¢çš„æƒ…å†µä¸‹ç”Ÿæˆçš„ toy dialect å¦‚ä¸‹ï¼š

```go
func @transpose_transpose(%arg0: tensor<*xf64>) -> tensor<*xf64> {
  %0 = toy.transpose(%arg0 : tensor<*xf64>) to tensor<*xf64>
  %1 = toy.transpose(%0 : tensor<*xf64>) to tensor<*xf64>
  toy.return %1 : tensor<*xf64>
}
```

å¦‚æœå°†è¿™ä¸ªç¨‹åºä½¿ç”¨ C++ å†™ï¼Œ å¤§æ¦‚é•¿è¿™ä¸ªæ ·å­ï¼š

```c++
void sink(void *);
void double_transpose(int A[N][M]) {
  int B[M][N];
  for(int i = 0; i < N; ++i) {
    for(int j = 0; j < M; ++j) {
       B[j][i] = A[i][j];
    }
  }
  for(int i = 0; i < N; ++i) {
    for(int j = 0; j < M; ++j) {
       A[i][j] = B[j][i];
    }
  }
  sink(A);
}
```

è¿™ä¸ªç¨‹åºè‡³å°‘å¯¹äºç°åœ¨çš„ clang è€Œè¨€ï¼Œ æ— æ³•å°†ä¸¤æ¬¡è¿ç»­çš„è½¬ç½®æ¶ˆé™¤ã€‚æˆ‘ä»¬æ¥ä¸‹æ¥çœ‹ä¸€ä¸‹å¦‚ä½•åˆ©ç”¨ MLIR ä¸­çš„ æ¨¡å¼åŒ¹é…å’Œé‡å†™æœºåˆ¶å®ç° IR çš„è½¬æ¢

### 3.1. ä½¿ç”¨ C++ å†™ pass
å¯ä»¥ç›´æ¥å†™ C++ æ¥é‡å†™ IRï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å®ç° `RewritePattern` æ’å…¥ MLIR Canonicalizer passï¼š

```c++
/// æŠ˜å  `transpose(transpose(x))` -> `x`
struct SimplifyRedundantTranspose : public mlir::OpRewritePattern<TransposeOp> {
  /// We register this pattern to match every toy.transpose in the IR.
  /// The "benefit" is used by the framework to order the patterns and process
  /// them in order of profitability.
  SimplifyRedundantTranspose(mlir::MLIRContext *context)
      : OpRewritePattern<TransposeOp>(context, /*benefit=*/1) {}

  /// è¿™ä¸ªæ–¹æ³•å°è¯•åŒ¹é…å›ºå®šçš„æ¨¡å¼(å³ä¸¤ä¸ªè¿ç»­çš„è½¬ç½®)ï¼Œå¹¶è¿›è¡Œé‡å†™. 
  matchAndRewrite(TransposeOp op,
                  mlir::PatternRewriter &rewriter) const override {
    // Look through the input of the current transpose.
    mlir::Value transposeInput = op.getOperand();
    TransposeOp transposeInputOp = transposeInput.getDefiningOp<TransposeOp>();

    // Input defined by another transpose? If not, no match.
    if (!transposeInputOp)
      return failure();

    // Otherwise, we have a redundant transpose. Use the rewriter.
    rewriter.replaceOp(op, {transposeInputOp.getOperand()});
    return success();
  }
};
```

ä¸Šè¿°ä»£ç ä½äº `examples/toy/Ch3/mlir/ToyCombine.cpp`ï¼Œ é™¤äº†é‡å†™è§„åˆ™ä¹‹å¤–ï¼Œ è¿˜éœ€è¦å°†è¯¥è§„åˆ™æ·»åŠ åˆ° è§„èŒƒåŒ–æ¡†æ¶ (Canonicalization Framework) :

```c++
/// å°†æˆ‘ä»¬çš„ SimplifyRedundantTranspose patterns åŠ å…¥åˆ° "canonicalization" é‡å†™é›†åˆä¸­
/// ä»è€Œæ‰§è¡Œ Canonicalize pass æ—¶ï¼Œä¼šæ‰§è¡Œåˆ°è¿™é‡Œ
void TransposeOp::getCanonicalizationPatterns(RewritePatternSet &results,
                                              MLIRContext *context) {
  results.add<SimplifyRedundantTranspose>(context);
}

```

å°†è¡¨è¾¾å¼é‡å†™è§„åˆ™æ·»åŠ åˆ°äº†è§„èŒƒåŒ–æ¡†æ¶åï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¿®æ”¹ä¸€ä¸‹å®šä¹‰ `TransposeOp` çš„ `.td` æ–‡ä»¶ï¼Œå¯ç”¨è§„èŒƒåŒ–æ¡†æ¶(æ·»åŠ  `let hasCanonicalizer=1`)ï¼ŒåŒæ—¶ç»™ `TransposeOp` çš„å®šä¹‰æ·»åŠ ä¸€ä¸ª `NoSideEffect` çš„ traitï¼Œ ç°åœ¨ `Transpose` æ“ä½œçš„å®šä¹‰å¦‚ä¸‹ï¼š

```rust
def TransposeOp : Toy_Op<"transpose", [NoSideEffect]> {
  let summary = "transpose operation";
  let arguments = (ins F64Tensor:$input);
  let results = (outs F64Tensor);
  let assemblyFormat = [{
    `(` $input `:` type($input) `)` attr-dict `to` type(results)
  }];

  // Enable registering canonicalization patterns with this operation.
  let hasCanonicalizer = 1;

  let builders = [
    OpBuilder<(ins "Value":$input)>
  ];
  let hasVerifier = 1;
}
```

æˆ‘ä»¬è¿˜éœ€è¦æ›´æ–° `toyc.cpp`ï¼Œ ä»¥æ·»åŠ ä¼˜åŒ– passã€‚åœ¨ MLIR ä¸­ï¼Œä¼˜åŒ–ä»¥ç±»ä¼¼äº LLVM çš„æ–¹å¼é€šè¿‡ PassManager è¿è¡Œï¼š

```c++
mlir::PassManager pm(module->getName());
pm.addNestedPass<mlir::toy::FuncOp>(mlir::createCanonicalizerPass());
```

ç„¶åè¿è¡Œ `./bin/toyc-ch3 ../mlir/test/Examples/Toy/Ch3/transpose_transpose.toy -emit=mlir -opt` å¾—åˆ°

```go
module {
  // æ³¨æ„å¯¹æ¯”è¿™é‡Œä¼˜åŒ–å ä¸ ä¹‹å‰æœªä¼˜åŒ–
  toy.func @transpose_transpose(%arg0: tensor<*xf64>) -> tensor<*xf64> {
    toy.return %arg0 : tensor<*xf64>
  }
  toy.func @main() {
    %0 = toy.constant dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>
    %1 = toy.generic_call @transpose_transpose(%0) : (tensor<2x3xf64>) -> tensor<*xf64>
    toy.print %1 : tensor<*xf64>
    toy.return
  }
}
```

è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œ å¦‚æœæˆ‘ä»¬ä¸ä¿®æ”¹ `.td` ä¸­ `TransposeOp` çš„ traitï¼ˆæ·»åŠ ä¸€ä¸ª `NoSideEffect`ï¼‰ï¼Œ åˆ™ä¼šå‡ºç°ä»¥ä¸‹ç»“æœï¼š

```go
toy.func @transpose_transpose(%arg0: tensor<*xf64>) -> tensor<*xf64> {
  %0 = toy.transpose(%arg0 : tensor<*xf64>) to tensor<*xf64>
  toy.return %arg0 : tensor<*xf64>
}
```

è¿™æ˜¯å› ä¸ºï¼Œ æˆ‘ä»¬çš„æ¨¡å¼ç”¨å‡½æ•°è¾“å…¥æ›¿æ¢äº†æœ€åä¸€ä¸ªå˜æ¢ï¼Œå¹¶ç•™ä¸‹äº†ç°åœ¨æ­»æ‰çš„è½¬ç½®è¾“å…¥ã€‚ Canonicalizer çŸ¥é“æ¸…ç†æ­»æ“ä½œï¼›ç„¶è€Œï¼ŒMLIR ä¿å®ˆåœ°å‡è®¾æ“ä½œå¯èƒ½æœ‰å‰¯ä½œç”¨ã€‚è€Œåœ¨ä¸º `TransposeOp` æ·»åŠ ä¸€ä¸ª `NoSideEffect` å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ è¿™ä¸ª trait åœ¨ `include/mlir/Interfaces/SideEffectInterfaces.td` ä¸­å®šä¹‰ TODO: ä¹‹åå¯ä»¥ç ”ç©¶ä¸€ä¸‹ åœ¨ MLIR ä¸­æ€ä¹ˆå®šä¹‰ å¹¶ä½¿ç”¨ trait

### 3.2. ä½¿ç”¨ DRR å†™ pass
MLIR è¿˜æä¾›äº†ä¸€ç§åŸºäº DDR è§„åˆ™çš„æ–¹å¼æ¥è‡ªåŠ¨ç”Ÿæˆ æ¨¡å¼åŒ¹é… å’Œ é‡å†™å‡½æ•°ï¼Œä»£ç ç”Ÿæˆçš„éƒ¨åˆ†ä»ç„¶åŸºäº ODS æ¡†æ¶å®ç°ã€‚Declarative, rule-based pattern-match and rewrite (DRR) å®ƒæ˜¯ä¸€ç§åŸºäº DAG çš„å£°æ˜å¼é‡å†™å™¨ï¼Œæä¾›åŸºäº tablegen çš„æ¨¡å¼åŒ¹é…å’Œé‡å†™è§„åˆ™çš„å¥æ³•ï¼š

```c++
class Pattern<
    dag sourcePattern, list<dag> resultPatterns,
    list<dag> additionalConstraints = [],
    dag benefitsAdded = (addBenefit 0)>;
```

æ¥ä¸‹æ¥ä»¥æ¶ˆé™¤ MLIR è¡¨è¾¾å¼ä¸­å†—ä½™çš„å¼ é‡ reshape æ“ä½œä¸ºä¾‹:

```py
def main() {
  var a<2,1> = [1, 2];
  var b<2,1> = a;
  var c<2,1> = b;
  print(c);
}
```

å¯¹åº”çš„ toy dialect å¦‚ä¸‹ï¼š

```go
module  {
  func @main() {
    %0 = toy.constant dense<[1.000000e+00, 2.000000e+00]> : tensor<2xf64>
    %1 = toy.reshape(%0 : tensor<2xf64>) to tensor<2x1xf64>
    %2 = toy.reshape(%1 : tensor<2x1xf64>) to tensor<2x1xf64>
    %3 = toy.reshape(%2 : tensor<2x1xf64>) to tensor<2x1xf64>
    toy.print %3 : tensor<2x1xf64>
    toy.return
  }
}
```

aï¼Œbï¼Œc å®Œå…¨ç›¸åŒï¼Œ æˆ‘ä»¬æœ‰æœºä¼šåœ¨ dialect ä¸­æ¶ˆé™¤å†—ä½™çš„ `reshape` ã€‚ ä¸‹é¢æˆ‘ä»¬è¦åŸºäº DDR æ¡†æ¶æ¥å®šä¹‰åŒ¹é…å’Œæ¶ˆé™¤è§„åˆ™ã€‚

ç±»ä¼¼äº `SimplifyRedundantTranspose` çš„é’ˆå¯¹ å†—ä½™ `reshape` çš„ä¼˜åŒ–å¯ä»¥ä½¿ç”¨ DRR æ›´ç®€å•åœ°è¡¨ç¤ºå¦‚ä¸‹ï¼š

```rust
// Reshape(Reshape(x)) -> Reshape(x)
def ReshapeReshapeOptPattern : Pat<(ReshapeOp(ReshapeOp $arg)),
                                   (ReshapeOp $arg)>;
```

å½“è½¬æ¢ä»¥å‚æ•°å’Œç»“æœçš„æŸäº›å±æ€§ä¸ºæ¡ä»¶æ—¶ï¼ŒDRR è¿˜æä¾›äº†ä¸€ç§æ·»åŠ å‚æ•°çº¦æŸçš„æ–¹æ³•ã€‚ä¸€ä¸ªä¾‹å­æ˜¯å½“ reshape çš„å‚æ•°å’Œç»“æœçš„ç±»å‹æ˜¯ä¸€æ ·çš„ï¼Œè¯´æ˜è¿™ä¸ª reshape æ˜¯æ— ç”¨çš„ï¼Œç›´æ¥è¿”å›è¾“å…¥å‚æ•°å³å¯ï¼Œ å³ `Reshape(x) = x`

```rust
// Reshape(x) = x, where input and output shapes are identical
def TypesAreIdentical : Constraint<CPred<"$0.getType() == $1.getType()">>;
def RedundantReshapeOptPattern : Pat<
  (ReshapeOp:$res $arg), (replaceWithValue $arg),
  [(TypesAreIdentical $res, $arg)]>;
```
å³å½“ `0.getType()` ä¸ `1.getType()` ç›¸åŒæ—¶ï¼Œä½¿ç”¨æ“ä½œæ•° `$arg` ä»£æ›¿ã€‚

åŒæ ·éœ€è¦å°†è¿™ä¸ªå‡½æ•°åŠ å…¥åˆ°

DRRä»£ç ä½äº `mlir/examples/toy/Ch3/mlir/ToyCombine.td`ï¼Œ ç”Ÿæˆçš„ä»£ç ä½äº `Ch3/ToyCombine.inc`

æ‰§è¡Œ `./bin/toyc-ch3 ../mlir/test/Examples/Toy/Ch3/trivial_reshape.toy -emit=mlir -opt`

å¾—åˆ°ç»“æœå¦‚ä¸‹ï¼š

```go
module {
  toy.func @main() {
    %0 = toy.constant dense<[[1.000000e+00], [2.000000e+00]]> : tensor<2x1xf64>
    toy.print %0 : tensor<2x1xf64>
    toy.return
  }
}
```

## 4. Chapter 4: ä½¿ç”¨ Interfaces æ³›åŒ– Transformation
ä¸Šé¢å®ç°çš„é‡å†™è§„åˆ™æœ‰ä¸€ä¸ªæ˜æ˜¾çš„é—®é¢˜ï¼šæˆ‘ä»¬ä¸º Toy Dialect å®ç°çš„ Pass åœ¨å…¶å®ƒçš„ Dialect ä¸­æ²¡åŠæ³•é‡ç”¨ï¼Œå› ä¸ºæ˜¯é’ˆå¯¹ Toy dialect ä¸€äº› Operation çš„ç‰¹åŒ–æ“ä½œï¼Œå¦‚æœä¸ºæ¯ç§ Dialect å®ç°æ¯ç§è½¬åŒ–ä¼šå¯¼è‡´å¤§é‡é‡å¤ä»£ç ã€‚æ‰€ä»¥ï¼Œè¿™ä¸€èŠ‚çœ‹å¦‚ä½•åœ¨ MLIR ä¸­ åˆ©ç”¨ Interfaces å®ç°æ³›åŒ–ã€‚

é¦–å…ˆæ˜¯ `mlir/test/Examples/Toy/Ch4/codegen.toy` ä¸­çš„ä¾‹å­

```rust
def multiply_transpose(a, b) {
  return transpose(a) * transpose(b);
}

def main() {
  var a<2, 3> = [[1, 2, 3], [4, 5, 6]];
  var b<2, 3> = [1, 2, 3, 4, 5, 6];
  var c = multiply_transpose(a, b);
  var d = multiply_transpose(b, a);
  print(d);
}
```

å…¶ç”Ÿæˆçš„ Toy Dialectï¼š

```go
module {
  toy.func private @multiply_transpose(%arg0: tensor<*xf64>, %arg1: tensor<*xf64>) -> tensor<*xf64> {
    %0 = toy.transpose(%arg0 : tensor<*xf64>) to tensor<*xf64>
    %1 = toy.transpose(%arg1 : tensor<*xf64>) to tensor<*xf64>
    %2 = toy.mul %0, %1 : tensor<*xf64>
    toy.return %2 : tensor<*xf64>
  }
  toy.func @main() {
    %0 = toy.constant dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>
    %1 = toy.reshape(%0 : tensor<2x3xf64>) to tensor<2x3xf64>
    %2 = toy.constant dense<[1.000000e+00, 2.000000e+00, 3.000000e+00, 4.000000e+00, 5.000000e+00, 6.000000e+00]> : tensor<6xf64>
    %3 = toy.reshape(%2 : tensor<6xf64>) to tensor<2x3xf64>
    %4 = toy.generic_call @multiply_transpose(%1, %3) : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>
    %5 = toy.generic_call @multiply_transpose(%3, %1) : (tensor<2x3xf64>, tensor<2x3xf64>) -> tensor<*xf64>
    toy.print %5 : tensor<*xf64>
    toy.return
  }
}
```

ğŸ’¡æ³¨æ„åˆ°è¿™é‡Œ `multiply_transpose` çš„ç­¾åè¾“å…¥è¾“å‡ºç±»å‹ éƒ½æ˜¯ `tensor<*xf64>` å³**åŠ¨æ€å½¢çŠ¶**ï¼Œ æˆ–è€…å« generic tensor

åœ¨è¿™ä¸€èŠ‚çš„ä¼˜åŒ–ä¹‹å(`./bin/toyc-ch4 ../mlir/test/Examples/Toy/Ch4/codegen.toy -emit=mlir -opt`)ï¼Œ ç”Ÿæˆçš„ IR å°†ä¼šå˜ä¸ºï¼š

```go
module {
  toy.func @main() {
    %0 = toy.constant dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>
    %1 = toy.transpose(%0 : tensor<2x3xf64>) to tensor<3x2xf64>
    %2 = toy.mul %1, %1 : tensor<3x2xf64>
    toy.print %2 : tensor<3x2xf64>
    toy.return
  }
}
```

ğŸ’¡å…ˆæ˜¯åˆ©ç”¨åˆ°äº†ä¸Šä¸€èŠ‚ä¸­çš„ä¼˜åŒ–æ¶ˆé™¤æ‰äº†å†—ä½™çš„ `reshape`ï¼›å¹¶ä¸”æ­¤æ—¶ `multiply_transpose` è¢«å†…è”ï¼ˆåŸå®šä¹‰è¢«åˆ é™¤ï¼‰ï¼› æœ€é‡è¦çš„æ˜¯**æ‰€æœ‰çš„ tensor å½¢çŠ¶éƒ½å˜æˆäº† staticï¼Œ IR ä¸­ ä¸å†å…·æœ‰åŠ¨æ€å½¢çŠ¶**ï¼› å¹¶ä¸” `%4` and `%5` ç›¸åŒï¼Œ å› æ­¤åªè¢«è®¡ç®—äº†ä¸€æ¬¡ï¼›


Toy IR ç›®å‰æ“ä½œ generic tensorsï¼Œ è¿™æ„å‘³ç€é™¤äº†ä½¿ç”¨å¸¸é‡åˆå§‹åŒ–çš„ tensorï¼Œ æˆ‘ä»¬ä¸çŸ¥é“å…¶å®ƒ tensor çš„å½¢çŠ¶ã€‚è¿™ä½¿ ä¼˜åŒ– å’Œ ä»£ç ç”Ÿæˆ å˜å¾—å¤æ‚ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡åœ¨ IR ä¸­ä¼ æ’­ç¼–è¯‘æ—¶å·²çŸ¥çš„é™æ€å½¢çŠ¶ æ¥ç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚å½¢çŠ¶ä¼ æ’­çš„éš¾é¢˜åœ¨äºå¦‚ä½•å¤„ç† user-defined å‡½æ•°è°ƒç”¨å‚æ•°å’Œè¿”å›å€¼éƒ½æ²¡æœ‰ç»™å‡ºå½¢çŠ¶ä¿¡æ¯ï¼ˆå³ä¸Šé¢ä¾‹å­ä¸­çš„ `multiply_transpose`ï¼‰ï¼šæ¯ä¸ªè°ƒç”¨ç‚¹éƒ½å¯ä»¥æ¨æ–­å‡ºä¸åŒçš„å½¢çŠ¶ã€‚ä¸€ç§å¯èƒ½æ˜¯æ ¹æ®å‚æ•°ç±»å‹**æ‰§è¡Œç¬¦å·æ¨ç†**ï¼Œä½†éšç€å¼•å…¥æ›´å¤šæ§åˆ¶æµï¼Œç¬¦å·æ¨ç†å°†å¾ˆéš¾æ³›åŒ–ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯å‡½æ•°ç‰¹åŒ–ï¼Œå…¶ä¸­æ¯ä¸ªå…·æœ‰æ–°å‚æ•°å½¢çŠ¶çš„è°ƒç”¨ç‚¹éƒ½å†…è”è¢«è°ƒç”¨å‡½æ•°å¹¶å¯¹å…¶è¿›è¡Œç‰¹åŒ–ã€‚æˆ‘ä»¬å¯¹ Toy é‡‡å–çš„æ–¹æ³•æ˜¯å†…è”æ‰€æœ‰å‡½æ•°è°ƒç”¨ï¼Œç„¶å**æ‰§è¡Œè¿‡ç¨‹å†…å½¢çŠ¶ä¼ æ’­**ã€‚

æˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸“ä¸º Toy Dialect è®¾è®¡çš„å†…è”ç®—æ³•ï¼Œä½†è¿™å¯èƒ½ä¼šå˜å¾—ç›¸å½“å¤æ‚ã€‚æ’‡å¼€æˆæœ¬å»ºæ¨¡ä¸è°ˆï¼Œä»å¤´å¼€å§‹å†™å›ºå®šæ¨¡å¼çš„ä»£ç å°±å·²ç»å¾ˆå¤æ‚äº†ã€‚MLIR æä¾›äº† **Dialect å¯ä»¥ æ¥å…¥ çš„é€šç”¨å†…è”ç®—æ³•**ã€‚åœ¨ Toy ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åšçš„å°±æ˜¯ä¸ºå†…è”å™¨æä¾› [Interfaces](https://mlir.llvm.org/docs/Interfaces/)ã€‚

1. ç¬¬ä¸€æ­¥æ˜¯åœ¨ Toy Dialect ä¸­å®šä¹‰å¯¹å†…è”æ“ä½œçš„çº¦æŸã€‚æ­¤ä¿¡æ¯é€šè¿‡ [dialect interface](https://mlir.llvm.org/docs/Interfaces/#dialect-interfaces) æä¾›ã€‚ dialect interface æœ¬è´¨ä¸Šæ˜¯åŒ…å«ä¸€ç»„ virtual hooks çš„ç±»ï¼Œæ–¹è¨€é€šè¿‡é‡å†™è¿™äº›æ–¹æ³•æä¾›å…·ä½“å®ç°ã€‚åœ¨è¿™ä¸ªå†…è”ä¾‹å­ä¸­ï¼Œ æˆ‘ä»¬ç”¨åˆ°çš„ Interface æ˜¯ `DialectInlinerInterface`

    ```c++
    /// è¿™ä¸ªç±»å®šä¹‰äº†ç”¨äº Toy Dialect æ‰§è¡Œ inline æ“ä½œçš„æ¥å£
    /// è¿™é‡Œçš„å®ç°åšäº†ç®€åŒ–ï¼Œå¹¶ä¸”åªé‡å†™äº†å¿…è¦çš„æ–¹æ³•
    struct ToyInlinerInterface : public DialectInlinerInterface {
      using DialectInlinerInterface::DialectInlinerInterface;

      /// åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ simply return true, å› ä¸º Toy `Call` operation æ€»æ˜¯å¯å†…è”çš„
      bool isLegalToInline(Operation *call, Operation *callable, bool wouldBeCloned) const final {
        return true;
      }

      /// åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ simply return true, å› ä¸º Toy operation æ€»æ˜¯å¯å†…è”çš„
      bool isLegalToInline(Operation *, Region *, bool, IRMapping &) const final {
        return true;
      }

      /// åŒä¸Š
      bool isLegalToInline(Region *dest, Region *src, bool wouldBeCloned, IRMapping &valueMapping) const final {
        return true;
      }

      /// å½“ä¸€ä¸ª terminator operation è¢« inline åæ‰§è¡Œæ­¤ hookï¼Œ ä¿è¯æ§åˆ¶æµçš„æ­£ç¡®æ€§ï¼ˆä¸ä¼šæå‰è¿”å›ï¼‰
      /// Toy ä¸­å”¯ä¸€çš„ terminator Operationæ˜¯ `toy.return`
      void handleTerminator(Operation *op, ArrayRef<Value> valuesToRepl) const final {
        // å¤„ç† "toy.return"
        auto returnOp = cast<ReturnOp>(op);

        // ç®€å•çš„å°† return è¯­å¥æ›¿æ¢æˆ return è¯­å¥çš„ operands
        assert(returnOp.getNumOperands() == valuesToRepl.size());
        for (const auto &it : llvm::enumerate(returnOp.getOperands()))
          valuesToRepl[it.index()].replaceAllUsesWith(it.value());
      }
    };
    ```

    æ­¤å¤–ï¼Œå†…è”å™¨åªä¼š åˆ é™¤ ç§æœ‰å¯è§çš„æœªä½¿ç”¨å‡½æ•°å®šä¹‰ã€‚å› æ­¤è¿˜éœ€è¦åœ¨ `mlirGen` ä¸­è®¾ç½®å‡½æ•°ï¼ˆ`main`é™¤å¤–ï¼‰ä¸º private

    ```c++
    mlir::toy::FuncOp mlirGen(FunctionAST &funcAST) {
      ...
      if (funcAST.getProto()->getName() != "main")
        function.setPrivate();
      ...
    }
    ```

2. ç„¶åæˆ‘ä»¬ç›´æ¥åœ¨ Toy Dialect ä¸Šæ³¨å†Œæˆ‘ä»¬çš„ Dialect interfaceï¼›åœ¨æ–‡ä»¶ `mlir/examples/toy/Ch5/mlir/Dialect.cpp` ä¸­:

    ```c++
    void ToyDialect::initialize() {
      addOperations<
    #define GET_OP_LIST
    #include "toy/Ops.cpp.inc"
          >();
      addInterfaces<ToyInlinerInterface>();
    }
    ```

    è¿™é‡Œçš„ `addInterfaces<ToyInlinerInterface>()` å°±æ˜¯æ³¨å†Œå†…è” Pass çš„è¿‡ç¨‹ï¼Œå…¶ä¸­`ToyInlinerInterface` å°±æ˜¯æˆ‘ä»¬å®šä¹‰çš„è¡¨è¾¾å¼å˜å½¢è§„åˆ™ã€‚

3. æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦æä¾›ä¸€ç§æ–¹æ³•è®©å†…è”å™¨çŸ¥é“ `toy.generic_call` ä»£è¡¨ä¸€ä¸ªè°ƒç”¨ï¼Œ `toy.func` ä»£è¡¨ä¸€ä¸ªå‡½æ•°ã€‚ MLIR æä¾›äº† [operation interface](https://mlir.llvm.org/docs/Interfaces/#attributeoperationtype-interfaces)ï¼Œ å¯ç”¨äºå°† operation æ ‡è®°ä¸º `call-like` æˆ– `callable-like` (ä¸ dialect interface ä¸åŒï¼Œ operation interface æä¾›æ›´ç»†ç²’åº¦çš„ä¿¡æ¯)ï¼Œ è¿™é‡Œä¸º GenericCallOp æ·»åŠ  `CallOpInterface` ï¼Œ ä¸º FuncOp `CallableOpInterface` 
  
    è¦æ·»åŠ æ­¤æ¥å£ï¼Œæˆ‘ä»¬åªéœ€å°†å®šä¹‰ include åˆ°æˆ‘ä»¬çš„ operation æè¿°æ–‡ä»¶ (`Ops.td`) ä¸­ï¼š

    ```py
    include "mlir/Interfaces/CallInterfaces.td"

    ...

    def FuncOp : Toy_Op<"func",
        [DeclareOpInterfaceMethods<CallableOpInterface>]> {
      ...
    }

    def GenericCallOp : Toy_Op<"generic_call",
        [DeclareOpInterfaceMethods<CallOpInterface>]> {
      ...
    }
    ```

4. è¿˜éœ€è¦åœ¨ Dialect å®šä¹‰ä¸­æ·»åŠ  cast æ“ä½œå¹¶è®¾ç½®è°ƒç”¨çš„æ¥å£ã€‚ä¸ºä»€ä¹ˆéœ€è¦æ·»åŠ  cast æ“ä½œå‘¢ï¼Ÿè¿™æ˜¯å› ä¸ºåœ¨å‡½æ•°è°ƒç”¨æ—¶ï¼Œè¾“å…¥å¼ é‡çš„ç±»å‹æ˜¯ç¡®å®šçš„ã€‚ä½†åœ¨å‡½æ•°å®šä¹‰çš„æ—¶å€™ï¼Œè¾“å…¥å¼ é‡çš„ç±»å‹æ˜¯ generic çš„ã€‚å³æˆ‘ä»¬éœ€è¦`tensor<2x3xf64> -> tensor<*xf64>` ã€‚ä¸‹é¢åœ¨ `mlir/examples/toy/Ch5/include/toy/Ops.td` ä¸­æ·»åŠ  cast æ“ä½œï¼š

    ```rust
    def CastOp : Toy_Op<"cast", [
        DeclareOpInterfaceMethods<CastOpInterface>,
        NoSideEffect,
        SameOperandsAndResultShape
      ]> {
      let summary = "shape cast operation";
      let description = [{ ... }];

      let arguments = (ins F64Tensor:$input);
      let results = (outs F64Tensor:$output);

      let assemblyFormat = "$input attr-dict `:` type($input) `to` type($output)";
    }
    ```

    æˆ‘ä»¬ä½¿ç”¨äº† `DeclareOpInterfaceMethods` åœ¨ `CallOpInterface` çš„å£°æ˜ä¸­å£°æ˜æ‰€ç”¨çš„æ¥å£æ–¹æ³•ã€‚ `DeclareOpInterfaceMethods` è¿™ä¸ª trait è¯´æ˜ç¨‹åºä¼šè¯†åˆ« cast æ“ä½œã€‚

    æ¥ä¸‹æ¥è¿˜éœ€è¦é‡å†™ cast op çš„ `areCastCompatible` æ–¹æ³•ï¼ˆåœ¨ `mlir/examples/toy/Ch5/mlir/Dialect.cpp`ä¸­ï¼‰ï¼š

    ```c++
    bool CastOp::areCastCompatible(TypeRange inputs, TypeRange outputs) {
      if (inputs.size() != 1 || outputs.size() != 1)
        return false;
      // The inputs must be Tensors with the same element type.
      TensorType input = inputs.front().dyn_cast<TensorType>();
      TensorType output = outputs.front().dyn_cast<TensorType>();
      if (!input || !output || input.getElementType() != output.getElementType())
        return false;
      // The shape is required to match if both types are ranked.
      return !input.hasRank() || !output.hasRank() || input == output;
    }
    ```
    è¿™ä¸ªæ–¹æ³•ç”¨æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦è¿›è¡Œç±»å‹è½¬æ¢ï¼Œå¦‚æœ inputs å’Œ outputs çš„ç±»å‹æ˜¯å…¼å®¹è¿”å›çœŸï¼Œå¦åˆ™éœ€è¦è¿›è¡Œç±»å‹è½¬æ¢ï¼ˆcastï¼‰è¿”å›å‡ã€‚

    å¦å¤–æˆ‘ä»¬è¿˜éœ€è¦é‡å†™ `ToyInlinerInterface` ä¸Šçš„ hook ï¼Œ å³ `materializeCallConversion` å‡½æ•°ï¼š

    ```c++
    struct ToyInlinerInterface : public DialectInlinerInterface {
      ....
      /// å°è¯•åœ¨å‡½æ•°è°ƒç”¨çš„åœ°æ–¹æ’å…¥ cast èŠ‚ç‚¹. å¦‚æœä¸èƒ½è½¬æ¢ è¿”å› nullptr
      Operation *materializeCallConversion(OpBuilder &builder, Value input,
                                          Type resultType,
                                          Location conversionLoc) const final {
        return builder.create<CastOp>(conversionLoc, resultType, input);
      }
    };
    ```
    è¿™ä¸ªå‡½æ•°æ˜¯å†…è” Pass çš„å…¥å£ã€‚

5. å°† Inline Pass æ·»åŠ åˆ°ä¼˜åŒ– pipline ä¸­ï¼Œåœ¨ `mlir/examples/toy/Ch5/toyc.cpp` ä¸­ï¼š

    ```c++
    if (enableOpt) {
        mlir::PassManager pm(&context);
        // Apply any generic pass manager command line options and run the pipeline.
        applyPassManagerCLOptions(pm);

        // å°†æ‰€æœ‰çš„ call æ’å…¥ main å¹¶ä¸”åˆ é™¤ä¹‹
        pm.addPass(mlir::createInlinerPass());
    ...
    }
    ```

æ­¤æ—¶å¾—åˆ°çš„ toy dialect å¦‚ä¸‹ï¼š

```go
func @main() {
  %0 = "toy.constant"() {value = dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>} : () -> tensor<2x3xf64>
  %1 = "toy.constant"() {value = dense<[[1.000000e+00, 2.000000e+00, 3.000000e+00], [4.000000e+00, 5.000000e+00, 6.000000e+00]]> : tensor<2x3xf64>} : () -> tensor<2x3xf64>
  %2 = "toy.cast"(%1) : (tensor<2x3xf64>) -> tensor<*xf64>
  %3 = "toy.cast"(%0) : (tensor<2x3xf64>) -> tensor<*xf64>
  %4 = "toy.transpose"(%2) : (tensor<*xf64>) -> tensor<*xf64>
  %5 = "toy.transpose"(%3) : (tensor<*xf64>) -> tensor<*xf64>
  %6 = "toy.mul"(%4, %5) : (tensor<*xf64>, tensor<*xf64>) -> tensor<*xf64>
  toy.print %6 : tensor<*xf64>
  toy.return
}
```

ç°åœ¨ MLIR è¡¨è¾¾å¼åªæœ‰ä¸€ä¸ªä¸»å‡½æ•°ï¼Œä¹‹å‰çš„ `transpose` å‡½æ•°è¢«å†…è”äº†ï¼Œå¹¶ä¸”å¯ä»¥çœ‹åˆ° `toy.cast` å®ç°çš„åŠŸèƒ½ã€‚

### 4.2. å½¢çŠ¶ä¼ æ’­ pass
ç°åœ¨æˆ‘ä»¬å·²ç»å†…è”äº†æ‰€æœ‰å‡½æ•°ï¼Œå‰©ä¸‹çš„æ˜¯ä¸€ä¸ªåŒ…å«é™æ€å’ŒåŠ¨æ€å½¢çŠ¶æ“ä½œæ··åˆçš„ä¸»å‡½æ•°ã€‚æˆ‘ä»¬ç°åœ¨å¯ä»¥ç¼–å†™ä¸€ä¸ªç®€å•çš„å½¢çŠ¶æ¨ç†è¿‡ç¨‹åœ¨å•ä¸ªå‡½æ•°å†…æ’­å½¢çŠ¶ã€‚æˆ‘ä»¬å¯ä»¥å°†å…¶å†™æˆé’ˆå¯¹ Toy Dialect passï¼Œç„¶è€Œç»éªŒæ³•åˆ™å‘Šè¯‰æˆ‘ä»¬ï¼Œæœ€å¥½å°½å¯èƒ½é€šç”¨åœ°è¡¨è¾¾è½¬æ¢ï¼Œä»¥ä¾¿å°†æ¥å¯ä»¥æ‰©å±•åˆ°å…¶ä»–æ–¹è¨€ã€‚

ä¸ Operation ç±»ä¼¼ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ ODS æ¡†æ¶æ¥å®šä¹‰ Operation Interfaces

1. ä½¿ç”¨ ODS æ¡†æ¶å®šä¹‰ Shape æ¨æ–­ Operation Interfaceï¼Œ ä»£ç åœ¨ `mlir/examples/toy/Ch5/include/toy/ShapeInferenceInterface.td`

    ```rust
    def ShapeInferenceOpInterface : OpInterface<"ShapeInference"> {
      let description = [{
        Interface to access a registered method to infer the return types for an
        operation that can be used during type inference.
      }];

      let methods = [
        InterfaceMethod<"Infer and set the output shape for the current operation.",
                        "void", "inferShapes">
      ];
    }
    ```

    å…¶ä¸­çš„ `method` è¡¨ç¤ºéœ€è¦ä¸ºè¯¥æ¥å£æä¾›çš„æ–¹æ³• ï¼Œ ä¸‰ä¸ªå­—æ®µåˆ†åˆ«è¡¨ç¤º descï¼Œ return typeï¼Œ method name
2. å°† å®šä¹‰çš„ `ShapeInferenceOpInterface` æ·»åŠ åˆ°å¿…è¦çš„ Toy Operation å®šä¹‰ä¸­

    è¿™é‡Œæˆ‘ä»¬ç»™ `AddOp`, `MulOp`, `CastOp` å’Œ `TranposeOp` åŠ ä¸Š ShapeInferenceOpInterfaceï¼š

    ```Rust
    def CastOp : Toy_Op<"cast", [
        DeclareOpInterfaceMethods<CastOpInterface>,
        // è¿™é‡Œæ·»åŠ  ShapeInferenceOpInterface
        DeclareOpInterfaceMethods<ShapeInferenceOpInterface>, 
        NoSideEffect,
        SameOperandsAndResultShape
      ]> {...}
    ```

    æ‰€æœ‰æ·»åŠ äº† `ShapeInferenceOpInterface` çš„ Op éƒ½éœ€è¦å®ç°æ¥å£`method`å­—æ®µä¸­å®šä¹‰çš„çš„ `inferShapes` æ–¹æ³•ï¼š

    ```c++
    // cast op çš„å½¢çŠ¶æ¨æ–­å‡½æ•°
    void CastOp::inferShapes() { getResult().setType(getOperand().getType()); }

    // transpose op çš„ å½¢çŠ¶æ¨æ–­å‡½æ•°
    void TransposeOp::inferShapes() {
      auto arrayTy = getOperand().getType().cast<RankedTensorType>();
      SmallVector<int64_t, 2> dims(llvm::reverse(arrayTy.getShape()));
      getResult().setType(RankedTensorType::get(dims, arrayTy.getElementType()));
    }
    ```


3. å®ç°å½¢çŠ¶æ¨å¯¼ï¼ˆå³å½¢çŠ¶ä¼ æ’­ï¼‰ Pass

    `ShapeInferencePass` å°†å¯¹å‡½æ•°è¿›è¡Œæ“ä½œï¼šå®ƒå°†åœ¨æ¯ä¸ªå‡½æ•°ä¸Šç‹¬ç«‹è¿è¡Œã€‚ MLIR è¿˜æ”¯æŒåœ¨ä»»ä½• å•ç‹¬çš„ Operation ä¸Šè¿è¡Œçš„é€šç”¨ `OperationPass`ï¼Œä½†è¿™é‡Œæˆ‘ä»¬çš„ moduleä»…åŒ…å«å‡½æ•°ï¼Œå› æ­¤æ— éœ€æ³›åŒ–åˆ°æ‰€æœ‰æ“ä½œã€‚

    ```c++
    struct ShapeInferencePass 
     : public mlir::PassWrapper<ShapeInferencePass, OperationPass<toy::FuncOp>> {
      MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(ShapeInferencePass)
    
    void runOnOperation() override {
      auto f = getOperation();

      // 0. å°†æ‰€æœ‰éœ€è¦ å½¢çŠ¶æ¨å¯¼ çš„Op(è¿”å› dynamic shape çš„ Op) åŠ å…¥ worklist
      llvm::SmallPtrSet<mlir::Operation *, 16> opWorklist;
      f.walk([&](mlir::Operation *op) {
        if (returnsDynamicShape(op))
          opWorklist.insert(op);
      });

      // åœ¨ worklist ä¸Šè¿­ä»£ï¼Œ ç›´åˆ°æ‰€æœ‰çš„ operations éƒ½è¢«æ¨å¯¼ï¼ˆworklist ä¸ºç©ºï¼‰
      while (!opWorklist.empty()) {
        // 1. æ‰¾åˆ°ä¸‹ä¸€ä¸ªéœ€è¦æ¨å¯¼çš„ operation â€”â€” è¿™ä¸ª operation çš„æ‰€æœ‰å‚æ•°å½¢çŠ¶åº”è¯¥éƒ½å·²ç»è¢«æ¨å¯¼
        auto nextop = llvm::find_if(opWorklist, allOperandsInferred);

        // 2. æ²¡æœ‰æ‰¾åˆ°è¯´æ˜å·²ç»æ”¶æ•›ï¼Œ ç»“æŸç®—æ³•
        if (nextop == opWorklist.end()) break;

        // 3. ä» worklist ä¸­åˆ é™¤ è¯¥ opï¼Œ å¹¶è°ƒç”¨è¯¥ op çš„ inferShapes æ–¹æ³• æ¨å¯¼å½¢çŠ¶
        Operation *op = *nextop;
        opWorklist.erase(op);
        
        // 3.1. op å®ç°äº† `ShapeInference` æ¥å£ä¸Šçš„æ–¹æ³• `inferShapes` åœ¨è¿™é‡Œè¢«è°ƒç”¨
        if (auto shapeOp = dyn_cast<ShapeInference>(op)) {
          shapeOp.inferShapes();
        } else {
          op->emitError("operation doesnt have shape inference interface");
          return signalPassFailure();
        }
      }
      
      // 4. è·³å‡ºå¾ªç¯åï¼Œ å¦‚æœ operation worklist ä¸ä¸ºç©º, æ„å‘³ç€ç®—æ³•å¤±è´¥.
      if (!opWorklist.empty()) {
        f.emitError("Shape inference failed, ")
            << opWorklist.size() << " operations couldn't be inferred\n";
        signalPassFailure();
      }
    }
    }
    ```

4. æŠŠå½¢çŠ¶æ¨å¯¼ Pass åŠ åˆ°ä¼˜åŒ– pipline

    åŒæ ·çš„ï¼Œæˆ‘ä»¬åœ¨æœ€åæŠŠ shapeinference pass æ·»åŠ åˆ°æˆ‘ä»¬çš„ passmanager ä¸­ï¼š

    ```c++
    optPM.addPass(mlir::toy::createShapeInferencePass());
    ``` 

    MLIR ä»£ç ä¸­è¿˜æ·»åŠ äº†ä¸€ä¸ª CSE passï¼Œ è¿™æ ·å°±å¾—åˆ°äº†æœ¬ç« å¼€å§‹çš„æœ€ç»ˆç»“æœã€‚

