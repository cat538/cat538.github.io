# TVM-lowerTir

è¿™ç¯‡æ–‡ç« ç”¨ä¸€ä¸ªä¾‹å­è¿½è¸ª tir æ˜¯å¦‚ä½•ç»è¿‡ target translation(ä»¥LLVMä¸ºä¾‹) è¢«ç¿»è¯‘ä¸ºä¸€ä¸ª `runtime.Module`

ä½¿ç”¨çš„ä¾‹å­ä»£ç å¦‚ä¸‹ï¼š

```py
import tvm
from tvm import te
SIZE = 1024

# 1. ä½¿ç”¨ TE å£°æ˜è®¡ç®—
# mm
k = te.reduce_axis((0, SIZE), 'k')
A = te.placeholder((SIZE, SIZE), name='A')
B = te.placeholder((SIZE, SIZE), name='B')
C = te.compute((SIZE, SIZE), lambda x, y: te.sum(A[x, k] * B[k, y], axis=k), name='MM')
# relu
D_IN = te.placeholder((SIZE, SIZE), name='RELU_IN')
D_OUT = te.compute((SIZE, SIZE), lambda i, j: te.max(D_IN[i, j], 0), "RELU_OUT")

# 2. ä» TE åˆ›å»º PrimFunc 
te_mm: tvm.tir.PrimFunc = te.create_prim_func([A, B, C]).with_attr({"global_symbol": "mmult"})
te_relu: tvm.tir.PrimFunc = te.create_prim_func([D_IN, D_OUT]).with_attr({"global_symbol": "relu"})

# 3. å°†åˆ›å»ºå‡ºæ¥çš„ PrimFunc æ·»åŠ åˆ°ä¸€ä¸ª IRModule ä¸­
ir_m: tvm.IRModule = tvm.IRModule({'mm': te_mm})
gv_relu = tvm.ir.GlobalVar("relu")
ir_m.update_func(gv_relu, te_relu)
print(ir_m.get_global_vars())
# è¿™é‡Œä¹Ÿå¯ä»¥ä½¿ç”¨ å…ˆæ„å»º Scheduleï¼Œ å†è°ƒç”¨ `tvm.lower` çš„æ–¹æ³• å¾—åˆ°ä¸€ä¸ª IRModule
# te_sch: te.Schedule = te.create_schedule(C.op) # C.op: te.tensor.ComputeOp
# ir_m: tvm.IRModule = tvm.lower(te_sch, [A, B, C], simple_mode=True,name='mmult')

# 4. Lower and Build
''' åœ¨è¿™ä¸€æ­¥å°† IRModule ==> runtime.Module'''
rt_m: tvm.runtime.Module = tvm.build(ir_m, target='llvm', name='func_set')

print(f"\033[31mtvm.build\033[0m: {type(ir_m)} \033[31m==>\033[0m {type(rt_m)}")

# print IRModuleï¼Œ å…¶ä¸­åŒ…å«ä¸€ä¸ª PrimFunc
# print(f"\033[31mAfter lowering, the IRModule\033[0m:\n{ir_m}")
ir_m.show()

# # print source code
# print(f"\033[31msource code\033[0m:\n{rt_m.get_source()}")
```

## 1. ç†è§£ tir å…ƒå¼ é‡å‡½æ•°(`PrimFunc`) çš„ç¼–è¯‘è¿‡ç¨‹

`tvm.build` å°†ä»£ç ä» IRModule è½¬æ¢æˆ runtime.Moduleï¼› 

- å…¶ä¸­ IRModule å®šä¹‰åœ¨ `include/tvm/ir/module.h` ä¸­ï¼› å¯ä»¥ç®€å•è§†ä½œä¸€ä¸ª `<name, BaseFunc>` çš„å“ˆå¸Œè¡¨(å³å¯åŒæ—¶åŒ…å«`PrimFunc` å’Œ `Func`)
- å…¶ä¸­ runtime.Module å®šä¹‰å¯¹åº”åœ¨ `include/tvm/runtime/module.h` ä¸­ï¼› å¯ä»¥ç®€å•è§†ä½œä¸€ä¸ª `<name, PackedFunc>` çš„å“ˆå¸Œè¡¨ã€‚ `ModuleNode` æ˜¯ä¸€ä¸ªæ¥å£ï¼Œ å¯¹åº”æœ‰å¤šç§ä¸åŒçš„å®ç°ï¼Œ å¦‚ `CUDAModuleNode`ï¼Œ `LLVMModuleNode` ç­‰


ä»¥ä½¿ç”¨teå£°æ˜ è®¡ç®—è¿‡ç¨‹ ä¸ºä¾‹ï¼Œå±•ç¤ºä¸€ä¸ª `te.tensor.ComputeOp` æ˜¯å¦‚ä½•è¢«ç¼–è¯‘æˆ `runtime.Module` çš„ï¼š

1. ä½¿ç”¨teå£°æ˜è®¡ç®—è¿‡ç¨‹
2. ä½¿ç”¨ `te.create_schedule` åˆ›å»ºä¸€ä¸ªSchedule å¯¹è±¡ï¼Œ æ¥ç€ä½¿ç”¨ `te.lower()` å°†ä¸€ä¸ª `te.Schedule` è½¬æˆä¸€ä¸ªIRModuleï¼›

    æˆ–è€…ä½¿ç”¨ `te.create_prim_func` åˆ›å»ºä¸€ä¸ª `tvm.tir.PrimFunc` å¯¹è±¡(å³ä¸€ä¸ªå…ƒå¼ é‡å‡½æ•°)ï¼Œ ç„¶åä½¿ç”¨ IRModuleçš„æ„é€ å‡½æ•°æŠŠè¿™ä¸ª PrimFunc æ”¾åˆ° è¿™ä¸ªIRModule ä¸­

3. æ¥ç€è°ƒç”¨ `tvm.build()` å¯¹ IRModuleè¿›è¡Œæ„å»ºï¼Œ åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œ IRModule æœ€ç»ˆå°†è¢«è½¬æ¢æˆä¸€ä¸ª `runtime.Module`ï¼› 

    è¿™é‡Œéœ€è¦æ³¨æ„ `tvm.build` å¯ä»¥æ¥å— `Schedule`, `PrimFunc`, `IRModule` ç­‰å¤šç§ç±»å‹ï¼ˆå®é™…ä¸Šéƒ½ä¼šè¢«è½¬æˆ IRModule ç„¶åå†ç¼–è¯‘ï¼‰ä½œä¸ºè¾“å…¥ï¼Œ å¦‚æœä¼ å…¥çš„æ˜¯ä¸€ä¸ª `Schedule` çš„è¯ï¼Œ åˆ™éœ€è¦ä¼ å…¥å‡½æ•°ç›¸åº”çš„è¾“å…¥å‚æ•°åˆ—è¡¨

ğŸ’¡å› æ­¤æ¥ä¸‹æ¥ä¸»è¦çœ‹ ä½äº `python/driver/build_module.py` ä¸­çš„ `tvm.build` æ–¹æ³•

---

`tvm.build()` åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤

1. è°ƒç”¨ `python/driver/build_module.py` ä¸­ `lower()`ï¼Œ è¿™æ˜¯ä¸€æ­¥ IRModule åˆ° IRModule çš„å˜æ¢ï¼› å…·ä½“æ¥è¯´ï¼Œ`lower()` ä¸­ä¼šè°ƒç”¨ `ffi.lower_module(inp, simple_mode)`ï¼Œè¿™é‡Œå¯¹åº”åˆ° C++ ä»£ç  `src/dirver/driver_api.cc` ä¸­çš„ `LowerModule` æ–¹æ³•ï¼š

    ```c++
    IRModule LowerModule(IRModule mod, bool simple_mode) {
        Array<transform::Pass> pass_list = CreatePassList(simple_mode);
        return LowerWithPassList(std::move(mod), pass_list);
    }
    TVM_REGISTER_GLOBAL("driver.lower_module").set_body_typed([](IRModule mod, bool simple_mode) {
        return LowerModule(std::move(mod), simple_mode);
    });
    ```

    å¯ä»¥çœ‹åˆ° åœ¨ `LowerModule` é€»è¾‘ä¸­ï¼Œ é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªpass åˆ—è¡¨ï¼Œç„¶åæŠŠåˆ—è¡¨ä¸­çš„passåº”ç”¨åˆ°è¯¥ IRModule ä¸­ï¼š

    ```c++
    IRModule LowerWithPassList(IRModule mod, Array<tvm::transform::Pass> pass_list) {
        auto optimize = tvm::transform::Sequential(pass_list);
        mod = optimize(std::move(mod));
        return mod;
    }
    ```

    åœ¨è¿™æ®µé€»è¾‘ä¸­ï¼Œ é¦–å…ˆæ„é€ äº†ä¸€ä¸ª `Sequential` å¯¹è±¡ï¼Œ æ¥ç€è°ƒç”¨äº† `SequentialNode::operator()`

2. åœ¨ç¬¬ä¸€æ­¥çš„ lower ä¹‹åï¼Œ`tvm.build()` æ¥æ”¶çš„inputså‚æ•° `Union[te.Schedule, PrimFunc, IRModule, Mapping[str, IRModule]]` è¢«è½¬æˆäº†ä¸€ä¸ª IRModuleï¼Œ æ¥ä¸‹æ¥æ£€æŸ¥ target ç›¸å…³ä¿¡æ¯ï¼Œä¼šæ ¹æ® `tvm.build()` çš„è¾“å…¥è®¾ç½®ç›¸åº”çš„ target, target_host ç­‰å˜é‡


3. åœ¨æ‹¿åˆ° target ç­‰è§„èŒƒæ ¼å¼çš„ä¿¡æ¯ä¹‹åï¼Œä¼šæ‰§è¡Œ`rt_mod_host = _driver_ffi.tir_to_runtime(annotated_mods, target_host)` ï¼Œè¿™é‡Œè°ƒç”¨çš„ `tir_to_runtime` å¯¹åº”åˆ°C++ä¸­çš„ `TIRToRuntime`:

    ```c++
    TVM_REGISTER_GLOBAL("driver.tir_to_runtime")
        .set_body_typed([](const Map<Target, IRModule>& inputs_arg, Target host_target) {
            return TIRToRuntime(inputs_arg, host_target);
        });
    ```

    æ¯”è¾ƒå…³é”®çš„ `TIRToRuntime` é€»è¾‘å¦‚ä¸‹ï¼š

    ```c++
    runtime::Module TIRToRuntime(const Map<Target, IRModule>& inputs_arg, const Target& target_host_arg) {
      std::vector<runtime::Module> device_modules;
      Map<Target, IRModule> inputs = inputs_arg;
      Target target_host = target_host_arg;
      // 1. æ£€æŸ¥å¹¶è®¾ç½®target_host
      // ...
      // 2. éå†è¾“å…¥çš„ {Target: IRModule}
      //  SplitMixedModule å°†ä¸€ä¸ª IRModule åˆ†ä¸º host ä¸ device ä¸¤éƒ¨åˆ†
      //  æ ¹æ® host ä¸ device ä¿¡æ¯æ›´æ–° mhost_all
      IRModule mhost_all = IRModule(Map<GlobalVar, BaseFunc>(),{},{},{},(*inputs.begin()).second->attrs);
      for (const auto& it : inputs) {
        if (it.second.defined()) {
          const auto& [target, ir_module] = it;
          auto& [host_mod, device_mod] = SplitMixedModule(ir_module, target, target_host);

          bool overrides_host_target =
            target->GetTargetDeviceType() == target_host->GetTargetDeviceType();
          bool non_host_target_kind = target->kind != target_host->kind;
              
          if (overrides_host_target && non_host_target_kind)
            device_modules.push_back(codegen::Build(host_mod, target));
          else
            mhost_all->Update(host_mod);

          if (device_mod->functions.size() != 0)
            device_modules.push_back(codegen::Build(device_mod, target));
        }
      }
      // 3. Build host module
      runtime::Module mhost = codegen::Build(mhost_all, target_host);
      for (const auto& it : device_modules)
        if (it.operator->())
          mhost.Import(it);
      return mhost;
    }
    ```

    è¿™é‡Œæ¯”è¾ƒå…³é”®çš„ `codegen::build` åœ¨`src/target/codegen.cc` ä¸­ï¼Œ å®ç°å¦‚ä¸‹ï¼š

    ```c++
    runtime::Module Build(IRModule mod, Target target) {
      auto target_attr_map = tvm::TargetKind::GetAttrMap<FTVMTIRToRuntime>("TIRToRuntime");
      if (target_attr_map.count(target->kind))
        return target_attr_map[target->kind](mod, target);
      // the build function.
      std::string build_f_name = "target.build." + target->kind->name;
      const PackedFunc* bf = runtime::Registry::Get(build_f_name);
      return (*bf)(mod, target);
    }
    ```

    å¯ä»¥çœ‹åˆ° é€šè¿‡ä½¿ç”¨å­—ç¬¦ä¸²æ‹¼æ¥ æ‹¿åˆ° `build_f_name` (ä¾‹å¦‚ target æ˜¯ llvmï¼Œ è¿™é‡Œå¾—åˆ°å°±æ˜¯ "target.build.llvm")ï¼Œ æ¥ç€ç”¨è¿™ä¸ªåå­—æŸ¥æ‰¾åˆ°å·²æ³¨å†Œçš„å‡½æ•°ï¼Œè¿›è¡Œ build

4. æ¥ä¸‹æ¥ä»¥ llvm åç«¯ä¸ºä¾‹ çœ‹ä¸€ä¸‹å¦‚ä½•ç”Ÿæˆçš„ llvm IR

    ```c++
    TVM_REGISTER_GLOBAL("target.build.llvm")
    .set_body_typed([](IRModule mod, Target target) -> runtime::Module {
      auto n = make_object<LLVMModuleNode>();
      n->Init(mod, target);
      return runtime::Module(n);
    });
    ```

    å¯ä»¥çœ‹åˆ°è¿™é‡Œæ„é€ äº†ä¸€ä¸ª `LLVMModuleNode` å®ä¾‹ï¼Œ è°ƒç”¨äº†å®ƒçš„ `Init` æ–¹æ³•ï¼Œ å› æ­¤å¯çŸ¥è¯¥æ–¹æ³•å°±æ˜¯å°†IRModule lower ä¸º LLVMModuleNode çš„æ ¸å¿ƒå‡½æ•°ã€‚ å…³äº `LLVMModuleNode` çš„å®šä¹‰ï¼Œ å¯å‚è€ƒ [TVM-type](./tvm-type.md)ï¼Œä¸‹é¢æ˜¯ `Init` æ–¹æ³•çš„å…·ä½“å®ç°ï¼š

    ```c++
    void LLVMModuleNode::Init(const IRModule& mod, const Target& target) {
      // LLVMInstance å®ä¾‹ä¸­åŒ…æ‹¬ä¸€ä¸ª llvm::Module å’Œä¸€ä¸ª llvm::LLVMContext 
      llvm_instance_ = std::make_unique<LLVMInstance>();
      With<LLVMTarget> llvm_target(*llvm_instance_, target);
      llvm::TargetMachine* tm = llvm_target->GetOrCreateTargetMachine();
      // ä¼šæ ¹æ® llvm_target åˆ›å»º CodeGenCPU or CodeGenNVPTX or CodeGenAMDGPU
      std::unique_ptr<CodeGenLLVM> cg = CodeGenLLVM::Create(llvm_target.get());
      std::vector<PrimFunc> funcs;
      std::string entry_func;
      relay::Runtime runtime =
          mod->GetAttr<relay::Runtime>(tvm::attr::kRuntime).value_or(relay::Runtime::Create("cpp"));
      bool system_lib = runtime->GetAttr<Bool>("system-lib").value_or(Bool(false));
      bool target_c_runtime = runtime->name == "crt";
      // 1. éå† IRModule ä¸­çš„ PrimFunc, å‡½æ•°åä¿å­˜åˆ° LLVMModuleNode å®ä¾‹çš„ `function_names_` ä¸­
      for (auto kv : mod->functions) {
        if (!kv.second->IsInstance<PrimFuncNode>()) 
          continue;
        auto f = Downcast<PrimFunc>(kv.second);
        auto global_symbol = f->GetAttr<String>(tvm::attr::kGlobalSymbol);
        function_names_.push_back(global_symbol.value());
        if (f->HasNonzeroAttr(tir::attr::kIsEntryFunc))
          entry_func = global_symbol.value();
        funcs.push_back(f);
      }
      // 2. è°ƒç”¨ CodeGenLLVM çš„ Init åˆå§‹åŒ–ç›¸å…³ä¿¡æ¯ï¼Œ å°† PrimFunc æ·»åŠ åˆ° CodeGenLLVM å®ä¾‹ä¸­
      cg->Init("TVMMod", llvm_target.get(), system_lib, system_lib, target_c_runtime);
      cg->SetFastMathFlags(llvm_target->GetFastMathFlags());
      cg->AddFunctionsOrdered(funcs.begin(), funcs.end());
      if (entry_func.length() != 0)
        cg->AddMainFunction(entry_func);
      // 3. è°ƒç”¨ Finish æ–¹æ³•å®Œæˆ lower
      module_owning_ptr_ = cg->Finish();
      module_ = module_owning_ptr_.get();
      llvm_target->SetTargetMetadata(module_);
    }
    ```

5. ä»ä¸Šä¸€æ­¥ä¸­å¯çŸ¥ï¼Œ `cg->Finish()`  çœŸæ­£å®Œæˆäº† lower çš„åŠ¨ä½œ

    TODO: