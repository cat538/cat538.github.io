# Ansor: Generating High-Performance Tensor Programs for Deep Learning

## 0. Abstract
目前，DL 系统依靠供应商提供的内核库或各种搜索策略来获得高性能的张量程序。 这些方法要么需要大量的工程工作来开发特定平台的优化代码，要么**由于有限的搜索空间和无效的探索策略而无法找到高性能程序**。

我们介绍了 Ansor，这是一种用于 DL 应用程序的张量程序生成框架。 与现有的搜索策略相比，Ansor 通过从搜索空间的分层表示(hierarchical representation)中对程序进行采样，探索了更多的优化组合。 然后，Ansor 通过进化搜索(evolutionary search)和 a learned cost model 对采样程序进行微调，以确定最佳程序。 Ansor 可以找到现有最先进方法搜索范围之外的高性能程序。 此外，Ansor 利用任务调度程序同时优化深度神经网络中的多个子图。 我们表明，相对于最先进的技术，Ansor 在 Intel CPU、ARM CPU 和 NVIDIA GPU 上的执行性能分别提高了 3.8 倍、2.6 倍和 1.7 倍

## 10. Conclusion
我们提出了 Ansor，一种为深度神经网络生成高性能**张量程序的自动搜索框架**。 通过有效地探索大型搜索空间并确定性能瓶颈的优先级，Ansor 可以**找到现有方法搜索空间之外的高性能程序**。 Ansor 在各种神经网络和硬件平台上的性能优于现有手动库和基于搜索的框架高达 3.8 倍。Ansor 已集成到 Apache TVM 中。

## 1. Intro
基于搜索的编译 [2、11、32、49、59] 来自动生成张量程序(即张量算子的低级实现)得到了很多研究。 对于一个或多个算子的（子）图，用户使用高级声明式语言 ([第2节](#2-background)) 定义计算，然后编译器搜索针对不同硬件平台定制的程序。

为了找到高性能的张量程序，基于搜索的方法有必要探索足够大的搜索空间以涵盖所有有用的张量程序优化。 然而，现有方法无法捕获许多有效的优化组合，**因为它们依赖于预定义的手动编写模板(如 TVM [12], FlexTensor [59])** 或通过评估不完整程序(如 Halide auto-scheduler [2])，这会阻止它们覆盖全面的搜索空间 ([第2节](#2-background))。 他们用来构建搜索空间的规则也是有限的。

!!! warning "疑问"
    手动编写模板指的是 AutoTVM 中的方法，大概是 TE-Schedule ？


在本文中，**我们探索了一种用于生成高性能张量程序的新型搜索策略**。 它可以找到现有方法遗漏的高性能程序。

实现这一目标面临多重挑战：

1. 首先，需要为给定的计算定义自动构建一个大的搜索空间来覆盖尽可能多的张量程序。
2. 其次，需要在比现有模板覆盖范围大几个数量级的大型搜索空间中不比较不完整程序的情况下进行高效搜索。
3. 最后，在优化具有许多子图的 DNN 时，应该识别并优先考虑对整体性能影响大的子图。

为此，我们设计并实现了 Ansor，这是一种用于自动张量程序生成的框架。 Ansor **利用分层表示**来覆盖大型搜索空间。 这种表示解耦了高层结构和低层细节，实现了高层结构的灵活枚举和低层细节的高效采样。然后 Ansor 从搜索空间中采样完整的程序，并使用 **evolutionary search 和 a learned cost model** 对这些程序进行微调。 为了优化具有多个子图的 DNN 的性能，**Ansor 动态地对更有可能提高端到端性能的 DNN 的子图进行优先级排序**。

我们根据 manual libraries 和最先进的  search-based frameworks ， 在标准 DL benchmark 和新兴的工作负载上评估 Ansor。 结果表明，Ansor 将 DNN 在 Intel CPU、 ARM CPU 和 NVIDIA GPU 上的执行性能分别提高了 3.8 倍、2.6 倍和 1.7 倍。 对于大多数计算定义，Ansor 找到的最佳程序位于现有 search-based 的方法的搜索空间之外。 结果还表明，与现有的 search-based 的方法相比，Ansor 的搜索效率更高，在更短的时间内生成性能更高的程序，尽管其搜索空间更大。 Ansor 可以与最先进框架的性能相媲美，搜索时间减少一个数量级。 此外，**Ansor 只需要他们的数学定义而无需手动模板，从而可以自动扩展到新的算子**。

贡献： 

- 一种为计算图生成张量程序的大型分层搜索空间的机制。 
- 一种具有学习成本模型的进化策略，用于微调张量程序的性能。 
- 一种基于梯度下降的调度算法，在优化DNN 的端到端性能时优先考虑重要的子图。 
- Ansor 系统的实施和综合评估表明上述技术在各种 DNN 和硬件平台上优于最先进的系统。

## 2. Background
从高级定义自动生成高性能的张量程序是极其困难的。 根据目标平台的架构，编译器需要在一个非常大和复杂的空间中搜索，其中包含优化的组合选择（例如，tile 结构、tile 大小、矢量化、并行化）。 我们在本节中描述了两种最近有效的方法，并在第 8 节中描述了其他相关工作

1. **<u>Template-guided search</u>**

    在 Template-guided 搜索中，搜索空间由手动模板定义。 如 图2a 所示，编译器（例如 TVM）要求用户手动编写计算定义模板。 该模板使用一些可调参数 (例如，tile size 和 unrolling factor) 定义张量程序的结构。 然后，编译器针对特定输入形状配置和特定硬件目标搜索这些参数的最佳值。 这种方法在常见的深度学习算子上取得了良好的性能。 
    
    然而，开发模板需要大量的努力。 例如，TVM 的代码库中已经包含了这些模板的 15K 多行代码。 随着新算子和新硬件平台的出现，这个数字还在继续增长。 此外，构建高质量模板需要张量算子和硬件方面的专业知识。 开发质量模板需要大量的研究工作 [32, 55, 59]。 尽管模板设计很复杂，但手动模板仅涵盖有限的程序结构，因为手动枚举所有 算子 的所有优化选择是令人望而却步的。 
    
    这种方法**通常需要为每个 算子 定义一个模板**。 FlexTensor [59] 提出了一个覆盖多个算子的通用模板，但它的模板仍然是为单个算子粒度设计的，没有包括涉及多个算子的优化（例如，算子融合）。 优化具有多个算子的计算图的搜索空间应该包含不同的方式来组合算子。 基于模板的方法无法实现这一点，因为它无法分解固定模板并在搜索过程中重新组合它们。

2. **<u>Sequential construction based search</u>**

    !!! warning "疑问"
        后续可以看一下这个是什么东西， beam search?
    
    这种方法通过将程序构造分解为固定的决策序列来定义搜索空间。 然后，编译器使用一种算法，例如 beam search [34] 来搜索好的决策（例如，Halide auto-scheduler [2]）。 在这种方法中，编译器通过**顺序展开计算图中的所有节点来构建张量程序**。 对于每个节点，编译器都会就如何将其转换为低级张量程序做出一些决定（即决定计算位置、存储位置、分块大小等）。 当所有节点展开后，一个完整的张量程序就构建完成了。 该方法对每个节点使用一组通用的展开规则，因此它可以自动搜索而不需要手动模板。 由于每个决策的可能选择数量很大，为了使顺序过程可行， 编译器估计候选程序的性能并将其与 学习成本模型 进行比较，以选择前 k 个候选程序。 在搜索过程中，候选程序是不完整的，因为仅展开了部分计算图或仅做出了部分决策。 图 2b 显示了这个过程。然而，**估计不完整程序的最终性能在几个方面是困难的**：
    
    (1) **在完整程序上训练的成本模型不能准确预测不完整程序的最终性能**。 成本模型只能在完整的程序上进行训练，因为我们需要编译程序并测量它们的执行时间以获得训练标签。 直接使用这个模型来预测不完整程序的性能准确性会很差。 作为案例研究，我们使用来自搜索空间的 20,000 个随机完整程序来训练我们的成本模型 (§5.2)，并使用该模型来预测不完整程序的最终性能。 不完整的程序是通过仅应用完整程序的一小部分循环转换而获得的。 我们使用两个指标进行评估：pair-wise 的 accuracy 和 前 k 个程序的 recall@k score (k = 10)。 如 图 3 所示，两条曲线分别从 50% 和 0% 开始，这意味着零信息的随机猜测给出了 50% 的成对比较准确率和 0% 的 top-k recall。 这两条曲线随着程序的完成而迅速增加，这意味着成本模型对于完整程序的性能非常好，但无法准确预测不完整程序的最终性能。

    !!! note "note"
        其中 accuracy 是检索出相关文档数与检索出的文档总数的比率，衡量的是检索系统的查准率；

        recall 是指检索出的相关文档数和文档库中所有的相关文档数的比率，衡量的是检索系统的查全率。
    
    (2) **顺序决策的固定顺序限制了搜索空间的设计**。 例如，某些优化需要向计算图中添加新节点（例如，添加缓存节点，使用 rfactor [46]）。 不同程序的决策数变得不同。 很难对齐不完整的程序以进行公平比较。

    (3) 基于等式构造的搜索不可扩展。 扩大搜索空间需要增加更多的顺序构造步骤，然而，这会导致更严重的累积误差。

3. **<u>Ansor’s hierarchical approach</u>**

    Ansor 由分层搜索空间支持，该空间将高级结构和低级细节分离。 Ansor **自动构建计算图的搜索空间**，无需手动开发模板。 然后 Ansor 从空间中采样完整的程序并对完整的程序进行微调，避免对不完整程序的估计不准确。 图 2 显示了 Ansor 的方法与现有方法之间的主要区别。

## 3. Design Overview

## 8. Related work
- **<u>基于调度语言的自动张量程序生成</u>**。 

    Halide [41] 引入了一种可以描述循环优化原语的调度语言。 该语言适用于手动优化和自动搜索。 Halide 具有基于不同技术的三个版本的自动调度程序 [2、31、36]。 最新的带有 beam search 和 learned cost model 的模型在其中表现最好，我们的评估也使用了它。 
    
    TVM [11] 使用类似的调度语言并包括**模板引导搜索框架 AutoTVM** [12]。 FlexTensor [59] 提出了可以针对一组算子的通用模板，但它的模板是为单个算子设计的。 很难将这些模板用于涉及多个算子的优化（例如，算子融合）。 
    
    并行工作 ProTuner [19] 使用蒙特卡洛树搜索来解决 Halide 自动调度器中的不准确估计问题。 ProTuner 主要针对图像处理工作负载，而 Ansor 针对深度学习工作负载并引入了新的搜索空间和其他优化。 

- **<u>多面体编译模型</u>**。 

    多面体编译模型 [8,52,53] 将程序优化表述为整数线性规划 (ILP) 问题。 它使用仿射循环变换优化程序，使相关语句之间的数据重用距离最小化。 Tiramisu [5] 和 Tensor Comprehensions [49] 是两个同样针对深度学习领域的多面体编译器。 Tiramisu 提供了类似Halide语言的调度语言，需要手动调度。 Tensor Comprehensions 可以自动搜索 GPU 代码，但它还不能用于计算受限的问题 [11]。 它不能在 conv2d 和 matmul [11,48] 等算子上胜过 TVM。 这是因为缺乏某些优化 [50] 和多面体公式中不准确的隐性成本模型。

- **<u>深度学习的图级优化</u>**。 

    图级优化将计算图中的算子作为一个基本单元，不改变算子内部实现。 常见优化包括 布局优化[32]、算子融合[11、38、60]、常量折叠[42]、自动批处理[33]、自动生成图替换[29]等。 图级优化通常是算子级优化的补充。 图级优化也可以受益于算子的高性能实现。 比如通用算子融合就依赖于Ansor的代码生成能力。 我们将 Ansor 的 **联合优化和更多图级优化作为未来的工作**。

- **<u>基于搜索的编译和自动调整</u>**。 

    基于搜索的编译和自动调整已经在深度学习以外的领域展示了它们的有效性。 Stock [44] 是一个基于随机搜索的超级优化器。 Stock 搜索无循环硬件指令序列，而 Ansor 生成带有循环嵌套的张量程序。 OpenTuner [4] 是一个基于 multi-armed bandit approaches 的程序自动调整的通用框架。 
    
    OpenTuner 依赖用户指定的搜索空间，而 Ansor 自动构建搜索空间。 传统的高性能库，如 ATLAS [56] 和 FFTW [16] 也使用自动调整。 最近的作品 NeuroVectorizer [18] 和 AutoPhase [20, 26] 使用深度强化学习来自动向量化程序并优化编译器阶段顺序

## 9.  Limitations and Future work
1. Ansor 的局限性之一是 无法优化具有  dynamic shapes 的 graph [45]。 Ansor 要求计算图中的形状是静态的并且事先已知，以便进行分析、构建搜索空间和执行测量。 如何为符号或动态形状生成程序是一个有趣的未来方向。
2. 另一个限制是 Ansor 仅支持密集(dense)算子。 为了支持稀疏神经网络 [17] 和图形神经网络 [25] 中常用的稀疏算子（例如 SpMM），我们希望 Ansor 的很大一部分仍然可以重用，但我们需要重新设计搜索空间。
3. 最后，Ansor 仅在高层执行程序优化，但依赖于其他代码生成器（例如 LLVM 和 NVCC）来进行平台相关的优化（例如指令选择）。 Ansor 没有利用 Intel VNNI、NVIDIA Tensor Core 和 ARM Dot 等针对混合精度和低精度算子的特殊指令，目前现成的代码生成器无法很好地处理这些指令。

